8/5/22 To do today

✅    Make some music with the chords you made for Balloon Drum Music. Build a woodwind orchestra.

✅    Start logging to a log file instead of print().                  

----------------------------------------------
8/6/22 To do today:

✅    Double check the note numbers between the chart and the notebook. The diamond to the 31 limit online is bogus. Lots of wrong numbers for the note number. But the ratios, names, and locations are correct. I couldn't get Sagittal installed, and the replacement is not compatible with Sagittal. I installed BravuraMSS, and I can see some of the characters, but they don't match what Sagittal provided. Dave Keenan came to my rescue and I have the Sagittal font now. Some of the notes aren't right, but enough are to just move on. 40 - 127 are good. 160 - 242 seem good too. But 128 through 159 are whack. I think I fixed them. Now I need to fix the diamond in the spreadsheet, save it as a jpeg, and post it to the notebook.

✅    I have it as a jpeg now. Need to overwrite this: http://ripnread.com/listen/31-Limit-Just-Tonality-Diamond.jpg
Actually, I left that one up there, but made a new one here: http://ripnread.com/listen/Diamond_31-limit.jpg
Almost legible in a half screen.

----------------------------------------------
8/7/22 To do today:

✅    Figure out why the logging starts going to ball.log, then switches to open_samples3.log weird. 
      The important thing is to make sure it doesn't restart logging in any of the following calls:
            stretch.piano_roll_to_pfields(csound_params) 
            p.load_csd
            stretch.process_pfields_to_csd_file
            
✅    Convert the vstack to np.concatenate 

-----------------------
8/8/22 to do today:

✅    Include finger piano and balloon drums along with the woodwinds. 
      Fewer winds. Loose the eng horn, bach trumpet, contra bassoon. That was much harder than I remember. At first I couldn't get the tempo to work. I had to have multiple voices before it started working with the q variable. Prior to that it was ignoring the q4000. No idea why.

--------------------
8/9/22 to do today:

✅    Fix the tempo assignment. It's whack. 
      t 0 117 100.0 117 100.0 104 100.0 104 100.0 104 100.0 104 100.0 103 100.0 103 100.0 99 100.0 99 100.0 99 100.0 99 100.0  
      Spent two hours on it and I can't figure it out. Amazing.   
      t 0 138 108.0 138 108.0 147 216.0 147 216.0 147; must leave off the last one or add one more tempo at the end
      Fixed it. Tempo is way too fast at the moment. But it works. The key is adding one more at the end of the string.
      
----------------------------------------
8/10/22 To do today:

✅    You have the outline of a piece of music now. 
      Circle through the ABCD modes and back to A. Fix up the ending of each section, perhaps eliminate gaps. Think about transitions. 

------------------------------
8/12/22 To do today:

☐    put all the chord assignments into a python module and import it. 
      Clutters up the notebook.  Bbmaj_A_1 and the like ABCD, all chords

☐    There are many levers in the variable setting cell of the notebook. 
      What are the most important levers affecting the musical quality?

✅    I think I'm going to have to double up the voices, and use pfields to csound to limit the voices at any one time. 
      It's already 32 voices. Take a look at the zero to one ratios. I reduced the zeros and increased the ones.
      Looking at coconet_open_samples.ipynb for some ideas on how to do that. 
      It was a mess. for row in pfields:
      The idea should be that we have a list of lists of voices, and if the voice of the row is in the list, then it gets played, otherwise it is dropped. 
            collection = [[1, 2], [5, 6, 7, 13], [9, 10, 11, 12, 13], [1, 7, 10, 12], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]]      
      
✅    The key is knowing when to switch from one list of lists to the next.  Some key ideas that I took advantage of:
            - Current time_step: pfields[17] 
            - Adjust volume and velocity for downbeats: volume(pfields[i][3] and the velocity pfields[i][14] is the volume)
            - voice is row[6]. If in collection[this_collection] - collection is a list of lists, this_collection starts of as 0, and is incremented with each section 
            - at the end of the section, 
                  this_collection += 1
                  this_collection %= len(collection)
            - I had to add in the missing notes after the loop, which indicates I wrote the loop wrong. Is there a while loop instead of iterating through the rows of pfields. 
      I seem to have royally screwed up this section of code. I was thinking that the index of the array, i was the time_step. Not even close. It's the index through the pfields, which I don't think I even need to keep track of. So I got rid of i, now it still moves almost every pfield row into new_pfields. Crazy. Well, all but 71 of them anyway. Why? And if I change the collections array, it only moves the voice 1 into new_pfields. I think that's because pfields at this point is sorted by voice, not by time_step. pfields.sort()  fixed it.

✅    Shorter section endings. I kind of like them now. Vary the length of the section endings more. Some very long, some very short

☐     I found a reference to Erv Wilson and Cassandra on Facebook in the Xenharmonic Alliance from 3/29/2017. 
      I posted something about this on Facebook and Paul Ehrlich responded. Someone else said to look in tres.pdf in the Wilson Archives.

☐    I should do something about this bug. It's annoying. 
      shaded_mask building. total_size = 864, (zero_ratio + one_ratio) * (total_size / total_ratio) = 864.0
      shaded_mask building. total_size = 512, (zero_ratio + one_ratio) * (total_size / total_ratio) = 512.0
      INFO:root:mask_zeros = 8, mask_ones = 3
      shaded_mask building. total_size = 800, (zero_ratio + one_ratio) * (total_size / total_ratio) = 800.0000000000001
      The sum of the ratios 11 must be divisible into the product of the mask shapes: 800
      72.72727272727273 is not an integer
      I'm going to have to switch from a range to specific collections of zero_ratio, one_ratio, total_size, total_ratio. 

✅    I need to be able to control the envelopes more closely. 
      Today, I can specify only a set of envelopes that are used across all instruments and throughout the whole piece. I can influence how likely they are. This worked when all the instruments were fairly similar, strings and plucked tines, for example. Or for bowed, plucked and vibrato strings. But when I have woodwinds, finger pianos, balloon drums and brass, I'll need some other way to control them. 
      I could change them during the scan of the pfields. 
            for row in pfields: # might be a good section to modify the envelopes. 
      This is a big job. Not really. Just a few lines
      Why is the first section sometimes empty of notes? I think I fixed it. It was because of the use of one index for both the collections: time step range and instrument collection.
            this_last_time_step += 1
            this_last_time_step %= len(last_time_step) 
            this_collection += 1
            this_collection %= len(collection_of_voices)
      This appears to have fixed it.
-------------------------------------------      
8/14/22 To do today:     

✅    Make some of the bridge sections shorter than others. End them earlier in the sequence. 

✅    Find a way to have a rather longer vamp on different tetrads. 

✅          Tetrad otonal ratios
            A     1:1 5:4 3:2 7:4
            B     9:8 11:8 13:8 15:8
            C     17:16 24:16 25:16 29:16
            D     19:16 23:16 27:16 31:16

            Tetrad utonal ratios
            A     8:7 4:3 8:5 1:1
            B     6:15 16:13 16:11 16:9
            C     32:29 32:25 32:21 32:17
            D     32:31 32:27 32:23 32:19

✅    Finished several pretty good versions. All around 10 minutes. 
      Posted #17 to ripnread.
      -rw-r--r--. 1 prent prent 25M Aug 14 15:35 /home/prent/Dropbox/Uploads/ball2-t17.mp3
      -rw-r--r--. 1 prent prent 20M Aug 14 15:21 /home/prent/Dropbox/Uploads/ball2-t11.mp3
      -rw-r--r--. 1 prent prent 27M Aug 14 15:16 /home/prent/Dropbox/Uploads/ball2-t12.mp3
      -rw-r--r--. 1 prent prent 29M Aug 14 13:51 /home/prent/Dropbox/Uploads/ball2-t13.mp3
      -rw-r--r--. 1 prent prent 26M Aug 14 13:47 /home/prent/Dropbox/Uploads/ball2-t14.mp3
      -rw-r--r--. 1 prent prent 28M Aug 14 13:44 /home/prent/Dropbox/Uploads/ball2-t15.mp3
      -rw-r--r--. 1 prent prent 24M Aug 14 13:37 /home/prent/Dropbox/Uploads/ball2-t16.mp3

-----------------------
8/16/22 To do today:

✅    Why does the log show up in the jupyter notebook output? 
      That's new and very annoying. Am I calling it more than once? Once I rebooted it no longer wrote the logs to the notebook. Fixed it with a reboot. It must have had something to do with running the code too many times, or out of order.

☐    What if I were to arpeggiate two separate ranges of the chorale with two different rates of speed. 
      For example, take a chord progression, tile one by 8 and another by 9, the arpeggiate each by different masks, then bring them back together.
      Do that later.

-----------------------
8/17/22 To do today:

✅    To reference a dictionary, make sure you don't get messed up with print quote marks vs. dictionary quote marks. They must be different from each other.

✅    I made the ctcsound instance produce a wave file from pfields. Next step is the live part.

----------------------
8/18/22 To do today:

✅    I can get by with 16 voices instead of 32 for the finger piano and balloon drums. Maybe even fewer, or higher zeros in the mask to thin it out.

✅    Next steps: Create a short chorale structure and use the ctcsound implementation to speed up the feedback loop. 
      Create an instance of csound that I can throw notes against live. 

✅    Make a csd file that can be used for live performance. 
      Needs a long f0 function, and route audio to live. ball3.csd is the one. I know how to set f0 to a long time, but what is the <CsOptions> statement to go live instead of to a file. Here is what sending it to a file looks like:
            -o /home/prent/Music/sflib/ball2.wav -W -G -m2 -3 
      -o means output         
      -o dac for realtime output. That's all it takes I guess. But timing is important, since the orchestra plays notes at a specified time. 
      More here: https://csound.com/docs/manual/UsingRealTime.html

      Segmentation fault. I hate segmentation faults.
----------------------------
8/22/22 To do today:

✅    See if you can call ctcsound twice without segmentation faults. 
      Switch to the flute used in Whisper Song in 53 EDO. The liner notes says bass flute, but I think it's actually alto flute.
      It looks like I made it in May 22, 2005. I found the source code, and it's definitely a bass flute 96 in the McGill.dat.
      If I'm going to make that change, also delete the unused balloon flute in ball2.csd
      
✅    There is an option to have ctcsound take the sound as it arrives, or some sort of offset factor.
            pt.scoreEvent(0, 'i', field)
      The event has type opcod (e.g. ‘i’ for a note event). 
      pFields is tuple, a list, or an ndarray of MYFLTs with all the pfields for this event, 
      starting with the p1 value specified in pFields[0]. 

      if absp2mode is 0 (False), the start time of the event is relative to the current time.
      if absp2mode is 1 (True), the start time of the event is measured from the beginning of the performance.
      I've always used False, 0 for this value. That may explain why I sometimes had the tempo go all crazy sometimes. If it was long, it would start setting the time relative to the current time, which was moving forward as more notes were sent to ctcsound. I should have said True. I'll have to confirm that later. When I switch it to 1 in the notebook, it runs the first few notes together, like it's trying to catch up. I'm going to stick with zero.

✅    Create a mask for each scale to indicate if a note has to be lowered an octave. 
      Tried that. Devilishly challenging. np.subtract works, but it's critical that all the dimensions are the same. 
      It's as hard as the np.concatenate function. If the dimensions don't match with concat, it fails. If they don't match with np.subtract, you suddenly have exploding dimensions. 

--------------------------------
8/24/22 To do today:

✅    I discovered that I can keep the ctcsound running for hours without having to shut it down. 
      I can even keep sending new chords to it.

-----------------------------
8/25/22 To do today

✅    Next step is to find a way to collect all the glissando, trills, mordants in a data structure that is indexed.
      I'm thinking I could index it by the 16 scale degrees much like to dictionary keys:
            keys = {'Bbmaj': np.array([179, 200, 0, 16, 34, 49, 63, 77, 90, 103, 115, 127, 138, 147, 159, 169]), 
                  'Dpmaj': np.array([42, 61, 79, 95, 112, 127, 141, 155, 168, 180, 194, 210, 0, 6, 21, 33]), ...
                  
            Each of those 16 scale degrees could have a different ratio to the next note. But those ratios are probably not used very often. Better to work out ratios between ranks, or within scales
            scales = {'A_oton':np.array([note % 16 for note in np.arange(0, 16, 2)]),
                  'B_oton':np.array([note % 16 for note in np.arange(2, 18, 2)]),...

            for rank in scales:
                  print(f'{rank}: {scales[rank]}')

            A_oton: [ 0  2  4  6  8 10 12 14]
            B_oton: [ 2  4  6  8 10 12 14  0]...
            
            otonal_ratios = {(0,2): 9/8, (0,4): 5/4, # I'll need the inverse of these as well. Got them.
                  (1,3): 19/17, (1,5): 21/17,
                  (2,4): 10/9, (2,6): 11/9,...
            
            Can I effectively access these ratios from my code? otonal_ratios[(0,2)] = 1.125
            Can I then call something that will return the function number in the csound file?
                  trills_2_step = {16/15: 176, 15/14: 177...
                  print(f'{trills_2_step[otonal_ratios[(14,0)]] = }')
                        trills_2_step[otonal_ratios[(14,0)]] = 176

            o_numerator = np.arange(16,32,1)
            u_denominator = np.arange(16,32,1)

            There is a marvelous function called str(Fraction(some_decimal_number).limit_denominator())
                  from fractions import Fraction
            It takes in a decimal number and writes it out as a ratio.

            print(f'list of fractions in o_numerator over 16: {[str(Fraction(num/16).limit_denominator()) for num in o_numerator]}')
            print(f'list of fractions in 16 over u_denominator: {[str(Fraction(32/num).limit_denominator()) for num in u_denominator]}')

                  unique ratios in the dictionary otonal_ratios: ['16/15', '31/29', '15/14', '29/27', '14/13', '27/25', '13/12', '25/23', '12/11', '23/21', '34/31', '11/10', '21/19', '10/9', '19/17', '9/8', '8/7', '31/27', '15/13', '7/6', '34/29', '27/23', '13/11', '25/21', '25/21', '6/5', '6/5', '23/19', '11/9', '38/31', '21/17', '5/4']

                  list of fractions in o_numerator over 16: ['1', '17/16', '9/8', '19/16', '5/4', '21/16', '11/8', '23/16', '3/2', '25/16', '13/8', '27/16', '7/4', '29/16', '15/8', '31/16']
                  list of fractions in 16 over u_denominator: ['2', '32/17', '16/9', '32/19', '8/5', '32/21', '16/11', '32/23', '4/3', '32/25', '16/13', '32/27', '8/7', '32/29', '16/15', '32/31']

            I am limited to the existing ratios in the .csd file, unless I add new ones. That restricts my use to ranks A and B.
            For example, (1,3) is 19/17 and that's not in the csound .csd file. If I could find room, I can add them. 
            I will need 30 for each of the 2 step, 8 step trills, and the slide. That's 120 new function tables. I'm already up to 536, and they have to stop before 601, that's where the samples starts the sample f tables. I don't want to dump the slide with vibrato, because that makes a mean slide guitar impression with piano samples. Kyle Gann referred to it as my whammy bar. I would have to modify the samples code, and I'm loathe to do that. 
             
            I'm also missing 6/5 ratio in the 8 step trill. Could I squeeze it in? It's only missing there. Fixed it.

-----------------------------
8/26/22 To do today

✅    Fix a few remaining missing ratios in yesterday's work. 
      I don't have the utonal ratios, including 16/9, (I have 8/9). 
      I need to systematically look at the needed ones, 16/9 is way to big to use, as is 16/13, 4/3, 16/11, 8/5, 
      What I need are the utonal adjacent ratios - actually I don't need these. 
            
      Just A & B ranks  
            0        2     4     6      8     10      12     14     0
            2/1    16/9   8/5  16/11   4/3   16/13   8/7   16/15   1/1
                9/8    10/9  11/10  12/11 13/12  14/13  15/14  16/15
                8/9    0/10  10/11  11/12 12/13  13/14  14/15  15/16
      I have all those ratios already in the list of ratios, but the steps are only valid for the otonal scales. I need a similar table for the utonal scales. It turns out the ratios are the same as the otonal ones, becuase I'm going down instead of up, they match 100% with the otonal ratios. I wonder if I thought about that in advance.
      
✅    Saved the percussion concat_chorale to a file:
            np.save('balloon_drum_percussion', concat_chorale)
      Now I can retrieve it whenever I need it.            
            concat_chorale = np.load('balloon_drum_percussion.npy')

-----------------------------------
8/29/22 To do today:

✅    I need a section where the chords in the woodwinds held against the fast drums and finger pianos. 
      Maybe I can do that along with the melodies, scales, arpeggios, trills, slides.
      This is what I want to get done today. Make a choice about how you are going to use the glissandos and trills.
      Ideas for how to implement glissandi and trills:
            loop over pfields. update_row could transform two notes into one
            Do it earlier, and create a new place to store the fact that you want to apply a gliss to a voice/time_step 
                  You could change from a (voice, time_step) to a (voice, time_step, gliss) structure
            combine a bit of both. I completed a hybrid form: I created a chord structure as array 4, 2 four flutes 2 time_steps, then after the pfields were complete, I queried each note and replaced the gliss field (9) where the note field (4) was equal to the value that I wanted to change. That's not scalable, since not every note number 179 will have the same gliss value. But for now it works. I also made sure the gliss up used upsample 1 and gliss down used upsample 255. That made them have the same vibrato rate. I found the right glissando values for 4 different ratios: 9/10, 11/12, 13/14, 15/16 and their inversions: 10/9, 12/11, 14/13, 16/15. I testing slides, trills of 2 steps ending up, and trills of 8 steps starting on the note and ending down, or if they go up they end up.
                  for i in range(8): # check every note in the whole file - not scalable.
                        if pfields[i][4] == 34: pfields[i][9] = 35 # slide down 9/10 35 or trill down 2 steps 197 - 8 steps (528) 227 

✅    Make a separate set of chorale structures for the woodwinds than the percussion instruments. 
      Let them be the rhythm section, and create a horn section and melody in the winds. Make sure it exactly matches the timing of the percussion.
      I've built a set of scales in each of the ranks, A, B, C, D. They are all going up as default, and the utonal starts with the minor key. I can let them jump around: rng.choice(flute, size = 8, replace = False, shuffle = True)

✅    One thing that worked well in a previous piece of mine was used in 01 - Whisper Song in 53 EDO 1.mp3
      53-TET bass flute, cello martele, finger piano, and dry spring. 
      Some other things that really worked well: Flute with vibrato backed with cello martele. 
      Starting with a vamp, flute trills, then stopping everything but two slow chords on finger piano, then the slightest of breaks for 1/2 a beat. Then the flute comes in on the upbeat. Flute arpeggios across 2 octaves backed by the finger piano and cello.

☐     How come I never use dry spring any more?

✅    How can I store these slides along with the voices and time_steps.
      Prep work for a separate set of structures for winds
      The winds don't fit into the structures used for the percussion parts. Those can use the typical array of (voices, time_steps), but for the winds I need different envelopes, different durations, and especially the ability to support trills and slides. I'm thinking that I need to add additional dimensions:

            voices (instrument)
            time_step (midi equivalent number)
            envelope (short, long, etc.)
            glissando (slide, trill, none)).

✅    I noticed that I have a key that includes the mode in the name
      the mode includes the rank and the mode
      the inversion includes the mode, the rank, and the inversion
      I need to normalize these so that they only include the necessary information.
            key = 'Bbmaj' # it should only include the key
            mode = 'A_oton' # it should only include the oton or uton, not the rank 
            inversion = 'A_oton_2' # it should only include the inversion 
      Change them so that they look like this, in this order:
            key = 'Bb'
            mode = 'oton'
            rank = 'A' 
            inversion = '2'

✅    What are all the important variables needed for the dictionaries:
            rank = 'A'              # 'B', 'C', 'D'
            mode = 'oton'           # 'uton'
            key = 'Bb'              # keys.keys() = dict_keys(['Bb', 'Dp', 'Db', 'C_', 'G_', 'F_', 'Eb', 'Em'])
            gliss_type = 'slide'    # gliss.keys() = dict_keys(['trills_2_step', 'trills_8_step', 'slide'])
      Dictionaries:
            keys[mode][ratio] = array([179, 200,   0,  16,  34,  49,  63,  77,  90, 103, 115, 127, 138, 147, 159, 169])
            scales[rank][mode] = array([ 0,  2,  4,  6,  8, 10, 12, 14])
            scale_mask[rank][mode][key] = array([1, 1, 1, 1, 1, 0, 0, 0])
            inversions[rank][mode][inv] = array([ 0,  4,  8, 12])
            ratio_table[(step_start, step_stop)]) = '11/9'
            gliss[gliss_type][ratio] = 176 
      How to use:
            print(f'{str(Fraction(ratio_table[(step_start, step_stop)]).limit_denominator()) = }')
                       
      Functions:
            def build_chords(key, mode, rank, inversion): return chord
            def build_scales(key, mode, rank): return scale

✅    To use a list comprehension to print multiple values put the initial variables in parenthesis. As in:
                  
            for gliss_type in gliss.keys():
                  print(f'{gliss_type = }')
                            +-- parenthesis
                            |+-- first value
                            ||                                         +-- second value
                            ||                                         |
                  print(f'{[(str(Fraction(ratio).limit_denominator()), g_value) for ratio, g_value in gliss[gliss_type].items()]}')
✅    To see if a key is in a dictionary:
            if 'oton' in keys["Bb"]: print(f'{keys["Bb"]["oton"] = }')
                  keys["Bb"]["oton"] = array([179, 200,   0,  16,  34,  49,  63,  77,  90, 103, 115, 127, 138, 147, 159, 169])

----------------------
8/30/22 To do today:

✅    Latest problem is synching up the slides with the notes to which they belong. 
      I never know what note will appear in any of the pfields, even when I sort them. I need a way to make certain the slides stay with the note to which I want to apply them.
      The only way I can think of to link them is to modigfy piano_roll_to_pfields to do the following:
            1. Increase the dimension of the array to include many more variables than just the note number
                  this will break other uses
            2. Replace the piano_roll_to_pfields with a call containing everything needed to call ctcsound, process one time step at a time.
            Currently, inside the function it processes one voice at a time. 
                  for voice in csound_params["piece"]: # once for each voice    
      
☐     This is a time series, and perhaps I can use some time series frameworks to extend the sequences. 
      I remember a podcast on Data Skeptic with Julien Herzen
      PhD graduate from EPFL in Switzerland, spoke about his work with Unit 8 and the development of the Python Library: Darts. Follow Julien on twitter: @jlhrzn      
      Darts code: https://github.com/unit8co/darts
      Paper: '/home/prent/Dropbox/Tutorials/Classical-Piano-Composer/Darts: Machine Learning Time Series 21-1177.pdf'

✅    Make the time_step the key value in an array, then each will have at least one or more notes. 
      Notes have the characteristics that I want to send to csound. Each row has a time_step which is some relative time for an action. There could be multiple notes on each time_step. 
      What could it look like:
            time_step_headings = ['instrument', 'start', 'duration', 'velocity', 'tone', 'octave', 
                  'voice', 'stereo', 'l_envelope', 'gliss1', 'upsample', 'r_envelope', 'gliss2', 'gliss3', 'volume']
            So we have two dimensions: time_step, note_information
            This is basically the structure of input to csound, and the way I made pfields. 
            How can I get my notes, glisses, etc into this array? 
            I can create a chord of notes in the shape (4,) for 4 notes with no other dimension
            I can also create a set of glissandi that can take each note up to the next chord in shape (4,)
            How can I load those into the time_step array? 
            I can hand type the data into each row and column, but I'd rather find a better way. Tomorrow.
      I need something better than this:
            time_steps = np.array([[1, 0, 5, 60, 34, 4, 6, 8, 1, 35, 255, 0, 0, 0, 30],
                        [1, 0, 5, 60, 90, 4, 6, 8, 1, 33, 255, 0, 0, 0, 30],
                        [1, 0, 5, 60, 138, 4, 6, 8, 1, 31, 255, 0, 0, 0, 30],
                        [1, 0, 5, 60, 179, 4, 6, 8, 1, 29, 255, 0, 0, 0, 30],
                        [1, 5, 5, 60, 0, 4, 6, 8, 1, 20, 1, 0, 0, 0, 30],
                        [1, 5, 5, 60, 63, 4, 6, 8, 1, 18, 1, 0, 0, 0, 30],
                        [1, 5, 5, 60, 115, 4, 6, 8, 1, 16, 1, 0, 0, 0, 30],
                        [1, 5, 5, 60, 159, 4, 6, 8, 1, 14, 1, 0, 0, 0, 30]
                     ])
            I used samples to do this quite simply:
                  d0h50&Bbmaj.u255&n1.g35 &n5.g33 &n9.g31 &n13.g29d50
                  d0h50&Bbmaj.u1&n3.g20 &n5.g18 &n9.g16 &n13.g14d50
                  @ Bbmaj would set the &n_. variables to the right tone value
            So perhaps I should create several column values, then concatenate them all together.

✅    Transpose operator: array.T turns rows into columns and visa versa.
      
      This resulted in the correct data:
            time_step_dict = {'instrument': np.ones((8,), dtype = int),
                  'duration': duration,
                  'hold': np.ones((8,), dtype = int) * hold,
                  'velocity': np.ones((8,), dtype = int) * velocity,
                  'tone': np.concatenate((chord, chord2)),
                  'octave': np.ones((8,), dtype = int) * 4,
                  'voice': np.ones((8,), dtype = int) * 6,
                  'stereo': np.ones((8,), dtype = int) * 8, 
                  'l_envelope': np.ones((8,), dtype = int) * 1, 
                  'gliss1': slides, 
                  'upsample': np.concatenate((np.ones((4,), dtype = int) * upsamples[0], np.ones((4,), dtype = int) * upsamples[1])),
                  'r_envelope': np.ones((8,), dtype = int) * 1, 
                  'gliss2' : np.zeros((8,), dtype = int),
                  'gliss3': np.zeros((8,), dtype = int),
                  'volume': np.ones((8,), dtype = int) * volume}
            
            def array_from_dict(time_step_dict):
                  time_step_array = np.empty((len(time_step_dict),len(time_step_dict["instrument"])), dtype = int)
                  assert all([len(time_step_dict[time_step]) == len(time_step_dict["instrument"]) for time_step in time_step_dict.keys()]),\
                        "not all items are same quantity"
                  inx = 0
                  for column in time_step_dict:
                        time_step_array[inx] = time_step_dict[column]
                        inx += 1
                  return (time_step_array.T)
            
✅    So every phrase I want to create should be in the form of that dictionary. 
      It is a self contained multi note section. You can concatenate more of these together:
            # first convert the dictionary, which should have the correct format, into a numpy array, transposed.
            # the function checks that there are the right number of items in each of the dictionary keys().
            time_step_array = np.concatenate((array_from_dict(time_step_dict), array_from_dict(time_step_dict2)), axis = 1)
      So I'm trying to think of ways to speed this up. Instead of having to keep track of start times, use the idea that start time is always the sum of the preceding duration values, and each note has a separate hold value that used as the duration in each note. 
      Stop using start, duration
      start using duration, hold, and save somewhere the current start value as the sum of the durations that preceded it.
      It's more complicated than you remember. 
      If I'm not careful, the start time column starts to get very big. You can't go through the rows more than once, because it modifies the start location from what it was, to what it needs to be for the ctcsound invocation.
      Solved that by copy.deepcopy so I'm always using a new copy of the array and can run as many times as I want.
      Making progress.
      I need a separate data structure to keep track of the unique start_times for every voice
            inx = 0
            start_time = 0 # start at the beginning of the piece - need one of these for each voice.
            current_duration = 0 # 
            for row in temp_array:
                  start_time += current_duration 
                  current_duration = row[1] # this is the 'start' column
                  temp_array[inx,1] = start_time
                  pt.scoreEvent(0, 'i', row)
                  inx += 1
      created voice as a dictionary, with sub-dictionaries for start_time as a dictionary with instrument names, and voice numbers
            voice = {'flute': {'start_time': 0,
                              'voice_number': 6},
                     'oboe': {'start_time': 0, 
                              'voice_number': 7}
                    } 
      I wonder if I should create a voice dictionary, with start_time and voice number        
---------------------
8/31/22 To do today

✅    Done of my recent work has anything to do with TonicNet since 8/5/22.
      I should create a separate folder for this project and share it on github.

✅    Run through the tutorial on Python Classes here: https://www.pythontutorial.net/
      It's very well done and simple to follow.
      I made a notebook to run the examples: Python_Class_Tutorial.ipynb
--------------------------------------
9/1/22 To do today:

✅    How big is the tonality diamond 
      Brute force in the notebook
----------------------
9/2/22 to do today:

✅    Revise the keys to read the ratios and steps from the cassandra.csv file 

✅    Revise the scale mask to use ratios instead of the 'Bb' notation.
      
✅    I've revised many of the dictionaries on the past few days, so here they are now. 
      Put them in a separate file called dictionaries.txt.

---------------------
9/2/22 To do today:

☐    I really need a way to make this easier to use than manipulating dictionaries. Not scalable. 
      Remember how easy samples made it:
            d0h50&Bbmaj.u255&n1.g35 &n5.g33 &n9.g31 &n13.g29d50 # make a tetrad chord in Bb rank A, slide down, for 50 clicks, upsample 255 (-1) 
            d0h50&Bbmaj.u1&n3.g20 &n5.g18 &n9.g16 &n13.g14d50 # make a tetrad chord in Bb rank B, slide up, for 50 clicks, upsample 1
            @ Bbmaj would set the &n_. variables to the right tone value

☐    What would python classes do for me? A lot I think. 
      It's easier to use than a dictionary, and does a whole lot more.
      Could I set some default values automatically?
      Could I call some function with just a few values, and have it fill out the dictionary for me? Or remember the last value and just use that for subsequent items? Kind of like an automatic '.' in a field in csound which means use the same value as the prior row. But I want the same value as the previous row of the same voice. Like a behavior if we don't specify a value it automatically uses the prior value for that voice. How can I make that behaviour work? 

----------------------------------
9/3/33 To do today:

✅    What if I started out with a very skinny csd file, and then passed the key function tables via ctcsound?
            f336 = (336, 0, 256, -7, 1, 16, 1, 128, 0.90000, 112, 0.90000) # g value 35 ratio 9/10
            pt.scoreEvent(0, 'f', f336)
            # it gets a warning message written to the log: 
                  WARNING: replacing previous ftable 330
            But it works.
            So what this means is I no longer need to prewrite the glissandi to the csd file, but even if I do, I can overwrite them. 
            And I can switch back to 213 tones per octave. This may take a while

      The current ball3.csd file structure:
            <CsoundSynthesizer> 
            <CsOptions> 
            -o dac
            ; -W -G -m2 -3 
            </CsOptions> 
            
            <CsInstruments> 
            ; here is where the instrument is defined
            <CsScore> 
            ; here is where the function tables are defined
            f0 2440 ; how long the piece is, how long ctcsound will stay alive waiting for commands to act upon
            ; cents for each step in the scale 217 partch tonality diamond to the 31-limit
            f3 0 256 -2 ...
            f4 0 1025 9 .25 1 0 ;The first quadrant of a sine for panning 
            f300 and up are the gliss tables: 2 step, 8 step, slide, slide with vibrato
            f526 - last gliss table
            f298 down to 261 - envelope tables
            f601 and up - sample file metadata and samples
            ; the next two are calculated by samples.pas to point to the location of the sample files and metadata
            f768 end of sample file metadata and samples.
            f1 0 64 -2 0 601 630 656 661 666 671 687 706 728 748 
            f2 0 64 -2 0 1 1 2 2 2 2 2 2 2 2

✅    I've created an f3 table that I can load after I start the "skinny" csd file. 
      But I'll need some pretty gnarly logic to link the ratios to the 213 tone scale degrees. Maybe I shouldn't remove the duplicates. But I might need to have them sorted. Maybe not. Give it a try. It works with 296 scale degrees not sorted in the f3 table. Neat.

✅    So I was able to recreate the keys[mode][ratio] dictionary with the items now pointing to the new f3 function table values 
      And once I send the f3_array_ready_to_load to Ctcsound it overwrites what is in ball3.csd. I made ball3.csd have the current f3_array_ready_to_load values, so it works by default.

---------------------------------------
9/4/22 To do today:

✅    Create new 'ranks' for all the other 8 note scales I can make from the oton or uton modes, like those identified in the microtonal spreadsheet. Lots of those require all both 'uton' and 'oton' notes, so those will be off limits for now. I made a stab at a subminor scale on oton, and one that doesn't have a 3:2 in 'uton'. I think a scale really needs the 3:2. This has broken a lot of other functions. I'll have to think about this some more. 

✅    Finish the ratio_table with all the steps. 
      Remember that ratio_strings.reshape(256,)[note] is a string. Created a function to turn it into a float.

✅    Something is wrong with the scale_mask numbers now. Now that I've reordered the f3 table, they are whack.
      The distance between note numbers doesn't really tell me anything, unless they are bigger than 256. 

--------------------------
9/5/22 To do today

✅    Replace some of the dictionaries with function calls. 
      Making the dictionaries is prone to failure. And if you can code what the dictionary should contain then you can code a function to deliver the answer. For example, the ratio_table. I coded up the content yesterday, but had to print the content, then cut and paste to make the dictionary. Error prone. Replaced with a simple calculation. Brilliant. 

✅    What other dictionaries would be better as functions? 
      I think the scale mask could be replaced by a function that would provide a mask on demand.

✅    Perhaps I should return note to just an index into the f3 table. Use octave for what it says it should be.

✅    One of the things I've always done when looking for interesting scales is limit them to ones with at least one 3/2.
      See the ratios of each of these steps in oton and uton scales. I found some where the ratio was in ([3/2, 3/4]) those are:
            oton
            (0, 8): 3/2, (2, 11): 3/2, (4, 14): 3/2, (8, 2): 3/4, (12, 5): 3/4,
            uton
            (2, 8): 4/3, (5, 12): 4/3, (8, 0): 2/3, (11, 2): 2/3, (14, 4): 2/3, 

            Make sure the 3:2 is in position 5, not 6. 
            Next step is to play these on a keyboard and fiddle with the upper tones until you find something with character.

            otonal modes:
            A: [ 0  2  4  6  8 10 12 14 ]: 1/1 9/8	5/4	11/8	3/2	13/8	7/4	15/8	1/1	
            root: 1/1 third: 5/4 3rd ratio: 5/4 above root - this is already in scales['A','oton']
            B: [ 2,  4,  6,  8, 10, 12, 14,  0]:  9/8 5/4 11/8 3/2 13/8 7/4 15/8 
            C: [ 1,  3,  5,  7,  9, 11, 13, 15]:  17/16 19/16 21/16 23/16 25/16 27/16 29/16 31/16 
            D: [ 3,  5,  7,  9, 11, 13, 15,  1]:  19/16 21/16 23/16 25/16 27/16 29/16 31/16 17/17
            E: [  2,  4,  6,  8, 11, 13, 15,  0]: 9/8 5/4 11/8 3/2 27/16 29/16 31/16 1/1
            root: 9/8 third: 11/8 3rd ratio: 11/9 above root - this is almost the same as scales['B','oton'], but with a 3:2 11
            F: [ 8, 10, 12, 14,  0,  2,  4,  6]: 3/2	13/8	7/4	15/8	1/1	9/8	5/4	11/8	3/2	
            root: 3/2 third: 7/4 3rd ratio: 7/6 above root
            G: [ 4,  6,  8, 10, 14, 15,  0,  2]: 5/4	11/8	3/2	13/8	15/8	31/16	1/1	9/8	5/4	
            root: 5/4 third: 3/2 3rd ratio: 6/5 above root
            H: [12, 14,  0,  2,  5,  7,  9, 11]: 7/4	15/8	1/1	9/8	21/16	23/16	25/16	27/16	
            root: 7/4 third: 1/1 3rd ratio: 4/7 above root
            
            utonal modes:
            A: [ 8,  6,  4,  2,  0, 14, 12, 10]
            B: [14, 12, 10,  8,  6,  4,  2,  0]
            C: [13, 11,  9,  7,  5,  3,  1, 15]
            D: [15, 13, 11,  9,  7,  5,  3,  1]
            'E': [ 8, 6, 4, 2, 0, 15, 13, 11] # 3rd: 6:5 minor (8,4,0)
            'F': [ 0, 14, 12, 10,  8,  6,  4,  2] # 3rd: 8:7 subminor (0,12,8)
            'G': [14, 10,  8,  6,  4,  2,  0, 15] # 3rd: 5:4 major (14,8,4)
            'H': [5,  3,   1, 15, 12, 10,  8,  6]# 3rd: 21/17 neutral (5,1,12) G+, B-, D+
-------------------------------------
9/6/22 To do today

✅    I think I may have put too much weight on the distinction between ranks A & B and C & D. 
      After all, they are the same notes, just start at a different spot. For that matter, the scales above are just a different 8 note scale. They key difference is between notes in the 15-limt and those in the 31-limit diamond.
      So I created E, F, G, H from the interesting scales above. It was more than just flipping the otonal to make the utonal. Finding the 3rd and 5th was challenging. But I got it done and the notebook works now.

----------------------
9/7/22 To do today:

✅    I think I eliminated the array_from_dict function's ability to translate duration and hold into start_time and duration.
      I remember making that work, but now it's gone. I looked at one from 4 days ago, and it doesn't have that capability. I must have done it somewhere else. It was somewhere else. And it's linked to the ability to track each voice's current start time. I created a new function fix_start_duration_values(time_steps, voice_time["flute"]["start_time"]). It updates the voice_time dictionary during the process. I'm not happy with that structure. I don't really have that much information about a voice that I need to track. Right now it has the voice number and the current time. Anything else needed? If now, I should just track the current time for the voice.

✅    Csound doesn't work. It keeps coming back with this error:
            
            INIT ERROR in instr 1 (opcode oscili.kk) line 109: Invalid ftable no. 0.000000
      The real problem is invalid table no. 0. 
            Here is line 109: 
                  kcpsm2 oscili 1, 1/p3, i13 ; create a 2nd set of shift multiplicands from table - glissandi 2
                  p1          2           3           4     5           6     7           8           9           10
            ['instrument', 'duration', 'hold', 'velocity', 'tone', 'octave', 'voice', 'stereo', 'l_envelope', 'gliss1', 
                  11          12          13          14    15
            'upsample', 'r_envelope', 'gliss2', 'gliss3', 'volume'])
            I tried to shift it back to integers from floats, that didn't help. Switched it back. The problem was a 0 table.
            Once I tested the table against zero, I routed around the problem. There must have been a table 301 that existed in the old csd file. When I got rid of all the gliss tables, I probably took that one too. Now that I no longer subtract 301 from the g value, it was suddenly exposed as an error. Fixed it.

-----------------------------------
9/8/22 To do today:

☐     I'm reading the csound manual sequentially. Interesting things are discovered
      ramping - https://csound.com/docs/manual/ScoreRamping.html for example a pitch will gradually ramp from one row to another with the < in place of a pitch value.
      #include "filename" - you can have one file that sets most of the default values and is called to imbed some text with one line. Neat. I could have really used that. For the last 20 years or so.
      voice - emulates the sound of a human voice - never tried that.
      sample playback signal generators: https://csound.com/docs/manual/SiggenSample.html
            a3 loscil 1, kcps2, iFtable, ibascps ; this is one I use for mono sampling with looping
      others: loscil3 - uses cubic interpolation - I don't know if I ever found an benefit from that. 
            loscilx - for multiple channel samples
            lposcil - high precision - I don't know if I ever tried that.
      printing - printk - https://csound.com/docs/manual/SigioPdisplay.html
      Limits: there used to be a limit of 200 tables. I blew through that 20 years ago. It is automatically extended. 

✅    ctcsound documentation. https://csound.com/docs/ctcsound/index.html
            csound magics https://github.com/csound/ctcsound/blob/master/cookbook/06-csoundmagics.ipynb
                  lets you run csound from a notebook
            API - scoreEvent(type, pfields)
                  https://csound.com/docs/ctcsound/index.html
                  type_ is the score event type (‘a’, ‘i’, ‘q’, ‘f’, or ‘e’). so what do they all mean?
                  csound manual under score statements: https://csound.com/docs/manual/ScoreStatements.html
                        a - advance score time a 0 start_advance - advance over silence, for example
                        i - instrument time, and duration, and other control statements 
                        q - quiet an instrument q instrument # 0 (muted)
                        f - table values created with GEN statements
                        e - mark the end of the last section 
                  By this I asssume I can pass f statements to csound to create glissandi dynamically
            I noticed that it doesn't talk about handling a t0 value to slow down and keep integer values. I don't need that any more because ctcsound supports floats just fine.

✅    I need to make sure that I have the right values reaching csound in terms of note and gliss. p5 & p10
            Solid match.

✅    I need to ajust fix_start_duration function to take the short name as input, instead of two values 
      instead of the current time and short_name just take the short name.

-----------------------
9/9/22 To do today:

✅    Noticed a problem with build_slides: 
            # the last slide is 1.875, which is from 14 (15:8) to 0 (1:1). I wanted 15:8 to 2:1.
            # how can I change the function build_slides to make that check and choose the nearest alternative?
            print(f'{scale_1[-1] = }, {all_ratio_strings[scale_1[-1]] = }')
            print(f'{scale_2[-1] = }, {all_ratio_strings[scale_2[-1]] = }')
      I think the problem can be best solved in the function ratio_distance.
            print(f'distance from {all_ratio_strings[15]} to {all_ratio_strings[1]} is {ratio_distance(all_ratio_strings[15], all_ratio_strings[1])} = {Fraction(ratio_distance(all_ratio_strings[15], all_ratio_strings[1])).limit_denominator(100)}')
            distance from 31/16 to 17/16 is 0.5483870967741935 = 17/31
            I want it to be smart enough to go to the nearest 17/16, which is 17/8 an octave up (or down from there.
            distance from 1/1 to 15/8 is 1.875 = 15/8 . I want it to go from 2/1 to 15/8. 
            Fixed it.

-------------------------------------
9/10/22 To do today:

✅    Create a python library with all the dictionaries and functions.
      This was harder than I expected. Again. I have to pass into the python code a lot of structures that were accessible in the notebook: keys, scales for example are defined in the diamond_music_utils.py, but not accessable from other functions. Perhaps it's because I define them in a function. Maybe. So I modified all the calls to pass them as parameters.
      Now I'm thinking it would be better to keep the dictionaries invisible to the notebook, instead have functions that return values. I wonder if I could use classes for this. 

✅    I pulled voice_time from the python library and put it in the notebook. 
      This dictionary will be different for every notebook. I think I'll have to pull the note dictionary also. I'm thinking I could replace it with a class. Maybe.
      So we now have two dictionaries in the notebook:
            voice_time[short_name] 'fpn', 'bnp', 'bdl', 'bdm', 'bdh', 'bfl', 'obo', 'cla', 'bss', 'frn'
            time_step_dict[] with a key = short name of the instrument, currently 'bfl' and 'bss' 

-------------------------
9/11/22 To do today:

✅    I need to remove the gliss tables to their own array. 
      Only store the table number with the note, not the whole function table itself. Solution is to have a function that stores up the functions that will be sent to csound until it's time to make music, then send them in bulk to the csound instance. 

✅    I need a way to reset the voice_time 'start' value. 
      I thought I did this, but it still fails to reset the start time:
            dmu.show_voice_time()[bfl]["start"] = 78.00000000000001
            dmu.show_voice_time()[bss]["start"] = 65.625
      This was left over from a prior function in the diamond_music_utils.py library. I removed the function, but python must cache it somehow, because even though it was no longer in the library, it was still returning results. Closed the notebook and restarted jupyter. Fixed it: AttributeError: module 'diamond_music_utils' has no attribute 'show_voice_time'

-------------------------------------
9/12/22 To do today:

✅    Fixed yesterday's bugs.

✅    The function time_steps = dmu.fix_start_duration_values(winds, voice_time, ) fails. 
      It needs a voice_time[short_name]. What if I want to send several voices? I really should not need the short name. I can look inside time_step_array for the voice number, then through the voice_time to find the relevant to find that voice number, and set the start time accordingly. I've made many changes, and the current version is in the notebook.
      The problem is that instrument wipes out the prior note that was sent to the instrument. I'll need someplace to save a collection of notes.

--------------------------
9/13/22 To do today:

✅    dmu.build_slides returns all the table number built since the first call. 
      It should only return the elements from the current call to the function, not all of them. 
      Fixed that.

✅    3.    dmu.build_slides(tones_1, tones_2) keeps returning 4 additional slides with every invocation, now up to 44 of them.
            I had forgotten to set global stored_gliss in the dum.init_instrument function. So it was just initiating a local stored_gliss instead of the global one. Fixed it. We only need to use the global keyword in a function if we want to do assignments or change the global variable. global is not needed for printing and accessing. 
            Fixed that 
            Csound fails to use the slides, maybe because he gets passed 44 of them instead of just 4. 
            Fixed that problem by making sure I was using global before variables that are assigned values in a function.
                  grep -c "replacing previous ftable" ball3.log
                  84            
            Csound still fails to use the slides even after I fixed the problem where it was passed 84 of them. 
            What's up with that?
                  gliss_1 = array([800., 801., 802., 803.]) # that's correct - csound is ready to receive them
                  print(f'{round(row[8],3)}') # prints .9, .917, .929, .938 which are the right ftable values
                  # csound was sent the right ftables.
                  But the instrument doesn't assign them. When it gets to the 'i' being sent to csound, the row values in winds are not correct.
                  instrument, duration, hold, velocity, tone, octave, voice, stereo, l_envelope, gliss, upsample, r_envelope, gliss2, gliss3, volume 
                  ins sta hol vel ton oct voi ste env gli ups renv gl2 gl3 vol
                  [1,  0,  5, 60,  36,  4,  7,  8,  1,  0,  1,  1,  0,  0,  30]
                  [1,  0,  5, 60,  36,  4,  7,  8,  1, 800, 1,  1,  0,  0,  30] # fixed it.
                  The name in the instrument function for gliss in the arguments did not match the name in the np.array statement below it. Fixed it. But it still keeps increasing - there was another variable being assigned that was not set to global. Fixed that too.

✅    5. stored_gliss expects every table to have the same dimensions. All three have different dimensions. 
            Could I pad the shorter ones?
            gliss_f_table.shape = (4, 19) # this is trill_2_step 70 - 51
            gliss_f_table.shape = (4, 67) # trill_8_step 70 - 3 
            gliss_f_table.shape = (4, 11) # slide 70 - 11
            Padding works. Fixed it. Later I generalized it on 10/8/22 so that any length up to 70 would work. I have a feeling that limitation is going to bite me on the butt.

✅    build_slides is still producing slides bigger than it should. It should always build the least distant slide. 
      I adjusted it as well as I could, but it still selects the best ratio distance and it's too far for good sound. 
      So I've listened to them all and arranged a dictionary called good_combos with the best.
      Systematically analyzing the possible glisses for 16/9 'oton' and came up with a problem. I can't remember what it was, but I fixed it.
---------------------------
9/14/22 To do today:

✅    What would you like the final piece to look like in terms of text on the page? 
      Build that, then figure out how to make the functions that will realize that structure.
      In fact, why not go back to the structure of the recent version of Balloon Drum Music and see how a separate thread for the winds could be implemented. 
      
✅    Should it be horizontal or vertical? 
            Horizontal writes out all the notes for one voice, then moves to the next voice
            Vertical spreads the information across all the instruments one time_step at a time. I'm going to start with that.
                  chord_1 = build_chords(mode, root, rank_1, inv_1)

✅    Finally figure out what dimension you want for the piece. 
            Traditionally, time series should have the time as the first dimension, and the samples as the second dimension. So that would be (time_step, features). My time steps can repeat, so they are not unique. If I have five notes, the dimensions should be (5,15). That's what I now have:
            winds.shape = (5, 15)
            But if I want the simply repeat that, how can I contatenate so that I have (10,15)
                  save_winds = np.empty((0,15), dtype = float) # do this once
                  save_winds = np.concatenate((save_winds, winds), axis = 0)
                  print(f'{save_winds.shape = }')
                  save_winds.shape = (10, 15)
            But that doesn't update the "start" times for the second chords. That's the flaw in moving from duration to start time too soon in the process. 
            After I've done this, all the notes appended to save_winds have the same start time as the previous winds, effectively doubling the voices. But what was inteneded was to bump up the newly added winds by the sum of the existing save_winds start times. It's like I should wait and send them all through at once instead of for each instrument. Or require that all newly added notes be added by sending them through instrument. Ban concatenation. After I finally figured out how to do it. Contatenate before sending notes through instrument.

✅    Move the fixing of duration to start time to the instrument function. 
            Take care of this once and don't risk doing it again. Lots of side effects with this action 
      
✅    Now to deal with the smelly code in the calls to instrument.
            I need a way to call it more easily.     
            Perhaps I could make instrument handle multiple notes at a time. 
            What I want is the ability to quickly assemble some code that includes many chords with interesting rhythm. 
            Another idea: Create a bunch of different multi-instrument riffs, and choose among them randomly.

✅    This led to the systematic analysis of the glides available for rank 'A' & 'B', mode 'oton', and inversions 1,2,3,4.
            This is just a subset of the best_combos shape (32,4)
                  [ranks inversions]
                  ['A' 'A' '1' '2']
                  ['A' 'A' '1' '4']
                  ['A' 'B' '2' '1']
                  ['B' 'B' '3' '2']
                  ['B' 'B' '3' '4']
                  ['B' 'B' '4' '1']
                  ['B' 'B' '4' '3']
            Make these part of best_combos. This took a while, and some are still questionable. If I look closely, it's clear that going from A to B works only with the same inversion or one lower inversion. B to A same or in higher inversion.
            Same rank works for inversion one lower or higher.
            Same results for a variety of root notes. 
            For trills_8_steps, use these envelopes to limit the number of trills 
                  15: 1 up, down, up 
                  14: 2 down & up 
                  13: 4 down & up
                  12: 5 down & up 
                  11: 6 down & up
            Use the function choose_combo_trills() to retrieve a row of combo_trills

✅    A slide created on this mixture doesn't slide: 
      root = '16/9', mode = 'oton', rank_1 = 'A', rank_2 = 'A', inv_1 = 3, inv_2 = 3, dur = 2
      Well, the rank stays A and the inversion stays 3. Why is that, pray tell.
      Found it:
            inv_1 = int(note_dict['combo'][2])
            inv_1 = int(note_dict['combo'][3]) # this should have assigned it to inv_2 
      fixed it.

✅    Track the movement through the different functions and see if you can minimize assignment statements. 
      Keep as many of the same structures as it moves through the functions.
      Settle on a structure that can move seemlessly.
      If the original function is a dictionary, find ways to programatically add new entries to the dictionary.
      Make it possible to use multiples of each instrument. For example, bass flute is 'bfl'. Have another bass flute that is called 'bfx', which can be silent for a while, then join in as needed. 
      Or take advantage of duration 0 to stack multiple notes in the same instrument. 
      Perhaps keep it always zero and then go back through and add start_times.

✅    Flow:
      dictionary of notes which specifies much of what is needed in downstream functions. Is there a way to specify a function call as one of the dictionary values? Yes! 
            note_dict = {0: {'exec': chord_slide, 'mode': 'oton', 'root': '16/9', 'combo': choose_combo(), 'dur': 2, 'hold': 2, 'octv': 3, 'gliss_type':'trill_8_step', 'env': 1},
            temp = note_dict[inx]['exec'](note_dict[inx]) # calls chord_slide, passing note_dict, get an array back

      Then we call a function, which takes the dictionary as an argument.
            So we have a dictionary that I can load with values, including the function to call for those values. 
            We can have some values that are only relevant to some functions, and other to other functions.
            I need to build additional functions that do other interesting things.

      Each of those functions takes the dictionary as an argument. It must ends by calling the instrument function, which in turn updates the start values, stores the current global start values for each instrument. Instrument returns a complete note row ready to go to csound. Or stored in an array that can be saved up until you want to call csound.

✅    We now have three tiers:
      1. A dictionary called note_dict that specifies the functions and arguments that function requires and calls the functions. I can step through them sequentially or randomly 
      2. the function set that is called by #1 that receives note_dict and creates an array across all the instruments and calls the instrument function in tier 3
      3. the instrument function that updates the start time and loads an array ready for csound one voice at a time.

---------------------------
9/16/22 To do today:

✅    I'm worried that we may run out of function table numbers. Should I create a way to save those slides used many times?
      I finished that revision after a day and half of work on 10/8/22

✅    Next step is the build some more functions that the note_dict can call
      
✅    1. refine chord_slide to accept the number of repeats

✅    2. def chord_chop(note_dict) Short chop with env = 2, all instruments play a 4 note chord. 
            Make it repeatable for a certain number.
            That was complicated, because I couldn't use the np.repeat or np.tile to get it done.
            Or could I?

✅    3. Triads arpeggios switching instruments at random. Might be all, might be few, might be one.
            Switched to tetrads. 
            What would you like: a four note arpeggio on one instrument, repeated on the next instrument, with a slight change, then the next until all have played it.
            I got it to work by delaying each of the voice starts by the dur times a delay value times the index into the instruments (starting at 0) So if I make the delay in the dictionary 4, then all the notes are continuous. But if it's less than 4 there is overlap. 
                  voice_time[note_dict["instruments"][v_num]]["start"] += dur[v_num] * note_dict["delay"] * v_num
            instruments[v_num * num_inst + inx]  is out of range if delay is 1
            I bumped it up by a factor of 2 and it seems ok now. Getting some interesting effects with delay of 1 and dur of .125, hold of .5. Delay can also be a float, but keeping track of time may be challenging.
            Now I'm thinking I have crammed too much function into this module. I'm going to create a simpler version that just plays a single tetrad with variable repeats on just one instrument with repeats and no delay. 
            Still can't get the repeats to work in this one. 

✅    4. Simple tetrad with masking. Kind of like arpeggios. Easiest so far.
            
✅    5. 8 note Scale from low to high including the root note at the start and end, held at the top. 
      Enable shifting left or right. np.roll(array, shift, axis = None)
      All the instruments playing all the notes, maybe with some masking like in simple_tetrad

✅    6. Combination of trill numbers and envelope values to optimize the trill_8_steps.
      Cut them off at the right spot to create subsets
            For trills_8_steps, use these envelopes to limit the number of trills 
                  15: 1 up, down, up hit 1/6 the normal length 
                  14: 2 down & up 1/4 the normal length 
                  13: 4 down & up 1/2 the normal length 
                  12: 5 down & up hit and sustain 2/3 the normal length 
                  11: 6 down & up 3/4 the normal length
                  1:  8 down & up full length
            combo_trills = ([15, 4,20])                  
 
 ---------------------------
 9/17/22 To do today
      
✅    Bug in dmu.build_scale_mask(). 
      It only handles one octave at a time, and screws things up for multiple octaves. I don't like scales of 
      more than 2 octaves anyway.

✅    Make a decision: tl;dr: 
      I decided to make the conversion from duration into start time much later in the process. I'm not going back
      - Was the choice of sending one note at a time to convert duration into start time correct or should I keep it in the duration format for longer through the process?
      - In favor of keeping it as is: Don't make changes unless you are certain it is the wise choice
            This format makes it easier to align several voices to do one task together, for example a chord slide using all the instruments.
            I'm working through the troubles, and may not change after all.

      - Opposed to keeping it as is: Today, once I have converted from duration into start time I can no longer use any of the numpy functions to modify the string of notes. No way to reorder, stretch, shrink, repeat, tile, or otherwise transform it once the start time is attached to the note. It's forever going to start at that time, or I'll have to go through complex processes to revise the note start times, outside of numpy.
      - Tiles always duplicate exactly. I'd like to roll between tiles. 

      What I have decided to do is to delay the conversion to start time from duration to later in the process. Perhaps during the write to csound or earlier. 

      I have duplicates the current notebook, called Diamond_music_utils.ipynb, as a new notebook Diamond_music_whisper_song.ipynb, and I will make that notebook the one with the delayed conversion of duration to start_time. I made Diamond_music_whisper_song-temp.ipynb to contain some fixes to Diamond_music_whisper_song.ipynb. 

✅    I'm working on that now. 
      I don't think it's quite getting the start times and durations correctly, and it's still letting the 0 hold notes through to csound. It should cut them off before going out.

      I can't figure out how this function is failing:
            winds.shape = (45, 15)
            fixed_winds.shape = (27, 15)
            Fixed it. I limited the return function to just those that belonged.
                  return note_array[:note_num,:]
      
      But it still messes up the start times. Here is how I used to do it.
            current_time = voice_time[voice_name]["start"] # what is this voice's current start time
            next_note[1] = current_time # overwrite column 1 (duration) with the new start_time
            return next_note
      I was using the hold time [2] instead of the dur [1] value
      I'm getting closer, but when I decrease the density, which causes more notes to have 0 hold time, the timing gets bad. I gave up trying to not copy the notes with 0 hold time, and just sent them through. Let csound sort it out. I later eliminated all the 0 duration notes with this one-liner:
            fixed_winds = np.array([row for row in fixed_winds if row[2] > 0]) 
      I'm starting to get the hang of this list comprehension business.

----------------------------------
9/18/22 To do today

✅    Make all the functions called from the dictionary much simpler. 
      Remove all tthe masks, repeats, and repeat with slight changes to downstream activities. 
            def scale_arpeggio(note_dict):
            def simple_tetrad_arpeggio(note_dict): 
            def chord_chop(note_dict):
            def triad_arpeggio(note_dict): # it's not a triad, the the simple tetrad arpeggio does everything I need
            def chord_slide(note_dict):
      See if you can't consolidate. For example, do you really need triad_arpeggio? simple tetrad arpeggio is really the same thing. And remove all the mods except flip and roll, and I'm not really fond of roll. If you want a different mode then choose a different rank and be done with it. flip is ok for scales. I finished removing as much function as I could, and placing it in simple functions or one-liners.

✅    Clean up fix_start_times so that you won't make the same mistakes again. 
      start and duration must be set to column 1, hold is not touched in column 2. 

✅    There appears to be a bug in dmu.build_scale_mask() Pass it a scale      
            The down one is complicated. I'm not thinking straight. Just take the up and flip it. easy-peasy.
            tones_1 = dmu.build_scales('oton', "16/9", "A")
      It started working correctly after I changed a few variables, but it's still wrong now. Fixed it. Wasn't updating prev_note with the previous note, retaining the first assignment. Fixed it.
      Now build_scales is broken. Sometimes it builds the scale starting at the C 1/1 at position 2. 
            array(['1/1', '10/9', '11/9', '4/3', '13/9', '14/9', '5/3', '16/9', '1/1'],
            You fool, that's because the rank passed from the dictionary is rng.choice(['A','B'])
            That's the B rank!
            Fixed.

✅    Now I'm suspicous of build_slides. It came back with array pf all four the same number. Not good.
            array([1.28571429, 1.28571429, 1.28571429, 1.28571429])
      That is to be expected moving from one mode to another inversion the same. They all move the same distance.
      Don't panic.

------------------------------
9/20/22 To do today:         

✅    I need a systematic search of all the slides to minimize the maximum distance, defined as more than 1.3 or less than 0.75
      So I completed this task, and it suggests the best pair of chords and inversions to use based on minimized movement. But then I need a way to choose the next pair of chords and inversions. 
      I was bogged down for several days with the incorrect assumption that I needed to fill out the ftable arrays for the slides with the ratios from one note to the next. I actually should have realized that what I need is the ratio from the origin, not from the previous note. Once I discovered that, everything fell into place. Sounds wonderful. And ultimately flexible.
      So I'm partially finished with this effort. I have the list of inversions that include only slides that are betwen 8/7 and 7/8. Now I want to pick the best. So I look at the sum of cents differences, and for each inversion pair the differences in sum of cents are the same. Why? Is that just the reality? or something more sinister? Since I am selecting for narrow range of potential slides already, and tossing out the outliers, I'm left with only the inversion pairs that have the smallest sum of cents. I increased the range, and started getting different sum of cent values. So I guess it's not sinister at all.
      So next I need to choose the one with the high note that is closest to the next high note. But if I look at the high notes, they are all the same for all the inversions. This makes sense, since the four notes are exactly the same. 
      The only difference is the order of the notes. But the octave can be the maker. So, basically I don't need the inversion, except that the inversion dictates the order of the notes, which in turn dictates the octave mask. I bet if I don't use the octave mask, the inversions will all be the same. Amazingly simple solution. 
      So, in the end, if I get rid of the octave mask, I no longer care about the inversion! 
      But I didn't predict that outcome when I started this process yesterday. And I now know which pair of inversions results in the lowest cent distance. And they sound super. 

✅    I'd like to be able to double up the chord_slide notes so that they cover more octaves. 
      I could call it twice, but the second time would start later. What happens now in instrument function? Basically it just returns a numpy array of features for a note. It doesn't do the start time. So I could double at some point, if I don't increase the duration values. Do it 13 times, and in the 3rd iteration, then include the durations.
      I could do it in the loop that does all the note_dictionary values. I did that. Or I could the function into the chord_slide, where note_dict['octv'] if it's an array, we iterate over it, supressing the duration to 0 until the last iteration. builde the note_dict["octv"] array as an array. If it has only one value, will it work? It does indeed. Nice. 
      assert (octv.shape[0] == repeats), f'shape of octave {octv.shape = }, must equal number of {repeats = }'
      'octv': octv, 'repeats': repeats,

------------------------------
9/21/22 - 9/22/22 To do today:     

✅    Make a function that can slide between three or more chords. Why stop at two?   
            def multiple_chord_slide(note_dict):      
      I suppose I should store each chord in an array instead of tones_1, tones_2, etc.
      So I was able to make a list comprehension out of the bridge_chords dictionary and dmu.build_chords(mode, ratio, rank)
      THe key to getting this to work is the start at the end and work your way forward. Check every step to make sure it is returning what you expect.
      
      What I ended up with: 
            array_of_chords = np.array([(dmu.build_chords(items["mode"], items["ratio"], items["rank"],1)) for items in [bridge_chords[chords][0] for chords in bridge_chords]]) # I later simplified this and made it better. 
      Start with the end:
            print(f'{[chords for chords in bridge_chords]}')   
                  [0, 1, 2, 3, 4, 5, 6, 7, 8]
      index bridge_chords with chords:
            print(f'{[bridge_chords[chords] for chords in bridge_chords]}')    
                  [{0: {'mode': 'oton', 'ratio': '16/9', 'rank': 'A'}, 1: {'mode': 'oton', 'ratio': '8/7', 'rank
      index bridge_chords[chords] with [0], since you only care about the first of two chords in the dictionary
            print(f'{[bridge_chords[chords][0] for chords in bridge_chords]}') 
                  [{'mode': 'oton', 'ratio': '16/9', 'rank': 'A'}, {'mode': 'oton', 'ratio': '8/7', 'rank': 'A'}, ...
      Step through that list of rows, where each row is a dictionary which can be indexed by ['mode'], ['ratio'], ['rank']
            print(f'\n{[(items["mode"], items["ratio"], items["rank"]) for items in [bridge_chords[chords][0] for chords in bridge_chords]]}')
                  [('oton', '16/9', 'A'), ('oton', '8/7', 'A'), 
      Now pass those items to dmu.build_chords and you get notes back
            print(f'\n{[(dmu.build_chords(items["mode"], items["ratio"], items["rank"],1)) for items in [bridge_chords[chords][0] for chords in bridge_chords]]}')
                  [array([32, 36, 40, 44]), array([192, 196, 200, 204])
      Then turn them into a numpy array that can be passed to the next function
            print(f'\n{np.array([(dmu.build_chords(items["mode"], items["ratio"], items["rank"],1)) for items in [bridge_chords[chords][0] for chords in bridge_chords]])}')
                  [[ 32  36  40  44]
                  [192 196 200 204]
                  [194 130  66   2]
                  [224 228 232 236]
                  [192 128  64   0]
                  [  0   4   8  12]
                  [204 140  76  12]
                  [206 142  78  14]
                  [ 32  36  40  44]]
            array_of_chords.shape = (9, 4)
            
      And voilà! We have the list of chords that I'd like to slide through with one ftable. Wish me luck.
      I also need the inversion for each chord, otherwise it will go all over the place.
            
            right_inversions = np.array([[2, 1, 2, 2, 1, 1, 1, 1, 2], [1, 3, 3, 3, 2, 1, 2, 2, 1], [3, 1, 1, 2, 1, 2, 3, 1, 3]])
            which_inversion = rng.integers(3)
            print(f'{which_inversion = }')
            array_of_chords = np.array([dmu.build_chords(bridge_chords[chords][0]["mode"],bridge_chords[chords][0]["ratio"], bridge_chords[chords][0]["rank"], right_inversions[which_inversion, chords]) for chords in bridge_chords])

            print(f'{array_of_chords.shape = }\n{array_of_chords = }')
            
            this shows each of the four paths through the array that minimizes the ratio distance of all the notes.
            I bet I could code up a list comprehension that would produce this. In a few hours.
            It doesn't seem to improve things beyond a random selection.
            Optimum choice one gets me to 8,054 cents. What is the maximum ratio distance in each? 
                  fl_set      max   sum of cents
                  3           1.29  8054.6
                  2           1.45  9268.4
                  1           1.29  8054.6
                  0           1.45  9268.4
            So the best route is with fl_set in (1,3) except I'm finding better ones when I run random inversions, like this one:
                 
            Wait a minute. Is the dmu.ratio_distance the actual distance or does it count on being able to take a shortcut by changing the octave? If you set find_closest=False it doesn't do that check. What does the slide building function do? I think I always prefer the shortcut regardless. It doesn't need to switch octaves during the slide obviously. It just takes the shortest distance to the next note up or down an octave.
      
      So, back to writing the multislide function
      How many slides are needed? One. How many steps in that slide if there are 9 chords?
      For example, suppose you were to build an ftable slide to cover these notes:
            [ 32 200  66 232   0   0  12  14  32]
      step      1   2   3   4   5   6   7    8
      Each step travels for each_f_step to reach the new destination and stays there for each_f_step
      So that's 8 steps of 128 time 2 each for 2048 total steps. 
      So why do we end up with 1792 steps? That's 7 * 256. Why 14? here was a bug when two notes are the same from one note to the next. I fixed it.

-----------------------------
9/23/22 To do today:

✅    Get the long slide module working. 

✅    The dmu.retrieve_gliss_tables(): now returns a 3 dimensional table. This is new. 
      Somehow I've added a dimension with the work I did for build_multiple_slides.
            print(f'{dmu.retrieve_gliss_tables().shape = }') 
      errors out with AttributeError: 'tuple' object has no attribute 'shape'
      So it's a tuple not a numpy array. 
      Track it through multiple_chord_slide:
            print(f'{stored_gliss_table.shape = }') # (0,70) 
            print(f'{current_gliss_table = }') # 800
            gliss_f_table = np.array([build_voice_slide(current_gliss_table + inx, array_of_chords.T[inx]) for inx in np.arange(voice_count)])
            current_gliss_table = current_gliss_table + voice_count
            print(f'{gliss_f_table[:,0] = }') # array([800., 801., 802., 803.])
            print(f'{gliss_f_table.shape = }') # (4, 37)
            gliss_f_table = np.concatenate((gliss_f_table, pad_gliss), axis = 1) # is this the right axis?
            print(f'{gliss_f_table.shape = }, {pad_gliss.shape = }') (4,70), (4,33)
            stored_gliss_table = np.concatenate((stored_gliss_table, gliss_f_table)) # this is a global variable.
            print(f'{stored_gliss_table.shape = }') (4,70)
            gliss = gliss_f_table[0]
            print(f'{gliss.shape = }') # (4,) <-- fixed this. it was (70,0)
      At every step it's the shape it should be: (4,70) then suddenly dmu.retrieve_gliss_tables returns a tuple of the (4,70) array and the number 804. How did that 804 get into the array?
            current_gliss_table = dmu.update_gliss_table(stored_gliss_table, current_gliss_table)
            print(f'{current_gliss_table = }') # 804
            print(f'{dmu.retrieve_gliss_tables()[1] = }') # 804 <-- what's that doing there.
      The problem was that dmu.retrieve_gliss_tables(): returns two values. I forgot that fact. 
            def retrieve_gliss_tables():
                  global stored_gliss 
                  global current_gliss_table 
                  return stored_gliss, current_gliss_table # <-- returns a tuple. Doh! Fixed it. Have to remember to always get two values from dmu.retrieve_gliss_tables()

✅    Why is there a 20 second delay before the start of the slides? 
      It was because I had not initialized the voice_start_time. Fixed it. 
      Now when I choose multiple octaves, it plays each one after than other, instead of simultaneously.
      Had to set duration to zero. That doesn't seem right. I added the code that does the automatic 0 of the first durations, so that each octave overlaps.

--------------------------
✅    I took a detour and finally figured out how to get code-server to work. 
      I now have vscode on the web on two machines, my T480 and the HP800. But I can't reach it from another machine, only on the one running code-server. Jupyter allows access. Let's see. need to set bind-addr: 0.0.0.0:8080 in /home/prent/.config/code-server/config.yaml
      That means anyone with a password can edit all my files if they get onto my network. The solutions are all very complex. See: /
            home/prent/Dropbox/Tutorials/vscode/Setting Up VScode server.txt
-------------------------------
9/24/22 To do today:

✅    Holy Cow. Now ctcsound is failing to load.
      It had an error message I haven't seen in months: (actually not since January 14: https://forum.csound.com/t/re-csnd-a-couple-of-questions-about-csound-and-python/644)                       
            OSError: libcsound64.so: cannot open shared object file: No such file or directory
            One suggestion: https://github.com/csound/ctcsound/issues/6
                  You should create a symlink to libcsound64.so.6.0 in usr/lib:
                  cd /usr/lib
                  sudo ln -s libcsound64.so.6.0 libcsound64.so

                  It's a cleaner way.

                  Then the Attribute error is due to the fact that the csoundCompileTreeAsync method didn't exist in Csound6.09.01. You should use the ctcsound.py file shipped within the apt package instead. The ctcsound.py file in the github repo is synced with the develop branch of Csound and thus it can refer to methods that don't exist in earlier versions of Csound.
            Another suggestion from Victor_Lazzarini: I think you are just missing the symlink. Some linux distros only install these with the dev packages. You could either create the symlink yourself or install csound-devel.
            Fixed it. I started the jupyter lab up before entering the toolbox csound and activate gym. Remember that step next time.

✅    Well, I have to say it sounds terrible. 
      Here's what I'm using for the inversions used across the bridge_chords in the long slide:
            right_inversions = np.array([[2, 1, 2, 2, 1, 1, 1, 1, 2], [1, 3, 3, 3, 2, 1, 2, 2, 1], [3, 1, 1, 2, 1, 2, 3, 1, 3]]) # the 3rd one is bad. Try this one: [4, 2, 1, 3, 4, 3, 4, 3] Terrible.
      I get the sneaking suspicion that it gets the wrong ratios. Keep track of the maximum movement and print it out.It sounds good for the first two chords, and then goes whack.  I need to go back to the good_slides array and see what they sound like. Perhaps it was because I did not exclude any ratios outside the range that I used for good_slides, which was that the ratio_distance had to be between 7/8 and 8/7. There are a few ways I can investigate this:
      
      a. shorten up the time of the slide from 128 steps to 0 steps and see what it sounds like. It resulted in total silence. I have to do more research. I set each_f_step to 0, and that wrecked the structure. 
      
      b. take another look at good_slides: 
            good_slides - an array of slides to use in the bridge to cycle through the bridge chords
                  values are [0] - chord number index into the dictionary bridge_chords. Points to a pair of chords.
                        [1] inversion for the starting chord 
                        [2] inversion for the ending chord  
            It's very suspicious that all the best ones had optimal times of exactly 329.9 as the sum of the absolution value of cents distance traveled. Weird. 
            I rewrote all the code and got the same answer. 
    
      c. Something is wrong when the which_inversion is zero. right_inversions[which_inversion] is screwing everythin up for some reason 
            if which_inversion == 0:
                  print (f'{right_inversions[which_inversion] = }') Fixed it.

      d. I should be tracking the distance each voice travels in total, not the sum of each chord change. I may find a difference there.
            Here is the journey that one voice took: total_f_steps = 2048.0
              This says that some voices traveled 702 at the max. That should not happen. What is going on?
            So I was able to build an array of arrays one for each inversion, but I am having trouble building voices that can take any path through that array
      
            Here they are in a nice compact array. I could try to figure out what each inversion is, but that's prone to error. 

            Here are all the inversions where all the notes have the same inversion.
      Here are some that had a cent score of 203            
      inv:    1   4    2   1   1   2   4   4   3
            [ 32 204   2 224 192   4 140 142  40]
            [ 36 192 194 228 128   8  76  78  44]
            [ 40 196 130 232  64  12  12  14  32]
            [ 44 200  66 236   0   0 204 206  36]
            inversions = 1
            [ 32 192 194 224 192   0 204 206  32]
            [ 36 196 130 228 128   4 140 142  36]
            [ 40 200  66 232  64   8  76  78  40]
            [ 44 204   2 236   0  12  12  14  44]
            inversions = 2
            [ 36 196   2 228   0   4  12  14  36]
            [ 40 200 194 232 192   8 204 206  40]
            [ 44 204 130 236 128  12 140 142  44]
            [ 32 192  66 224  64   0  76  78  32]
            inversions = 3
            [ 40 200  66 232  64   8  76  78  40]
            [ 44 204   2 236   0  12  12  14  44]
            [ 32 192 194 224 192   0 204 206  32]
            [ 36 196 130 228 128   4 140 142  36]
            inversions = 4
            [ 44 204 130 236 128  12 140 142  44]
            [ 32 192  66 224  64   0  76  78  32]
            [ 36 196   2 228   0   4  12  14  36]
            [ 40 200 194 232 192   8 204 206  40]
            best_bridge_chord_array[0]:
            inversions
               1   4   2   1   2   4   1   1   2
            [ 32 204   2 224   0  12 204 206  36]
            [ 36 192 194 228 192   0 140 142  40]
            [ 40 196 130 232 128   4  76  78  44]
            [ 44 200  66 236  64   8  12  14  32]

            These all sound terrible. Something must be wrong with my slides. Fixed it.
            voice #1: 
            
            gliss function tables:  
             +--table num
             |      +--start at 0
             |      |    +--points in table
             |      |    |        +--gen07
             |      |    |        |    +--start at 1:1, or in this case 16/9
             |      |    |        |    |    +--take 128 to reach next target
             |      |    |        |    |    |      +--target ratio. go up 9/8 to 1:1
             |      |    |        |    |    |      |                           +--target ratio. go up 9/8 to 9/8
             |      |    |        |    |    |      |                           |                           +--down 73/77 to 16/15
            [800.0, 0.0, 2048.0, -7.0, 1.0, 128.0, 1.125, 128.0, 1.125, 128.0, 1.125, 128.0, 1.125, 128.0, 0.948, 128.0, 0.948, 128.0, 0.938, 128.0, 0.938, 128.0, 0.875, 128.0, 0.875, 128.0, 1.143, 128.0, 1.143, 128.0, 1.071, 128.0, 1.071, 128.0, 1.037, 128.0, 1.037]

            I think the problem is an extra .T or a missing .T. It was the latter. It was solved on 9/27/22 by changing the ratios in the slide from relative to the previuos note to relative to the initial note. Obvious.
            
------------------
9/27/22 To do today:

✅    Find a way to combine several of the "bridge_chord_array":  rng.integers(best_bridge_chord_array.shape[0])
      When I try multiple instances that would overlap, it's not right at all. Each is wrong in its own way. Something is whack with the ratios.
      Then it occasionally comes together. This makes me think it's not picking the right notes. I created ball4.csd to test out ideas. I was able to reduce the slide duration and increase the hold durations of the slides. Now I can more clearly hear that it's not making the right notes.
      
✅    Combine over 45 seconds the note_array function and the multiple_chord_slide funtion.
      Make it so the both go through the nine chords at the same speed.

✅    Build an analog to build_scale_mask(scale): 
      Goal: find a way to ensure that the current chord is as close to the previous chord as possible.
      a. Compare all the notes and help out those below a mid-point and not those above the mid-point. 
      b. Take in two chords and build a mask for the second that makes it closer to the first. 

✅    id you know that it's imporant for the final element in the gen07 function table is the last ratio, not a duration. 
      And you can make it bigger than the size of the array and it will just truncate them. If it's too small, it will pad with zeros. 

✅    what if I ignored direction when ratio_distance was called to provide the ratio to arrive at the next note.
      What if I sometimes need to send the note in the other direction. If you were inside the code, what would you do now?
      Get out the pencil and paper and make sure the ratios are right. Now I have been able to build a csd file that simultaneously plays the chords and the slides. After a few notes, they diverge.
      I figured out the problem. I was assuming that the ratio changes were cumulative. 1.125 followed by another 1.125 would increase a second time. No. It just means it is 1.125 above the initial pitch. I need to make each ratio relative to the starting note.
      ratio_distance from the start, not the prior note. Greatly improved results, but not perfect. I need to take the ball4.csd and test every single voice. The first one is great for almost to the end, then diverges. It looks like the discrete pitches are where the mistake happens. I fixed it. Only it seems to cut off the last chord. I can add 120 more to the final duration. Didn't help.
                                 1:1         1:1        9:10       9:10        
      [800.0, 0.0, 2048.0, -7.0, 1.0, 181.0, 1.0, 60.0, 0.9, 181.0, 0.9, 60.0, 1.0125, 181.0, 1.0125, 60.0, 0.96, 181.0, 0.96, 60.0, 1.0285714, 181.0, 1.0285714, 60.0, 1.125, 181.0, 1.125, 60.0, 1.05, 181.0, 1.05, 60.0, 0.9642857, 181.0, 0.9642857, 60.0, 1.0, 181.0, 1.0, 120.0, 1.0]
      I'll just have to follow with a chord on 16/9 oton rank A. It's challenging to get the timing right. 
      I'd also like to make sure I have the best slide choices.
      Here are the choices: 

-------------------------------
To do 9/29/22:

✅    One alternative is to go back and use the methods I tried before but discarded. 
      It's just so easy to do a massive grid search and find plenty. So, now that I have fixed the multiple_chord_slide funtion I should probably go back and try the combinations that I discarded. 
      Those only sounded bad because of the bug in multiple_chord_slide. I tried a few different ways to solve the problem. Can you find where you documented those, by date? If so, you can probably recover them from Dropbox. Diamond_music_whisper_song.ipynb on 9/20 look for a line that lets through inversions that include only slides that are betwen ratios 8/7 and 7/8. Before that I was using decimal ratios, but the integer ratios were easier to handle.
            if 7/8 < decimal_ratio < 8/7: # if it's in this range, then don't add to out_of_range.
                  pass
            else:
                  out_of_range += 1
            if out_of_range == 0:
                  # save it. 
      I found the code.
      I ran a modified verion. What I had forgotten is that the ratio_distance used in the slide is always minimized compared to the initial note, not the previous note. I might not like that. First I'm going to include the logic that the slide would take, and compare what it picks that way vs what it picks minimizing the distance to the previous note. See if they agree.
      How can I determine these two amounts? Absolute cents from the origin. 
      I think I figured out a way to collect this information using absolute cents from the origin compared to the absolute cents achieved by moving to the closest ratio to each note.
      Using this method, I should elimintate the following members of best_bridge_chord_array: ([9, 15, 16, 17, 19])
      I need to eliminate the bad ones and save it as a numpy array. Done. I ran the collection routine again when the notebook crashed. Have to reset the specific ones to examine, because there is nothing wrong with those. Thankfully.
      New ones ([0, 5, 10, 14, 17, 19, 26, 32])

      Some of the ones that passed the examination also sound whack: #4 whipped back and forth. very whacky. It wasn't caught. I need to catch when two consecutive slides from initial result in large swings.
      Here is number 4 slide affecting note 36:

            size:        s     s    s    s    big     s  big    s     s   compared to previous note
            slide       1.0   0.9  .81  .84   1.44 1.35 0.78  0.84   0.8
      what it should be 1.0   0.9  .81  .84   0.72 0.67 0.78  0.84   0.8 <-- if it's a bigger move from the prev divide by 2
            note        36    204   66  236     64    8   12    14    32
            ratio       10/9  1/1  9/5  28/15  8/5  3/2  7/4   15/8 16/9 
            cents       182     0  1017 1080   813  702  968   1088  996
            What if it's a move to a very low ratio? Like 0.41 compared to the previous 0.84?
            
            Notice the big swing from 0.84 to 1.44. What characterizes that? 
            prev_cent_from_initial to current_cent_from_initial is large 
            or prev_ratio to curr_ratio is larger than 8/7 or smaller than 7/8/
            How can I capture that concept?
            Just changing ratio_distance (find_closest = False) doesn't help.
            Now I'm finding the following have the flaw: ([0, 4, 5, 6, 10, 14, 17, 19, 26, 32, ])
            What to do about it? I could fence them off, copy the good ones to a new array and be done with it. Or I could take the effort to correct the flaw and save them. Do I really need 32 separate paths through the chord changes? They all sound pretty much the same, after all, and I can't possibly use more than two or three. And I will have to do the same for the other ranks, and will end up in the same spot, perhaps. 
            I've decided to make a go of fixing them anyway. For ten minutes or so. Two hours later I still haven't a finished version. Drop it. I have used the brute force method with 1,000,000 cases and found what I needed.

✅    I ran 1,000,000 grid search and found 981 good ones. Took about ten minutes. Which one was the best? 
      I selected based on being lower than 323 cents of diversion. That's about 1 out of 1,000 random results.
      Copy the good ones to a new array and save it. Best one was 203 cents, then 266.0, 315.6. How many duplicates?
            best_bridge_chord_array.shape = (971, 4, 9)
            good_bridge_array.shape = (392, 4, 9)
            best_bridge_array.shape = (97, 4, 9)

      Plus it has the benefit of sorting them first. 
            best_bridge_array = np.unique(good_bridge_array, axis = 0)
      
      all_good = [78853, 88594, 310902, 328222, 350351, 580524, 606242, 745426, 762105, 829766, 865270]
      after duplicates, there are only 4. Out of a million. Amazing.

-----------------------------------------
10/1/22 To do today:

✅    I'll need to retrofit a bunch of code to deal with the fact that we will have ranks other than A at some point. 
      The first thing I did was create the function set_bridge_chord_rank(bridge_chord, rank) which does what it says. But it doesn't build the chord arrays. I finished it. I basically took the easy way out. But anyone who wants to use the bridge chord will specify the rank explicitly, so there is no value in set_bridge_chord_rank. I'm going to keep it around in case I find a use for it.
      
✅    I have four different collections of bridge chord arrays, loaded into four different arrays. 
      I need to fix that. I consolidated the best 19 of each rank into a single array: all_bridge_chord_arrays in file good_bridge_arrays.npy
      So now all_bridge_chord_arrays[0:19] are the arrays for each rank, each the 19 best, no duplicates.
      I've revised the notebook to be called Diamond_music_bridge_calculations and am running it on the HP800 for a while with the %%timeit magic to time the cell. 54 minutes before it died.

✅    Make sure all the note building functions work. I validated the following:
            note_array - needs dict["note_array"] - a (4,9) array of notes usually from all_bridge_chord_arrays. one octave only, no repeats - spreads the notes across the instruments provided
            chord_play - needs mode, ratio, rank, inversion, instruments, dur, hold, env, renv, repeats, defaults
                  chord play can't handle dur = 0. It mushes up all the notes at the start. Should I mask the octaves here?
                  I'm thinking no
            multiple_chord_slide - needs needs dict["note_array"] - a (4,9) array of notes, and the usual suspects, array of octaves
            chord_slide - needs mode1, mode2, root1, root2, rank1, rank2, inv_1, inv_2, gliss_type, octv indicates repeats
                  
-------------------------
10/2/22 to do today:

✅    Verify that these still work:
            scale_arpeggio. Needs "mode" "root" "rank"  "octv" "instruments" "dur" "hold" "defaults" "env" "renv"
                  "roll" "flip" "skip". These all work.
                  Each note in the scale has it's own dur and hold. Done.
                  How can I get more interesting arpeggios? Skip has some possibilities. Combine a skip 2 with another instrument with a skip 3, up or down, sounds interesting. Skipped notes are appended onto the end of the note array. That's interesting in itself. 
            tetrad_arpeggio. Needs "mode" "root" "rank" "repeats" "octv" "instruments" "dur" "hold" "defaults"
                  And we should be consistent with scale arpeggio, the dur and hold go with the notes, not the instrument.
                  Why is the result different for different instruments with the same arguments. Is there random in the function? It should be upstream in the dictionary. There is a hidden roll in there. Externalize it to the dictionary. Good. Now finish the last one root_chord_slide. Externalize everything you can. Standardize everything. Make things that are interesting.

            root_chord_slide. Needs mode, root, combo, gliss_type, instruments, dur, hold, env, renv, defaults, repeats
                  It works, but the trills sound bad. It's not the envelopes, it's the fact that I'm trying to repurpose 8 note trills as shorter trills. Need to build more gliss_types. Done.
------------------------
10/3/22 To do today:

✅    Figure out a way out of the issues with trills of 8 being cut off at 1,2,3,4,5,6,7 in a systematic manner. 
      Create individual trills just like the ones in multiple_chord_slide and build_voice_slide. 
      Make them as needed with the correct number of trills and the full duration. This avoids having to track the ratio of holds to durations. You are already doing that for the 2 and 8 step trills. Just add the other numbers. Easy-peasy.

      To start you need to look at the existing trills. build_slides - how does he know what to build for an 8 note trill?
      He calls make_ftable_glissando using a list comprehension:
            gliss_f_table = np.array([make_ftable_glissando(start_table + i, gliss_type, ratio_distance(all_ratio_strings[a],all_ratio_strings[b])) for i, (a, b) in enumerate(zip(chord_1, chord_2))])
      Somehow only five peaks are in the csound log, and in the ftables sent to csound. Csound wouldn't pick the wrong tables. So somehow build slides has the right ftables, but what makes is to csound is the wrong ftable. 
      New symptom. When I set it to trill_4_step, I get 8 steps. When I set it to 8 steps I get 6 steps. 
      I fingered it out. My routine that actually sent ftables to csound was only sending the first 41 items in the array, and not the whole thing. Padding is not a problem for csound. Except when it is. He tries to slide to zero Hz. Changed it to pad with ones. That seems to be ok. I was able to get all the legal slides and trills to work. I wonder about cubic polynomials.
      
      We still have the issue of ftable proliferation. You may need some occasional garbage collection to eliminate duplicates. 

✅    Could I make some slides out of cubic polynomials? Yes I can. And have a variable approach timing to the high note.
      Here are all the slides that are legal:
       if gliss_type == 'slide':
            fn_array = np.array([t_num, 0, 256, -7, 1, 64, 1, 64, ratio, 128, ratio])
      'cubic16_16_224':
            fn_array = np.array([t_num, 0, 256, -6, 1, 16, np.average((1, ratio)), 16, ratio, 224, ratio])
      'cubic32_32_192':
            fn_array = np.array([t_num, 0, 256, -6, 1, 32, np.average((1, ratio)), 32, ratio, 192, ratio])
      'cubic64_64_128':
            fn_array = np.array([t_num, 0, 256, -6, 1, 64, np.average((1, ratio)), 64, ratio, 128, ratio])
      'cubic96_96_64':
            fn_array = np.array([t_num, 0, 256, -6, 1, 96, np.average((1, ratio)), 96, ratio, 64, ratio])
      'trill_1_step':
            fn_array = np.array([t_num, 0, 32, -7, 1, 16, 1, 0, ratio, 16, ratio])
      'trill_2_step':
            fn_array = np.array([t_num, 0, 64, -7, 1, 16, 1, 0, ratio, 16, ratio, 0, 1, 16, 1, 0, ratio, 16, ratio])
      'trill_3_step':
            fn_array = np.array([t_num, 0, 64, -7, 1, 13, 1, 0, ratio, 13, ratio, 0, 1, 13, 1, 0, ratio, 13, ratio, 0, 1, 12, 1])
      'trill_4_step':
            fn_array = np.array([t_num, 0, 128, -7, 1, 16, 1, 0, ratio, 16, ratio, 0, 1, 16, 1, 0, ratio, 16, ratio, 0, 1, 16, 1, 0, ratio, 16, ratio, 0, 1, 16, 1, 0, ratio, 16, ratio])
      'trill_6_step':
            fn_array = np.array([t_num, 0, 256, -7, 1, 21, 1, 0, ratio, 21, ratio, 0, 1, 22, 1, 0, ratio, 21, ratio, 0, 1, 21, 1, 0, ratio, 22, ratio, 0, 1, 21, 1, 0, ratio, 21, ratio, 0, 1, 22, 1, 0, ratio, 21, ratio, 0, 1, 21, 1, 0, ratio, 22, ratio]) 
      'trill_8_step':
            fn_array = np.array([t_num, 0, 256, -7, 1, 16, 1, 0, ratio, 16, ratio, 0, 1, 16, 1, 0, ratio, 16, ratio, 0, 1, 16, 1, 0, ratio, 16, ratio, 0, 1, 16, 1, 0, ratio, 16, ratio, 0, 1, 16, 1, 0, ratio, 16, ratio, 0, 1, 16, 1, 0, ratio, 16, ratio, 0, 1, 16, 1, 0, ratio, 16, ratio, 0, 1, 16, 1, 0, ratio, 16, ratio])
      
      I'm really liking the cubic96_96_64. It kind of hides the end until the end.

✅    We need some alterations to make after going from note_dict to winds before going to csound. 
      I'd like to repeat but with subtle changes each time. Then flip, repeat, tile, roll.
      Extend notes with longer durations.
      Hold every n note for much longer duration
      mix_mask = rng.choice(2, size=(instruments.shape[0]), p = [1 - note_dict["density"], note_dict["density"]])
      hold[inst] * mix_mask[iterations]

----------------------------
10/4/22 To do today:

✅    Work on some of the alterations
      - extend - add an arbitrary amount to the hold values of a certain percentage of notes. 
            for example: extend(note_array, density, duration), extend(note_array, 0.1, 3) multiply 10% of the notes hold value by 1,2, or 3 spread evenly over the numbers.
            How to do that: 
                  dur_mask = rng.integers(low = min_dur, high = max_dur, size = (note_array.shape[0]), endpoint = True, dtype = int) 
                  note_array[:,1] = note_array[:,1] * dur_mask
                  winds = extend(winds, 1,  3) # create a mask of 1's 2's and 3's, multiply it by the duration column of note_array
            The problem with this is that the start times get messed up. Each instrument is it's own duration. What can I do about that?
                  Periodically reset all the start times to the lowest of all the instruments. Throw away notes.
                  This will get it done:
                        print(f'{reset_voice_time(np.min(([voice_time[voice]["start"] for voice in voice_time])))}')
✅    masked - standard masking of hold values to erase notes
            masked(note_array, density)
                  mix_mask = rng.choice(np.arange(2), size=(note_array.shape[0]), p = [1 - density, density], dtype = int) 
                  note_array[:,2] = note_array[:,2] * mix_mask # multiply by some zeros and the rest ones to erase a percent of the notes
✅    flip - this is a one liner, but it doesn't seem to match what you would expect. 
                  winds = np.flip(winds, axis = 0) # or concatenate the flipped onto the end
                  winds = np.concatenate((winds, np.flip(winds, axis = 0)), axis = 0)
✅    repeat - another one liner, but since extend messes with the timing, it doesn't sound like a repeat
                  remember that it just repeats every note this many times. It's not like a tile.
✅    tile - this is another kettle of fish. it turns a (80,15) array into (80,120) and there is no axis argument.
            But you can pass the number of repetitions as a tuple. e.g. np.tile(winds, (4, 1))
            Done. Very nice way to extend, and even though the extend messes with the timing, that just gives it character. 
✅     roll - I don't think we need that. 

✅    How to use list comprehension to print some of the rows in a note array (like winds) 
      Without using f strings which aren't legal inside a list comprehension:

      +-- print
      |     +--unpack the list
      |     |  +--What you want to see
      |     |  |                                               +--Which rows you want to see
      print(*[[round(item,2) for item in row] for row in winds[:5,:]], sep='\n')

-----------------------------
10/5/22 To do today:

✅    Find a way to modify the mask over time. Not just an integer but a function with a shape. Do that for all the variables.
            I'm struggling to find the equivalent of GEN06 in numpy. I found something useable in make_interp_spline
                  from scipy.interpolate import make_interp_spline
                  x = np.arange(10) # number of point
                  y = np.array([0.5, 0.52, 0.56, 0.6, 0.65, 0.70, 0.85, 0.85, 0.9, 0.8])
                  spline = make_interp_spline(x, y)
            This only works if the length of x and y are the same. The following works with any number of points. But it starts increasing too soon. 
                                 +--n, 15 array
                                 |      +--function
                                 |      |       +--range of values
                                 |      |       |         +--start -with the lowest probability you would find acceptable
                                 |      |       |         |     +--end the tanh of the range - 90%
                                 |      |       |         |     |     +--step size divided by the size of the array
                                 |      |       |         |     |     |             
                  winds = masked(winds, np.tanh(np.arange(0.45, 1.3, (1.3 - 0.45) / winds.shape[0])))
            Assume a function with the same number of points as the number of notes in winds. Each probability will be distinct for every note. I could draw samples from a wide variety of different distributions. Not relevant. 
      Got it done with tanh function, more and more likely to be heard over the course of the set of notes. I'd like to also determine the right function for growing and shrinking, and shrinking. 

✅    chord_play - needs mode, ratio, rank, inversion, instruments, dur, hold, env, renv, repeats, defaults
                  chord play can't handle dur = 0. It mushes up all the notes at the start. Should I mask the octaves here?
                  I'm thinking no.

------------------------------------------
10/6/22 To do Today:

✅    Extend the idea of density_function to more functions, and more variables. 
      - Draw your own and interpolate is the most flexible. Created build_density_function(y, points):
      - volume changes across long time periods
      - density across multiple time scales 

✅    Use some of the techniques previously exploited in Balloon_Drum_Music.ipynb to have more notes happening at the same time.
      The order of these matters a lot. 

      - make each note last longer: tile_time_steps is random from 3 to some arbitray high value (13)
            chorale = np.repeat(chorale, tile_time_steps, axis = 1) 
      - make every voice twice as many: 
            chorale = np.repeat(chorale, voices / chorale.shape[0], axis = 0) # make 4 times as many voices
      - Take what you have created then stretch out the octaves. 
            stretch.octave_shift(percent_up, duration_up, octave_size)
      - apply a mask after these actions:
            chorale = stretch.arpeggiate(chorale, mask, 1, bass_bump = False) 
      - Copy some section of notes and repeat it to slow it down.
            slow_end = np.repeat(chorale[:,slow_time_steps:], slot_repeat, axis = 1) 
            chorale = np.concatenate((chorale, slow_end), axis = 1)
      - pick different tempos for each section
            new_tempo = min(rng.integers(assigned_tempo_minimum, high = assigned_tempo_maximum, size = None), current_elapsed * 5)

--------------------------------------
10/7/22 To do today:

✅    Looking back at the previous notebook called Balloon_Drum_Music.ipynb. A lot to learn from it. 
      It really didn't do very much at all. It had a verse and a bridge. The verse was made by build_chords, which created a tetrad from the rank, mode, and keys 8 note scale with each of the four inversions. The bridge created tetrads using the same technique. It then made notes last longer using repeat axis = 1, made more voices with repeat axis = 0, stretched out the octaves up and down a percentage of the notes, masked the array to poke holes in it, then copied some sections to slow down the beginning and ending. It picked different tempos for each of 17 sections, with a gap between each. The tempo was controlled using the t0 tempo time statement. Note that the format is:
            start-time_1 tempo_1 end-time_1 tempo_1 start_time_2 tempo_2 end_time_2 tempo_2 start_time_3
            0              97       120       97          120         96    257      96        257
            start_time_2 = end_time_1, tempo is stated at the start and end of a segment, otherwise it accelarando or ritardando to the destination time.
              +--from time 0
              | +--set tempo to 97 beats per minute
              | |  +--until time 120 - first section had 120 seconds 
              | |  |     +--tempo still at 97 bpm
              | |  |     |  +--time 120
              | |  |     |  |     +--tempo 96
              | |  |     |  |     |  +--until time 257 then 102, till 367, then 108 till 290, then 91 till 426 etc.
            t 0 97 120.0 97 120.0 96 257.0 96 257.0 102 367.0 102 367.0 108 390.0 108 390.0 91 426.0 91 426.0 96 452.0 96 452.0 101 506.0 101 506.0 93 532.0 93 532.0 90 627.0 90 627.0 108 675.0 108 675.0 101 764.0 101 764.0 94 794.0 94 794.0 99 862.0 99 862.0 93 922.0 93 922.0 97 970.0 97 970.0 104 1040.0 104 1040.0 92 1088.0 92 1088.0 92
      One other thing it did was vary the tempo in several different ways. The T statement was one, from 90 to 110, the other was the tile_time_steps value, which dictates how much longer each note was: 3 to 13 times as long.
      It also varied the instrumentation by creating instrument collections to change the timbres. 

✅    I've been thinking about a way to simply limit the proliferation of glissandi. 
      After you have created one, do a search of all the previous glissandi and 
            if (current[1:] == previous[1:]).all() This didn't work. 
      then you have already created one. It's a bit more complicated. First obstacle was how to test if they are equal. There appears to be some rounding going on behind the scenes. Nothing big, but they fail the equality test.
            if np.allclose(stored_fn_array[1:gliss.shape[0]], gliss[1:gliss.shape[0]]): This works. 
      Now that you found the one that is a repeat, you have to avoid storing it, and save the pointer to the existing one.
      This is going to take another day to get finished.
-------------------------------
10/8/22 To do today:

✅    Finish the build_slides function in diamond_music_utils.py.
      - I've found the ones that don't need to be stored because they are already in the list. I need to return their numbers to the caller, but don't store them. Save up the numbers. 
            Got it done. It sounds amazing when combined with the stacatto horns.
            Now to clean up the print statements.     

✅    Getting new message in csound: WARNING: Division by zero            
      for every 0 hold note. instr 1:  p2 = 20.600  p3 = 0.000  p5 = 32.000  p10 = 799.000
      I should probably not send them to csound.
      Fixed it with one line:
            fixed_winds = np.array([row for row in fixed_winds if row[2] > 0])

---------------
10/9/22 To do today:

✅   Add more instruments to voice_time
            voice_time = {'fpn': {'full_name': 'finger piano', 'start': 0, 'number': 1},
            'bnp': {'full_name': 'bass finger piano #2', 'start': 0, 'number': 12},
            'bdl': {'full_name': 'bass balloon drum', 'start': 0, 'number': 3},
            'bdm': {'full_name': 'medium balloon drum', 'start': 0, 'number': 4},
            'bdh': {'full_name': 'high balloon drum', 'start': 0, 'number': 5},
            'bfl': {'full_name': 'bass flute', 'start': 0, 'number': 6},
            'obo': {'full_name': 'oboe', 'start': 0, 'number': 7},
            'cla': {'full_name': 'clarinet', 'start': 0, 'number': 8},
            'bss': {'full_name': 'bassoon', 'start': 0, 'number': 9},
            'frn': {'full_name': 'french horn', 'start': 0, 'number': 10},
            'fp2': {'full_name': 'finger piano #2', 'start': 0, 'number': 11},
            'bd2': {'full_name': 'bass balloon drum #2', 'start': 0, 'number': 13},
            'bd3': {'full_name': 'medium balloon drum #3', 'start': 0, 'number': 14},
            'bf2': {'full_name': 'bass flute #2', 'start': 0, 'number': 15}}

✅    Find a way to include several different dictionaries simultaneously. 
      In other words, call different functions with different dictionaries. Make it so there is not just one note_dict, but many.
      Make calling functions easier with the different note_dicts.

✅    So I built a new note_dict which has all the previous note_dict values. 
      But some of the functions need variables assigned before being called. For example multiple_chord_slide needs:
            rank = 'D'
            chord_choice = 3
      Got rid of that requirement. If I need to set a variable I can alter the master dictionary or set one variable with:
            note_dict[function_name][ind]["repeats"] = 5 # modify the note_dict by specifying the key and the new value 
      And each needs a different octv, some need an array and others just a value. multiple_chord_slide needs an array, and chord_play needs a single value, but it can accept an array. I made sure that all could accept octv as an array. I really should make it so if there are more than one octave it covers all octaves included. So I updated note_array to recognize all the octaves, but it plays them sequentially. How can I change that? Just live with it. And remember it.

✅   One concern to be handled is that you need to frequently execute the cell with the definition of the dictionary.  
      It stores the location of the function, not it's name. If python creates another function, the dictionary is still pointing at the old version, even though you have subsequently made revisions to the function. Even if you make substantive changes to the variables, like dur and hold in the cell that calls the dictionary functions, the changes are ignored. That's weird. 
      
✅   I'm thinking I may need to reorganize the dictionary to change a few things. 
      Get rid of the "exec" since it's already there in another form. But it's really not. I need one that is a string with the name of the funciton, and another that is the actual function. They are not the same. No can do. I tried and failed. Trust me on this one.
      

----------------------
10/10/22 To do today:

1.    I could also build my own envelopes and send those to ctcsound

2.    Maybe I could make room in the master note_dict for some variables that can apply to future invocations of the function. 
      Perhaps for rank, chord_choice, and octv. Later.
      
3.    Get serious about drastically lowering the amount of choices that need to be made for each note. Some ideas:
      a. Take a look at note_dict and see what can be remembered from one call to another.
      b. Use csound's built in . value to use the previous notes arguments.
      c. Build a different structure that looks more like my Pascal samples program input. 
      d. Don't change the structure, but find a way to automate the building of note_dict structures.      
      Is there some way to limit the number of arguments passed so that defaults can be set and forgotten? 
      At this point 3/4 of the function lines are dedicated to assignment statements. I hid the problem in an dictionary and an array of default values.

4.    At some point I'll need to explore the ranks E, F, G, & H. They are in the scales and inversions dictionaries
      
✅   Set a strategy for the overall structure of the piece like I did with the last balloon drum music piece. 
      That one was a set of 17 short pieces going through each of the four ranks four times, ending with the beginning as number 17. Each piece was aproximately 17 to 90 seconds in length. I varied the tempo so that the one with more notes was faster, and the one with fewer notes was slower, in a range of values, so that the length varied as well as the tempo. 
      Each of the 17 pieces had a verse and bridge of varying lengths.

✅    What do I want for this one? 
      Same or different? Think of the chord changes of Balloon Drum Music and the vibe of Whisper Song. I plan to start with a vamp of finger pianos, balloon drums, and maybe staccatto bassoon. Start with tetrad_arpeggio, masked and extended with interesting trends in mask density, repeat quantity that changes over the course of the winds array, and other factors that change as we move through the winds array.  Use the same combination of length extension and t0 tempo alteration. Once that is established, add bass flute trills and slides, then later add the woodwinds like an R&B horn section. Then, see what you have and make some additions. 

            for ind in note_dict:
                  winds = np.concatenate((winds, note_dict[ind]["exec"](note_dict[ind])), axis = 0)
                  print(f'Instrument {ind}: {voice_time[note_dict[ind]["instruments"][0]]["full_name"]}')
            winds = extend(winds, 1, 6) # messes up the voice_time array. Periodically reset it to 
            # new_start = np.min(([voice_time[voice]["start"] for voice in voice_time])) # reset all start times
            density_function = build_density_function(np.array([0.75, 0.45, 0.6, 0.8, 0.7, 0.9, 0.7]), winds.shape[0])
            winds = masked(winds, density_function)
            winds = np.tile(winds, (15,1)) # repeat the first dimension by 4, and the second dimension remains as is. Neat. Tile the reduced density version
            fixed_winds = fix_start_times(winds) # fix the start times for each note.

✅    Tetrad_arpeggio is seriously malfunctioning. I fixed it, but may have broken other functions.
      I will need to know which ones accept arrays vs integers. 
      - I need to figure out how I use octaves in tetrad_arpeggios. I used to pick rng.choice([2,3,4,5]) with different ranges for each instrument. One octave value would then go to the note generating function. Now is sequentially plays the octaves set in the calling cell of the notebook. 
      - It's playing woodwinds - the chords that end the multiple_chord_slide note generating fuction instead of the tetrad_arpeggio
      - The problem was that I was sending fixed_winds to csound, but I had not bothered to set fixed_winds to the output of the tetrad_arpeggio. I must call fixed_winds = fix_start_times(winds)
      - dur and hold were not set in the calling cell of the notebook.
      - there needs to be as many dur and hold as there are notes vertically: which is 4 - that's not true for tetrad_arpeggio.
      - There is another problem. The repeat just repeats the note, because it doesn't assume that two notes in a row is the same note held for a longer time. The old function that took an array and made a pfield with it would combine notes that were the same to make a longer held note, which I could then mess with using masks. If I could extend times and still make sure to extend all the instruments at the exact same amount of time, them I might have something. Here is what it is now:
            def extend(note_array, min_dur, max_dur):
                  dur_mask = rng.integers(low = min_dur, high = max_dur, size = (note_array.shape[0]), endpoint = True, dtype = int) 
                  note_array[:,1] = note_array[:,1] * dur_mask # increase the dur time of some notes by some factor
                  return note_array
            You need to keep track of the additions that are made to each voice in the array. 
            The duration is element 1, the voice is element 6. <--- I keep forgetting this.
            I am back to the durations not being equal across the voices. This is because I've masked some notes away. They had a duration, and I got rid of the note, so that duration was lost. Before the mask, the total duration by voice was equal. 
            This new structure has lots of side effects that I did not have with the prior algorithms. 
            What if I masked after I converted to fixed_winds? That works. 
            When should I do the extend? 
            The problem is all due to the change from the old algorithm to the new one.
            Previously, each note was a 1/16 note, so I never had to keep track of durations, hold, etc. If a note was repeated, then it was assumed that the repeat just increased the duration. If it started and stopped, then it would sound twice. The arrays were just voices and notes. Now, the arrays are just time_steps and features. If one has it's is erased, that duration is lost forever. Mask sets hold to zero, and when we get to send it to csound, it is not sent. How else should I handle it? fix_start time does not process rows with zero holds. It does now. I fixed it. There may be unintended consequences...

      Let's see how I can use the new structure to my advantage. I won't be able to increase the note duration by repeating notes. Nor will I be able to increase the density by just doubling the voices. But I can by extend(winds, 1, 6), even though it leaves the instruments ending at different times. I could work on that aspect. 
      
      Here's what I have so far for post-processing the output of the note generating function tetrad_arpeggio:
            tile_voices = 12
            winds = np.tile(winds, (tile_voices,1)) 
            extend_max = 12
            winds = extend(winds, 1, extend_max)
            fixed_winds = fix_start_times(winds)
            density_function = build_density_function(np.array([0.95, 0.5, 0.8, 0.7, 0.9, 0.7]), fixed_winds.shape[0])
            fixed_winds = masked(fixed_winds, density_function)
            # last note starts at 147 seconds with each dur 0.20 seconds each. But it's way too sparse. 
      So I thought I could add new instruments by just naming the same voice a different thing in voice_time, but it just sets the timing based on the instrument number, not the voice_time key 3 letter name. Could I change that somehow?
      fix_start_times searches through the voice_time dictionary for a voice with the same number. Can't do that. 
      What I need is some way to increase the density easily. With the old algorithm I'd do that by just doubling up the voices and sending different streams to each voice later in the process. 
      What can I do after fix_start_times to double up things? Does that make a difference? Or is it too late? I think it is.
      Doubling up works if you have different masks for each of the doubled voices. 
-----------------------------------
10/11/22 To do today:

✅    I have two critical issues that I need to deal with:
      a.    I can't use the same voice more than once. fix_start_times assumes all use of a voice number is for the same instrument, correctly, but that makes it impossible to use that instrument in more than one place, or more than one note generating function.
      b.    The kinds of altering functions that I used before will not work with the time_step, features architecture. I'll need a different set of modification functions, at different places than the old system of voices, note_numbers.

✅    Just for grins, what if tetrad_arpeggio's sparseness is solved by other note generating functions?      
      The problem is that I'm left with only one tool to increase density, and that is to set hold to zero and follow it with lots of other notes with hold 0, followed by one with a non-zero hold value. That requires a large number of note generating functions, or repeatedly calling the functions. And that can quickly overwhelm ctcsound with too many notes.
      I'm no more closer to my solution than I was yesterday. 

      Remember what you have: The output of the note generating functions is just a set of notes with durations and holds, n notes with 15 features. You can rearrange it in any way you want, then send it through fix_start_duration and it will then assume start times instead of durations. You can repeat those notes with all their features as many times as you want. You can also modify what is created by altering the dictionary values and creating a different set of notes. Example: change the inversion of a chord four times and you have four chords in a row. This creates repetition with subtle differences. This also removes the requirement to have multiple dictionary entries, the keys: 0, 1, 2, 3 in each note generating function name. You can create as many different ones as you want by looping and changing dictionary values. I think this is the next thing to try.

✅    I'm finding lots of issues as I go through this exploration:
      -     Why only one note sounds while I see four
      -     Why when I go through the dictionary loop with np.arange(2) it only does it once? 
            After the 0:
                  ind = 0
                  note_dict[function_name][dictionary_key]["exec"](note_dict[function_name][dictionary_key]) = array([], shape=(0, 15), dtype=float64), winds.shape = (0, 15)
            It goes to (5,15) after the 1st iteration. It's because during the 0th iteration, 'repeats' = ind and ind = 0. It's just doing what you told it to do.
      -     Why is the octave 2,2,4,5,6 when I set it to np.array([2,3,4,5]). What happens to octv in chord_play? 
            dmu.build_scale_mask is called, which should be handled by the inversion. Each instrument gets an octave in turn.
            the 2 is duplicated because there are only 4 notes and 5 instruments, we duplicate the note at the end of the array, and sort puts it on top. What happens to dur and hold in chord_play? 
      -     finding issues with tetrad_arpeggio. Same kind of problems with repeated notes. 
            It sends back four notes for each instrument. I didn't tell it to do that. Four notes spread across four instruments. 
            each playing one note four times with the same start time. It's not advancing the instrument. It actually was, but when I sorted the fixed_winds.sort it did not preserve the order of the features.
            What I want is each instrument plays all four notes and stop. But it plays four more at the end when there are five instruments. Notice that the ones at the end are all voice #3. Of the four voices I used, what were their numbers?
            
                  print(f'{[(inst, voice_time[inst]["number"]) for inst in percussion]}')
                        [('fpn', 1), ('bnp', 12), ('bdl', 3), ('bdm', 4), ('bdl', 3)]
                                                     ^                       ^               
            Both "bdl" and "bdl" have the same number 3. Obviously. I meant to use bdh instead of bdl again.

✅    Get back to the critical issues above in #1 about using instruments more than once.
      But first make sure extend doesn't create unequal endings. The strategy I'm using will get them close, I'll need one more step to get them exactly equal. I would be easier to do this if we had already gone through fix_start_duration, because then I could look at the start times higher than a certain number and be done with it. In winds we only have durations, not start times. 

4.    Ponder this: What if instead of an array of notes with features (n,15) I kept the instruments separate. 
      If I have ten instruments in the csound file, I would have (v, n, 15) to store the notes according to voice. Just wanted to write it down before I evalute this idea.

✅    I thought it would be useful to purposely make extend() calculate an even distribution of extensions.
      Make sure the new hold times across all voices are exactly equal. Is that possible? It kind of doesn't matter. Both will be approximate and you will need to fine tune the final duration to the millisecond or end up with a mess you can't track down. I finished extend so this is no longer a problem. But I've since made some rather drastic changes in structure that may eliminate the requirement.

------------------------------
10/12/22 To do today:

✅    Make a decision about how to deal with the limitations of the (note, features) structure compared to the (voices, notes) structure.
      Can I keep both? Should I. What are the advantages and disadvantages of each.
      Advantages:
            (note, features) - I could begin to explore the literature and tooling (DART) for time-series deep learning techniques.
                  - It makes it easy to preserve the linkage between the notes and the glissandi. 
                  - 
            (voices, notes) - I already know that I can do great things with this.
      Disadvantages:
            (note, features) - I'm having trouble creating interesting music with it. I need to fix the use of the same instrument more than once to see if I can't fix the sparseness challenge. 
            (voices, notes)  - 

✅    Fix the ability to have more than one of each instrument. 
      Start with when the instrument is assigned. By the time it gets to send_to_csound_file it's already done for. 
      fix_start_times is where I need to work. He calls voice_name = show_voice_time_short_name(note[6])
      to get a three letter name from the voice number in the winds array. 
      What if there are multiple voice names for each one voice number, which there are. That was supposed to be my workaround for using the same instrument in different places. 
      Maybe if I had a unique number for each voice name. It could look up that number and then assign a different 3 letter name for each. But then csound would not recognize that unique number. 

      voice_time = {"fpn": {"full_name": "finger piano", "start": 0, "number": 1},
            
      I think I figured it out. I need one number for csound and another number for fix_start_times

      voice_time = {"fpn": {"full_name": "finger piano", "start": 0, "csound_voice": 1, "time_tracker_number": 0},
                  "bnp": {"full_name": "bass finger piano", "start": 0, "csound_voice": 2, "time_tracker_number": 1},
                  "bdl": {"full_name": "bass balloon drum", "start": 0, "csound_voice": 3, "time_tracker_number": 2},
      Now go back to show_voice_time_short_name and search the time_tracker_number for the one to use in voice_time,
      and put the csound_voice number in the fixed_winds array. 
      I also need to update the function instrument. Done. 
      Just to document the process:
      1. Add a new instrument to voice_time like this: csound_voice is the voice in the csd file, time tracker is sequential from 0
            "bf2": {"full_name": "bass flute #2", "start": 0, "csound_voice": 6, "time_tracker_number": 13},
      2. Use the new name. "bf2". instruments will translate that into a tracker number and put that in the voice field of winds 
      3. fix_start_times will use show_voice_time_short_name(time_tracker_number) to get back the 3 letter instrument name "bf2" and the csound_voice number. It will keep track of the proper start time for the time_tracker_number, and place the csound_voice number in the fixed_winds array.
      4. send_to_csound_file will send the fixed_winds to csound, which will process the voice number correctly.

3.    This fix is not scalable for increasing the density. 
      I need a way to double, triple, or 16x times the number of voices. 
      I once did 256 voices in an orchestra. It was slow, but the sound was pretty good. But anyway, I'm not going to create a 300 entry dictionary, although I'm certain that python could handle it. What if instead of immediately sending the notes off to instrument to make a (notes, features) structure, I instead did some tiling and repeating. How would that work? Each note generating function calls instruments. Instead, make a note generating function that doesn't do that. It just builds a (4, n) structure from build_chords

✅    Instead of generating the optimum bridge chords, do it for the verse chords
      Create the optimum set of chords and inversions staying in ranks A & B, or B & C, or C & D, or D & A in one root key. 
      What I did before was choose a single chord from the four inversions, then tile it. 
      At some point I found these:
            best_rank_inversion_combos = np.array([["A", "A", 1, 2],["A", "A", 1, 4],["A", "A", 2, 1],["A", "A", 2, 3],["A", "A", 3, 2],
                  ["A", "A", 3, 4],["A", "A", 4, 1],["A", "A", 4, 3],["A", "B", 1, 1],["A", "B", 1, 4],["A", "B", 2, 1],["A", "B", 2, 2],
                  
            I basically wrote code that would generate this structure again, and got exactly the same results. Go figure. Past me wasn't any stupider than current me. I refined it so it now can function as a note generating function that builds (4,11) array of a path for the verse portion of the piece.
                  path = build_note_array(0) # 0 is the rank combination 'A', 'B', three others are also available.
                  verse_array = np.array([dmu.build_chords("oton", "16/9", rank, inversion) for (rank, _, inversion, _, cents) in  path])
------------------
10/13/22 To do today:

✅    Consider an additional layer of structure that would solve the problems I'm now facing. 

      Start with (voice, note). This can expand in both directions, keeping the two dimensional structure. Repeat horizontally and vertically an arbitrary number of times to create the necessary density. This is the note generation phase. No frills. I made 
            def densify_note_array(note_array, tile_time_steps, voices):
            It does this:
                  note_array = np.repeat(note_array, tile_time_steps, axis = 1)
      to generate notes. You pass it some chord changes and it returns a piano roll format (voices, notes). What if tile_time_steps was an array? tile_time_steps can be an array of integers broadcasted to fit the shape of the axis. What does that mean? Has to be the same size as the note_array.shape[1], since it's based on axis = 1. 
            time_array = np.ones(tones.shape[1], dtype = int) * 3

      The next step chooses what to do to the (voice, note) structure to create the (notes, features) structure. This step does not do note generation, just transformation.
      - gliss and trills
      - assign duration and hold
      - envelopes 
      - voice selection - perhaps just a general choice. Later be specific.
      . Each of those assignments will need significant considerations 

      Once that is done, then transform the durations into start times for csound.

✅    But first, finish the search for low-cent-distance chords in the A & B ranks for the verse section. 
      Then proceed to the same with the B & C, C & D, D & A ranks.      
      Why am I not comparing [316.0, 'A', 'A', 2, 4]? What is different about chord1 inversion 2 and chord2 inversion 4
      same problem with 'A', 'B'
            [316.0, 'A', 'A', 2, 3]
            [498.0, 'A', 'A', 3, 1]
      That's because I was only printing those that had less than 500 total cumulative cents. Duh!
      And some are double counted:
            [267.0, 'A', 'A', 3, 4]
            [498.0, 'A', 'A', 3, 4]
      That was because you had the append command inside the loop that accumulated the values. Duh!
      At the end I got it to work, and just created the same list that I already had in best_rank_inversion_combos. 
      Now I need to build a (4,n) array of a good path through the rank A & B. Completed this task.

-------------------------
10/14/22 To do today

✅    I'm going to have to get rid of all the note generating functions that do not include glissandi or trills. 
      They all send notes to instrument way too soon. And make it possible to increase the notes through repeats and tiles.
            chorale = np.repeat(chorale, tile_time_steps, axis = 1) # make each note x times longer
            chorale = np.repeat(chorale, voices / chorale.shape[0], axis = 0) # make 4 times as many voices
      I will need to alter note_array to combine multples of the same note notes into one note of the total duration and hold. So that implies 
      Make a break: You no longer need an instrument for every voice. Voices can double, triple, 100x the number of instruments 

✅    So the agreed structure is:

      a. note generating functions build lists of 4 voice note lists (4,1), (4,2), (4,9) to (4,14) which are optimum paths for the verse and bridge. These can be masked here or later. 
            # Verse note generator:
                  path = build_note_array(0) # 0 is the rank combination ('A', 'B'). Others are also available.
                  verse_array = np.array([dmu.build_chords("oton", "16/9", rank, inversion) for (rank, _, inversion, _, cents) in path]) # returns (4,11) or more
            # Bridge generator
                  array_of_chords = all_bridge_chord_arrays[rank][chosen_array] # returns (4,9) array
            all_bridge_chord_arrays.shape = (4, 19, 4, 9) where the dimensions are rank, 19 different choices in that rank, 4 voices and 9 notes

      b. Functions that extend that (voice, notes) list to additional voices and notes:
                  def densify_note_array(note_array, tile_time_steps, voices):
            tile_time_steps can be an integer or an array of shape[0] = note_array.shape[1]
            The functions return (voice, notes) but with greater vertical and horizontal size
            This set also includes those that mask, and those that augment durations.
                  def masked(note_array, density_function): set some hold values to zero. zero holds are later discarded
                  def extend(note_array, min_dur, max_dur): increase some durations by a factor 
      
      c. Functions that can return an array of octaves one for each note in the (voice, notes) array. See if you can group similar octaves in clumps. You want to have a melody stay in the same range for a while before shifting. I tried doing that previously, and the mask usually wiped out the visibility of that capability. 
            percent = 0.5
            clump = 10
            my_octave_shift = octave_shift(verse_array, percent, clump, distance = 1)
            for inx in np.arange(3):
                  my_octave_shift = my_octave_shift + octave_shift(verse_array, percent, clump, distance = 1)
            my_octave_shift += 1

Two paths with one for the straight notes and the other for those with glissandi.

Path #1: note_array path
      d. Function that combines the duration values of identical adjacent notes and replace them with one note with duration equal to the sum of the duration value of the identical adjacent notes. But you don't know the duration yet. Assume .25 second, and later on create a csound tempo t0 statement to convert it to whatever you want. Assign duration, hold, instruments, envelopes, stereo, and volumes to notes.
      # 0       1   2     3     4     5     6   7    8    9     10    11   12     13     14
      # Ins   Sta  Dur   Vel   Ton   Oct  Voi  Ste  En1  Gls    Ups  Ren  2gl    3gl    Vol
            def piano_roll_to_notes_features(note_dict): 
                  return (notes, features)

Path #2: glissando path
      e. Functions that take (voice, notes) and return (notes, features)
            These can take any number of voices and notes. Short or long. They can calculate gliss values.
            They need to take in dur, hold, plus the octave array with one second (or more) for each note times the tile_time_steps.
            They will need to keep track of the glissandi that are generated.
            Assign instruments, envelopes, & volumes. Return (notes, features).
            Examples:
                  def chord_slide(note_dict): This will need some pruning. Make it take in a (voices, notes) array instead of a dictionary. Get rid of all the superfluous add-ons. 
                  def root_chord_slide(note_dict): I can dump this one completely 
                  def scale_arpeggio(note_dict): This one produces a scale, with some alteration. It can be repurposed as a note generating function putting out (voices, notes)
                  def tetrad_arpeggio(note_dict): I can get rid of this one. 
                  def chord_play(note_dict): ditto it's been replaced by the simplified note generating functions

Combine the two paths here:
      e. Functions that take (notes, features) and returns (notes, features) but with duration replaced with start_time.
            def fix_start_times(note_array):
            def extend(note_array, min_dur, max_dur, budget = 0.10, likelihood = 0.20):
            def masked(note_array, density_function):

--------------------------
10/15/22 To do today:

✅    Why limit the search in build_note_array for the verse to just one pass through the 16 best_results array. 
      Why not go through it many times? Found this one when I increased the range from 10 to 16. Don't know why I chose 10. Must have been a mistake. I doubled the search and am finding lots of 16 note paths. Also set the starting chord to a random one in the list, and chose a random one from the legal moves. Gotta love that probablistic exploration. 
            row = rng.choice(best_results[rank_set]) # instead of the first one in the list

✅    Create an array of octaves with the same shape as (voices, notes). This will be used to spread out the octaves.
      Take a look at the octave spread algorithm I used in selective_stretching_codes.py. octave_shift() takes a (voice,note) list, a percent, a clump, and a distance=12 (used to increase a note by an octave). 
      I noticed that when I set the percentage to 0.5, it only changes 33% of the octaves. Wonder why.
      It handles 10% and 20% fine.
      10% comes out 7% to 10%
      20% comes out 15% to 19% 
      30% comes out 20% to 24%
      40% comes out 26% to 31%
      50% comes out 31% to 36%
      Run it a few times like this:
            percent = 0.5
            clump = 10
            my_octave_shift = octave_shift(verse_array, percent, clump, distance = 1)
            for inx in np.arange(3):
                  my_octave_shift = my_octave_shift + octave_shift(verse_array, percent, clump, distance = 1)
            my_octave_shift += 1
      See what it sounds like and make adjustments as needed.

-----------------------------------
10/16/22 To do today

✅    Get piano_roll_to_notes_features working.
      Now that I am requiring that all the major features (octave, dur, hold, env, vol, vel) must be arrays that are the same dimension as the number of notes in (voices, notes), I can concatenate them with voices and notes up front in the piano_roll_to_notes_features function. I'm not sure that concatenate is the right function. What am I looking for? zip. Your're looking for python zip, plus list and np.array.
            voices, notes (4,16) - I can make this any dimension that build_note_array() can supply.
            octaves (4,16) one for every note in every voice - this is what I've created.
            I'm thinking there is no quick way to do this. zip? Sort of. 
                  verse_array.shape = (4, 16)
                  my_octave_shift.shape = (4, 16)
                  combined_array = np.array(list(zip(verse_array, octave_array, env_array, durs_array, holds_array)))
                  print(f'{combined_array.shape = }') # (4, 5, 16)
            You can also zip in a float array, but it then turns all the integers into floats.
            notes, features: where features includes note numbers, durations, holds, envelopes, voice_number

------------------------------------------
10/17/22 To do today:

✅    Keep working on getting piano_roll_to_notes_features working. 
      I'm struggling with the fact that every voice plays the same notes in unison. 
      The problem was the way I duplicated the voices. I used:
            note_array = np.repeat(note_array, voices / note_array.shape[0], axis = 0) # this repeated each voice four times
      Instead of this:            
            note_array = np.tile(note_array, (voices // note_array.shape[0],1)) # this repeats all four voices four times in a row.

---------------------------------------------
10/18/22 To do today:

✅    Figure out why it's so sparse. 
      It's like I can't get back to what I had a few weeks ago to save my life. And why does it slow down?
      You don't suppose it's a t0 tempo statement? Can't find one. But it's clearly slowing way down for some reason. I think it's because I never reset duration. Bingo. Fixed it.
            else: # send the note to the (notes, features) array
                tone = prev_note
                stereo = rng.integers(low = 1, high = 17) # locate in stereo field randomly
                notes_features[feature_inx] = \
                    np.array((1, duration, hold_extra, velocity[voice_inx, note_num], prev_note, octave_array[voice_inx, note_num], voice_num, stereo, envelopes[voice_inx, note_num], \
                              799, upsample[voice_inx, note_num], envelopes[voice_inx, note_num], 799, 799, volume[voice_inx, note_num]))
                duration = 0 # I forgot this crucial reset 
                feature_inx += 1  

✅    It's still playing all four notes in the chord simultaneously, instead of as an arpeggio. How did balloon_drum_music.ipynb accomplish the arpeggio? It used a mask against the notes, and eliminated duplicates.

✅    Set up the right z factor so they don't all play simultaneously. It looks like a range of -0.01 to 0.01 is sufficient.
            note_dict{"z_factor": 0.01}       

✅    def masked doesn't seem to be doing what I designed it to do. 
      It looks like it's expecting assert note_array.shape[0] == density_function.shape[0], when I want it to mask the notes, not the voices. I think I rewrote it to mask (notes, features) instead of (voices, notes)      

✅    I'm starting to wonder why the end is just voice number 1, slowly. 
      Almost like all the other instruments have finished, but the finger piano is still playing all alone. That used to happen when I failed to keep track of the start_times. The total time is about 31 seconds, and the last 16 is just voice number 1. That's a big red flag that something is hosed up with the voice numbers. The last 79 are zero as the tracker number, which is also the tracker number for the first one.
            print(*[row[6] for row in voice_features[-79:]], sep='\t') # last 79 notes
      Now I changed voices=7 and now it only uses the first four voices in percussion, even though there are 7 voices in percussion.time_tracker_number in percussion: [0, 10, 11, 1, 4, 3, 2] When I double the voices to 14, it seems to do the right thing. Maybe the calculation I do is wrong piano_roll_to_notes_features is wrong:
            voice_name = instruments[voice_inx % num_inst] 
      voice_inx goes from 0 sequential to num_inst
      So I tested something, and if the voices overlap each other, it just starts using the previous voice short names, and so if the number of instruments doesn't equal the number of voices times an integer, it reuses the time_tracker_number. Big mistake. I need to check to ensure that voices is a multiple of instruments.shape[0].
      Two ways to fix that:
            voices = instruments.shape[0] * 3
            assert voices / instruments.shape[0] == voices // instruments.shape[0], f'{voices = } is not a multiple of {instruments.shape[0] = }'
      I later discovered that it's essential that the number of voices be divisible by 4. 4, 8, 16, 20 etc.

      
      When should I update start_times? I update it in fix_start_times based on the tracker_number
            fixed_winds = send_to_csound(fix_start_times(voice_features), print_only = print_only)
      piano_roll_to_notes_features does this:
            voice_num = voice_time[voice_name]["time_tracker_number"]
      So the voice_features array just has duration and holds until it goes to fix_start_times. There it converts duration into start_times and voice_number into the csound voice_number.

-----------------------
10/19/22 To do today:

✅    Get some music made. I'm very unhappy about how the ABABAB chain sounds. It's too extreme. 
      It was a nice idea, and had terrific symmetry, but sounds random. Not good.
      
✅    The z factor seems to accumulate over time. After about 20 seconds it seems like it is way off. 
      If I remove it, it sounds decent. But if I put it in, it starts good, then gets whack. Figured it out. 
      I added it away from the accumulate duration step. Added it just as it's going into notes_features.
      I also changed from np.arange to np.linspace, which is more consistent with small numbers. 
      The problem was at the start, I did not set duration and hold to time_per_note. I was setting to zero, which caused all the remaining notes to be off by a slight amount.

✅    Create a velocity_array that changes the volume over the course of the notes_features.      
            velocity_array = build_density_function(np.array([55, 54, 56, 57, 58, 60, 59]), verse_array.shape[1]) # changed over the course of the section. The range of values is quite small, from 54 to 60.

✅    Added tempos = 't0 80' the call to send_to_csound_file.
            voice_features = send_to_csound_file(fix_start_times(voice_features), tempos = 't0 80')
      I can adjust as needed. 

✅    Added a chance of rank B and more chords to start:
            verse_array = np.array([dmu.build_chords("oton", "16/9", rng.choice(["A", "B"], p = [0.9, 0.1]), (inversion % 4) + 1) for inversion in np.arange(0,12,1)]).T # this creates (4,12) once transposed
            # A is 32 36 40 44      B is 38 42 46 34

✅    Spent some time with the density function for masked. 
            density_function = build_density_function(np.array([0.5, 0.35, 0.4, 0.35, 0.5]), voice_features.shape[0])
            print(f'{density_function.shape = }') (4780,)
            verse_array = masked(voice_features, density_function) 

✅    So now I have a reasonable vamp going on, time to add some woodwinds. What are the elements to include?
            built the array. ranks = ['A', 'B'], p = [0.9, 0.1], repeat_verse_array = 12, verse_array.shape = (4, 12)
            repeat_each_note = 15. verse_array.shape = (4, 180)
            voices = 21, percussion.shape = (7,)
            after densify. verse_array.shape = (20, 3600)
            time_tracker_number in percussion: ['finger piano', 'finger piano #2', 'finger piano 3', 'bass finger piano', 'high balloon drum', 'medium balloon drum', 'bass balloon drum']
            velocity_array.shape = (3600,), round(tpq / repeat_each_note,2) = 0.07
            num_notes = 72000
            round(min_z,5) = -0.001, round(max_z,5) = 0.001
            Back from piano_roll_to_notes_features. voice_features.shape = (4780, 15)
            density_function.shape = (4780,)
            voice_features.shape = (4780, 15)
            round(limit,1) = 167.1
            read from to ball3.csd. lines = 638
            last start time was at 167.1
---------------------------------------
10/20/22 To do today:

✅    Take the set of variables used in the prior day's work and build some woodwinds section riffs. 
      Too many bugs to make progress on that front

-------------------------
10/21/22 To do today:

✅    Yesterday was a consolidation day. Not much new. 
      I've given up the build_note_array function in favor of 90% rank "A", 10% rank "B": 
            # path = build_note_array(0)
            # verse_array = np.array([dmu.build_chords("oton", "16/9", rank, inversion) for (rank, _, inversion, _, cents) in  path]).T
            ranks = ["A", "B"] # we can make this a loop on ranks
            p = [0.9, 0.1] # this can be reset as needed
            repeat_verse_array = 12 # how many times to go through the list comprehension
            verse_array = np.array([dmu.build_chords("oton", "16/9", rng.choice(ranks, p = p), (inversion % 4) + 1) \
                                    for inversion in np.arange(0,repeat_verse_array,1)]).T

✅    Something strange is going on. 
      voice_features ends up with 4780 notes, but covers those in only 167 seconds.                                    
      And I get 4780 over and over again. Even with a random mask. Something's up. But we don't get rid of the zero hold notes until after fix_start_times:
            After fix_start_times. voice_features.shape = (1645, 15)
            print(f'highest octave: {np.array([features[5] for features in voice_features]).max()}')
            highest octave: 7.0
            lowest octave: 2.0
            highest hold: 0.2525 # that's a pretty narrow range, don't you think? Why can't it be more mixed up? 
            Lowest hold: 0.2357
      It was because piano_roll_to_notes_features compressed repeated notes down to one note, and it was slower, but no different from fewer repeated notes.

✅    Looking for a way to set the tempo faster with the tpq approaches 2 and slower when it approaches 1. 
            tpq = 1 + rng.random()
            tempo = 120 if tpq = 1.37
            tempo = 140 if tp1 = 1.628
            tempo = 160 if tpq = 1.958
            tempo = 100 if tpq = 1.197
            tempo = 80 if tpq = 1.092

----------------------------------------
10/23/22 To do today:

✅    Get something done on including trills on bass flute synched with what you've already done with percussion.

✅    This will require simplifying the root_chord_slide to just returning (tones1, gliss), which are the 4 initial notes, gliss #
      It will require note_dict["mode", "root", "combo" (rank & inversions), "gliss_type"
            tones_1 = dmu.build_chords(note_dict["mode"], note_dict["root"], note_dict["combo"][0], int(note_dict["combo"][2])) 
            tones_2 = dmu.build_chords(note_dict["mode"], note_dict["root"], note_dict["combo"][1], int(note_dict["combo"][3])) 
            gliss = dmu.build_slides(tones_1, tones_2, gliss_type = note_dict["gliss_type"]) 
      combo - choose_best_rank_inversion_combos() will provide this.
            note_dict = {"combo": choose_best_rank_inversion_combos()}
-------------------------
10/24/22 To do today:

✅    Still working on getting the bass flute slide to work.
      What ended up in the new_output.csd was one chord played on finger piano and bass finger piano, with no slides.
      I had the bass flute in the input:
            combo = array(['B', 'B', '2', '1'], dtype='<U21')
            new glissandi to be stored: new_tables.shape = (4,), new_tables = array([800., 801., 802., 803.])
            built the chord and trills. note_array.shape = (4,), note_array = array([42, 46, 34, 38]), gliss_nums = array([800., 801., 802., 803.])
            time_tracker_number in woodwinds: ['bass flute', 'bass flute #2', 'bass flute #2', 'bass flute #2']
      a. Start with finding out why the voice was 1 & 2. it was because the "instrument_array": percussion, instead of woodwinds. 
      b. Why is the gliss not in new_output.csd - I was not more closely linking gliss with the notes to which it applies.

✅    I noticed that send_to_csound_file was expecting one value returned from dmu.retrieve_gliss_tables
            gliss_tables = dmu.retrieve_gliss_tables() # returns two variables, which python interprets as a tuple.
      It should expect two, they are:
            return stored_gliss, current_gliss_table
      So when it received two into one variable, python provided a tuple, and it had to be indexed. I fixed it, but I noticed subsequent references included an index to the tuple, which is no longer a tuple after I recognized that it needed two separate variables. 
      Fixed it.

✅    There is no reference to the slides for each of the four notes in new_output.csd:
            i 1.0 0.0 3.195153057764392 59.0 32.0 3.0 6.0 12.0 16.0 799.0 3.0 16.0 799.0 799.0 25.0 
            ...
            i 1.0 0.0 3.186246114608907 59.0 44.0 3.0 6.0 10.0 1.0 799.0 254.0 1.0 799.0 799.0 25.0       
      799 is no slide.
      The problem now is that I've separated the gliss numbers from the notes. I'm going to have to do with the gliss what I did with the octave, make an array that has the same dimension as note_array, called gliss_array, that has the slide numbers for each and every note.
      Fixed it.

✅    All the notes on a chord have different durations for some reason. 
            i 1.0 0.0 3.2807969901339353 59.0 34.0 3.0 6.0 7.0 16.0 800.0 0.0 16.0 799.0 799.0 25.0 
            i 1.0 0.0 3.2532674943773334 59.0 38.0 5.0 6.0 5.0 8.0 801.0 254.0 8.0 799.0 799.0 25.0 
            i 1.0 0.0 4.144864984784429 59.0 42.0 4.0 6.0 1.0 16.0 802.0 1.0 16.0 799.0 799.0 25.0 
            i 1.0 0.0 3.1569689248245894 59.0 46.0 3.0 6.0 1.0 2.0 803.0 3.0 2.0 799.0 799.0 25.0 
      The hold values were built for short notes. Changed it:
            if duration < 1: hold_extra += tp16 * ((rng.random() + rng.integers(low = 1, high = 5, size = None)))
            else: hold_extra += tp16
      fixed it.

✅    I think I may have the wrong upsample values. Fixed it.
            ;Inst Start                      Dur       Vel  Ton  Oct Voc Ste Env Gliss Ups R-Env 2nd-gl 3rd vol
            i 1.0 2.361153215896758 2.138908482965849  59.0 32.0 2.0 6.0 4.0 1.0 801.0 0.0 1.0 799.0 799.0 25.0 
            i 1.0 2.3616430118151253 2.296743031542501 59.0 36.0 3.0 6.0 5.0 0.0 802.0 0.0 0.0 799.0 799.0 25.0 
            i 1.0 2.362296073039615 2.23991612185452   59.0 44.0 3.0 6.0 7.0 1.0 800.0 0.0 1.0 799.0 799.0 25.0 
            i 1.0 2.362336889366146 2.209955553507459  59.0 40.0 2.0 6.0 2.0 0.0 803.0 0.0 0.0 799.0 799.0 25.0 

✅    Where is the tempo set? I need to figure out how to coordinate time between the percussion and the woodwinds.
      We send the chord with a slide through densify: 
            tile_time_steps = 15
            repeat_each_note = 6
            for i in np.arange(20):
                  tpq = 1 + rng.random()
                  print(round(tile_time_steps * (tpq / repeat_each_note),3), end = '\t')
            2.915	4.748	3.341	2.586	4.052	4.308	4.445	4.356	3.809	3.653	3.267	3.71	3.965	3.76	4.792	3.986	3.689	3.58	3.627	4.584	

✅    So how is the percussion part lasting so long.
      repeat_verse_array = 6
      We start with verse_array.shape = (4,6) - cycles through the inversions repeat_verse_array times.
            built the array. ranks = ['A', 'B'], p = [0.9, 0.1], repeat_verse_array = 6, verse_array.shape = (4, 6)
      Then it repeats each of the 6 notes across a four note chord 6 more times 
            repeat_each_note = 6. verse_array.shape = (4, 36)            
      Then it densifies by tile_time_steps = 15, and voices = 21 voices // verse_array.shape[0] 21 // 4 = 5
      Voices go from 4 * 5 = 20, and notes go from 36 * 15 = 540
            After densify. verse_array.shape = (20, 540)
      This array goes through piano_roll_to_notes_features which reduces the number of notes because repeating notes are combined into a single note with a larger duration. 20 * 540 = 10,800, reduced to voice_features.shape = (1780, 15)
      This is the array that is sent to csound for realization. 
      So, in sum, the increases are:
            start with 4,6
            repeat to reach 4,36
            densify:
                  voices go from 4 * 5 = 20
                  notes go from 36 * 15 = 540 
            piano_roll:
                  voices times notes: 20 * 540 = 10,800 keep 70% to 1780 of varying durations 
                  10,800 / initial voices (7) * .28 value = total duration 432 seconds. Not right.
      I will need to pass each of these calculations through to the bass flute note generation function.
      Here's another summation of the timings:
            repeat_verse_array = 10, verse_array.shape = (4, 10)
            repeat_each_note = 10. verse_array.shape = (4, 100)
            voices = 21, percussion.shape = (7,)
            # repeat_each_note = 10. verse_array.shape[1] = 100. 10 * 100 = 1000
            # voices 21 // 4 = 5 voice_array.shape[0] 4 * 5 = 20
            after densify. verse_array.shape = (20, 1000) 
            velocity_array.shape = (1000,), volume_array.shape = (1000,), 
            round(tpq,3) = 1.384,  round(tpq / repeat_each_note,2) = 0.14
            # I need to figure this next step out. 
            # how can this be predicted: 20 * 1000 = 20,000 down to 1,980
            # It does the exact same reduction every time:
            in piano_roll_to_notes_features. note_array.shape = (20, 1000)
            round(min_z,5) = -0.001, round(max_z,5) = 0.001
            Back from piano_roll_to_notes_features. voice_features.shape = (1980, 15)
            density_function.shape = (1980,)
            after masked. voice_features.shape = (1980, 15)
            round(tpq,3) = 1.384
            round(limit,2) = 92.3, tempo = 110
            last note ends: round(60*limit/tempo,1) = 50.3 seconds
            read from ball3.csd. lines = 638
            After fix_start_times. voice_features.shape = (700, 15)

-------------------------------
10/26/22 To do today:

✅    What could be causing the reduction from 20k to 1.9k. 
      The first factor is that repeat_each_note gets eliminated by piano_roll_to_notes_features, since they are duplicate notes
      This is not necessarily a bad thing. I repeat the notes 10 times, then mask some of them, which makes for interesting music.
      The function piano_roll_to_notes_features has voice.shape = (1000,) at the start of processing a voice.
      a. Could it be receiving many notes in a row that are the same note, making one note out of very many?
            Test this. The maximum duration is 0.476. That's not long. It doesn't confirm that I am handling the duplicate notes properly.
      
      b. Count the number of notes created by each voice. It's the same as I suspected: 19 per voice. That's suspicious. 
            input_voice_inx = 20, output_inx = 380, notes_made = 19
            why does 40 notes always go to 19 notes. Every time? It could be because every voice has the same notes to play?
            No it's because every voice has two repeating notes, followed by two repeating notes, always. So it should go to 20, not 19. It's dropping the last one. Add one zero pad at the end. That fixed the dropped note, and exactly explains how it goes from 40 to 20
            What are the notes in each voice? Here are the first four:
                  voice[:4] = array([32, 32, 36, 36])
                  input_voice_inx = 9, output_inx = 171, notes_made = 19
                  voice[:4] = array([36, 36, 40, 40])
                  input_voice_inx = 10, output_inx = 190, notes_made = 19
                  voice[:4] = array([40, 40, 44, 44])
                  input_voice_inx = 11, output_inx = 209, notes_made = 19
                  voice[:4] = array([44, 44, 32, 32])
            
      c.    The second factor is that piano_roll_to_notes_features was cutting off the last element of the array. 
            My solution was to pad the input array and be done with it. I could check why the code does this. It's because it never does anything with the first element of the array, not the problem with the last. I added an extra one at the end of the loop. Fix it, don't patch it. 
            So I know have an input note array with voices,notes of (20, 1000). Since each 10 notes in a row are duplicates, they all compress down to one note. 
            That would not be bad except the mask takes place after the notes have been compressed. I would be better off doing the masking after repeating the notes but before going through piano_roll_to_notes_features. I did not realize how important that is. I made masked to mask after the conversion to (notes, features). I'll have to make it able to mask before that. I saved masked as masked_notes_features, but I don't think I'll be needing that any more. 
            I created a new one called masked_voices_notes, to process a (voices, notes) array after all the repetitions and densifications, but before sending it to piano_roll_to_notes_features. 
            Next logical question: How do you mask a note from a (voices, notes) array? Look at the arpeggiate function in selective_stretching_codes. In piano_roll_to_pfields it ignored a note if the calculated octave was zero. So arpeggiate turned notes into zeros, and piano_roll_to_pfields ignored them. They were still there, just ignored. Could I do that? Maybe. I could also set it to some arbitrary value outsize the range of 0-255 notes. Like, set them to 256, and test against 256 in piano_roll_to_notes_features. Or I could mask the octave array, and then if the octave is zero in piano_roll_to_notes_features, ignore the note. That would be easier. He thought.
            The problem is that build_density_function only works on one dimension. That made sense when you were using it to (mask notes, features) arrays. You just have to decide if you want the note or not. If we are just choosing whether to include a note that has 15 features, one dimensional density function is fine. Works also for volume and velocity. But it won't work for octave_array, unless I flatten the array and reshape it afterwards. Hmm.
                  octave_shape = octave_array.shape # save the shape so you can restore it
                  octave_array = octave_array.reshape(-1) # flatten it
                  print(f'after flattening. {octave_array.shape = }')
                  density_function = build_density_function(np.array([0.25, 0.35, 0.4, 0.35, 0.25]), octave_array.shape[0])
                  print(f'{density_function.shape = }')
                  octave_array = masked_voices_notes(octave_array, density_function)
                  print(f'after masked. {octave_array.shape = }')
                  octave_array = octave_array.reshape(octave_shape)
                  print(f'after reshaping back to the original shape. {octave_array.shape = }')
            So I implemented the revised masking routine, and it's sounds kinda whack. Not good. It's lost the deep groove that it used to have a few weeks ago. I made it much better by reducing the repeat_each_note:
                  repeat_each_note = 4
            I think the problem is that by reshaping the octave array, it's lost the relationship to a path through the song. The octave_array shape was (20, 600), then reshape(-1) made it (12,000, ) and the density array was passed a set of probabilities which it applied using the latter structure, and when reshaped, lost it's way. Also, density function needs a minimum of four values in the input array. 
      
--------------------------------
10/27/22 To do today:

✅    Don't prematurely drop notes because they have octave_array values of zero. 
      You are missing out on advancing the hold values and durations.
      Instead, move the test for zero-ness to after the timing updates. So I did that, and now the density went to extremely sparce, and the notes are all very low octaves. I had switched the test for zero-ness to the opposite of what I intended. != vs. ==. 
            found_zero = 5760
            Back from piano_roll_to_notes_features. voice_features.shape = (3860, 15)
      I eliminated 5760 and kept 3860.
      But csound choked:
            new alloc for instr 1:
            instr 1:  p2 =  -nan  p3 =  -nan  p5 = 32.000  p7 = 1.000  p10 = 799.000
            INIT ERROR in instr 1 (opcode table.i) line 44: table: could not find ftable 2
            from file new_output.csd (1)
            iSampleType	table.i	p7	2	0	0	0	
                  B  0.000 - note deleted.  i1 had 1 init errors
      That -nan looks suspicious. I think it's the negative start time. I got rid of that and ended up with something out of an indian drum circle. Finger piano and any note changes were all gone. Now all notes are gone. Nothing made it through to new_output.csd. The notes came back, but the pitches are all the same throughout. And rather slow. 

✅    I can't figure out what I did to screw everything up today, so I recovered what I had as of last night. 
      Now I need to (carefully) redo the test for zero-ness. I completed that, but now the result is a strange conversion to only playing on the downbeat. I've tried changing the number of repeat_verse_array and repeat_each_note to no success. 
            repeat_verse_array = 5, verse_array.shape = (4, 5)
            repeat_each_note = 7. verse_array.shape = (4, 35)
            percussion.shape[0] = 7
            voices = 21, percussion.shape = (7,)
            after densify verse_array.shape = (20, 525) 10,500 notes, 
            compressed down to 440 notes in 33 seconds
            found_zero = 780
      Should I take this out:
            notes_features = np.array([row for row in notes_features if row[1] > 0]) # only include those with a non-zero start value
      And put this back:
            if duration + z < 0: duration = abs(duration - z)
      Didn't help. It sounds like a mass of dotted eighth then sixteenth note pairs. Then 2/3 of the way through it hints of better things in the past, but goes back to heavy downbeat with some other stuff.

✅    Double check how you are using build_density_function values. 
      Compare all the uses from the first time you used until today. Looks ok to me.
      I thought you could pass it any set of numbers and it would return the requested array size as a smooth path through those points. Was I wrong? No.
      For example:
            first one:
                  density_function = build_density_function(np.array([0.95, 0.65, 0.7, 0.9, 0.7]), fixed_winds.shape[0])
                  fixed_winds = masked_notes_features(fixed_winds, density_function) # choose to eliminate some of the notes, 5% to 35% of them gone
            later versions:
                  velocity_array = build_density_function(np.array([55, 54, 56, 57, 58, 60, 59]), verse_array.shape[1]) # 
                  volume_array = build_density_function(np.array([25, 27, 28, 30, 28, 26, 25]), verse_array.shape[1]) # 
                  density_function = build_density_function(np.array([.4, .5, .3, .2]), octave_array.shape[0])
                  octave_array = masked_voices_notes(octave_array, density_function) # choose to elminate 50% to 80% of the notes. 
            Describe what it does: 
                  It traces a smooth curve through the input values, overshooting and undershooting the targets.                 

-------------------------------
10/28/22 To do today:

✅    You have not made any progress lately. The music is gone. You need to trim everything down until you have control.
      Fewer notes. Build an understanding of what is happening and don't just change something you don't understand and hope for the best. That's not working.
      Found the first anomoly. I set repeat_verse_array = 8, verse_array.shape = (4, 8)
            verse_array = array([[32, 36, 40, 44, 32, 36, 40, 46],
                  [36, 40, 44, 32, 36, 40, 44, 34],
                  [40, 44, 32, 36, 40, 44, 32, 38],
                  [44, 32, 36, 40, 44, 32, 36, 42]])
      8 notes with no repetition of notes should produce 8 notes in the output.                   
      And yet:
            after densify verse. verse_array.shape = (4, 8)
            after densify gliss. gliss_array.shape = (4, 1) # why is this (4,1)?
      Then later: 
            In fix_start_times. note_array.shape = (27, 15)
            fixed_voice_features.shape = (27, 15)
            After send_to_csound_file. voice_features.shape = (4, 15)
      So something in send_to_csound_file looses 23 notes. Why?
      Again: 
            in send_to_csound_file. notes_features.shape = (22, 15)
            After send_to_csound_file. voice_features.shape = (1, 15)
      The fault happens because there are lots of zero hold values.
            are there any zero hold values in send_to_csound? notes_features[:,2] = array([1.35217062, 0.        , 0.        , 0.        , 0.        ,
            0.        , 0.        , 0.        , 0.        , 0.        ,
            ...
            1.35217062, 0.        , 0.        , 0.        ])
      Lots of zero hold values. Why. What happens in piano_roll_to_notes_features to set so many notes to zero hold?
      Nothing. Nothing happens if all the notes are different. Nothing gets added to hold. I should start with some value, then add to it if it repeats. And here I thought I could just initialize hold with a non-zero value 
            hold = time_per_note
      But there are still a majority of notes with zero values. There were two places where hold = time_per_note was needed. At the start and at a new note. Fixed it. Now I have lots of notes. But they all play at only two start_times. Why? 19 of them start at 1.66
            are there any zero hold values? notes_features[:,2] = array([3.34036715, 1.67018358, 1.67018358, 3.34036715, 1.67018358,
                                                                        1.67018358, 1.67018358, 1.67018358, 1.67018358, 1.67018358,
                                                                        1.67018358, 3.34036715, 1.67018358, 1.67018358, 1.67018358,
                                                                        1.67018358, 1.67018358, 3.34036715, 1.67018358, 1.67018358,
                                                                        1.67018358, 1.67018358, 1.67018358])
      Look at all those notes with the same hold value. 19 of them. Suspicious. 
      I think I've found a combination of values that makes more sense.
      But now it gone whack on me. It's like each voice has its own tempo. And we are back to the dotted eighth sixteenth sounds (DESS). But it sounds more like mistakes. I'm taking out the z value for now. Didn't help. It's like one instrument always plays on the downbeat and no one else plays on it. If I keep the repeat_each_note lower than 4 it seems better. 4 gets the DESS bad. 5 is worse. 6 is attrocious. I need to see what the voice_time start time looks like.
            print(f'start: {[round(voice_time[inst]["start"],3) for inst in percussion]}')
                  start: [33.63, 34.291, 34.513, 34.237, 32.583, 16.871, 19.021]
      Notice that they don't all end at the same time, not even close. That one with 16.871 is the finger_piano csound voice 1. It's about half the others, and the 19.021 is not even any relationship to the others. Why? 
      I'm no closer to answering that question than I was at the start of the day. How are the notes spread across the voices?
            num_inst = instruments.shape[0]
            # then we loop over voice in note_array, incrementing input_voice_inx as we loop.
            voice_name = instruments[input_voice_inx % num_inst] # three letter voice name
            voice_num = voice_time[voice_name]["time_tracker_number"] # the fake voice number, replaced with the real one in fix_start_time.
      It's almost like there is no control over making sure that they are spread equally over the voices. Didn't I find that problem before, and didn't I create a function that made all voices have the same ending? def extend includes logic to ensure equal endings. 


✅    Concatenate a scale on the end of the set of chords. use np.roll(tones, rng.integers(low = -2, high = 2, size = None))
      and np.flip(tones)
      It doesn't sound any different than before I added the scale at the end. 

✅    Now that I have a better understanding of the counts, summarize the most important ones.

-------------------------------
10/29/22 To do today:

✅    Check that each voice in piano_roll_to_notes_features gets equal number of notes to try to add, and to succeed in adding.
      Measure before and after checking octave_array for zero. Interesting discoveries. No matter how I try to set the probabilities lower, I still end up with very dense results. For example, here are some interesting numbers:
            voices = 16, percussion.shape = (8,)
            density_function = build_density_function(np.array([.01, .02, .03, .05]), octave_array.shape[0])
                  np.average(density_function) = 0.02625020927507115
            in piano_roll_to_notes_features. note_array.shape = (16, 1120)
            Total notes to process: note_array.shape[0] * note_array.shape[1] = 17920, num_notes = 17920
            found_zero = 8654
            voice_chosen_a = array([1118, 1078, 1118, 1118, 1118, 1078, 1118, 1118]), voice_chosen_b = array([18, 21, 21, 24, 26, 39, 34, 43])
      What this means is the the probability of being chosen is 18 out of 1118, and yet the result is very dense, but short. So we are not advancing the start times for notes not chosen. That's a problem, I think. 

      What is the function of fix_start_times? It reads in a notes_features structure and converts the duration column to be the start time. 
            In fix_start_times. note_array.shape = (226, 15) # 226 notes and 15 features each. So it adjusts the start times after piano_roll_to_notes_features has reduced the notes down to very few. Oops. That's not what I wanted.
            What do you want? 
            I want the density_function to be a density_function, that is, to reduce the density if it is low, and not if it's high.
            What are the steps?
            1. generate notes 
            2. increase the quantity of the generated notes vertically and horizontally through tile and repeat
            3. convert the (voices, notes) to (notes, features) using piano_roll_to_notes_features. Do not mask here, it's too soon.
            4. convert the durations to start times using fix_start_times
            5. mask the results so there are fewer notes - this means masking using masked_notes_features(note_array, density_function):
      
      I finally have something that sounds like a nice vamp. What an amazingly troubled journey. 
      
✅    One problem seems to be that there are 7 instruments, and we only allow 20 to be chosen (0 - 19). Why 20? 
      input_voice_inx goes from 0 to 19, why not 20 to make 21 different choices? 
            voices = 21, percussion.shape = (7,)
            verse_array.shape = (4, 32)
      densify does this:                        21    //   4   =  5 and 5 * 4 yields 20, not 21
            note_array = np.tile(note_array, tile_time_steps) # repeat the chords (4,32) by 1 yields (4,32)
            note_array = np.tile(note_array, (voices // note_array.shape[0],1)) # tile shape (4,32) by 5 yields (20, 32), but I would prefer (21,32)
            after densify verse. verse_array.shape = (20, 32) # 
            shouldn't this be 21,32? No. You can't tile (4,32) and yield (21,32)
      Best to choose a multiple of the initial number of voices in a chord, which is 4. Choose instrument counts that are divisible by 4, such as 4, 8, 12, 16, 20, 24, 28, 32, etc. number of instruments.

✅    Looking for the optimum values for the key variables:
            repeat_verse_array = 40 # how many tetrad chords before the scale - 2 & 3 are good too.
            repeat_each_note = 24 # best is 2, 4, 6, 8, 10, 12 is good too, 40 & 50 are great. this is weird. The higher the number the slower the play.
            tile_time_steps = 3 # dictates how long the piece will be, how many repetitions of the tetrad plus the scale

✅    I'm still seeing some rhythmic colapse towards the end of the segments. What could cause that? 
      Is it possible that the z factor is getting out of control? I turned it off. It's still sounding like chaos towards the end. Actually, it's chaos at various points, and then it comes together again. Like a cycle of chaos --> synch --> chaos --> synch. It's interesting at times, until it isn't.
      setting repeat_each_note to 
            2 it doesn't happen. But the balloon drums go for an extra 5 seconds at the end. It happened a second time just like that first. 
            50 almost doesn't until the end when it gets a little whack.
            3 rapidly switches in and out of synch.
            4 also switches in and out of synching
            6 switches but less frequently.
            8 switches a lot
            12 switches a lot
            24 is bad too. What is going on? It's like it goes into double time when it's out of sync.
            48 seems nice. But no better than 2, plus it creates 522,240 notes, then compresses 99.99% of them down to one note. 522k down to 10.8k. 48 to 1. That's because the masking takes place after the (notes, features) structure is created.
            So the piano_roll_to_notes_features compresses the duplicate notes away. That's why I wanted it before piano_roll_to_notes. But when I did that, it compressed the time down and kept the same density.
            I'm going to have to think about this. In the mean time, use repeat_each_note=2 for now. No benefit from the others.

----------------------------------------
10/30/22 To do today:

✅    So your bright idea to organize the order of processing has resulted in failure.
      Now, repeat_each_note isn't making a damn bit of difference. piano_roll_to_notes_features just compresses it away. But not correctly it turns out. I'm getting those wierd rhythm shifts of tiny amounts that makes the instruments get out of sync. Perhaps it is the last note in each voice. It turned out to be that I was starting with dur = 0 instead of dur = time_per_note. Oops. Fixed it. Now it works correctly with all the repeat_each_note values 2 through 36. But there is not much difference between them. 
      
      Regardless, the problem is less the out of sync problem, much more the fact that the only way for the masking to work correctly is for it to affect the actual notes. The attempt to use the octaves failed. Why? And more importantly, how can I fix it. 
      
      Some ideas:
      a. Go back to using octave_array as a masking tool, but this time make prev_note a tuple of the note and the octave. If it changes, send it to the output array. If it doesn't, then just accumulate the duration and hold. Consider using zip(note_array, octave_array) as the tuple generator:
            for (voice_note, voice_octave) in zip(verse_array, octave_array):
                  print(f'processing voice. {voice_note.shape = }, {voice_octave.shape = }')
                  dur = 1
                  for (note, octave) in zip(voice_note, voice_octave):
      My first attempt at modifying piano_roll_to_notes_features with zip(verse_array, octave_array) was unsuccessful. The sound was totally different. At first I blamed it on longer holds, but that wasn't it. 

      I noticed that the ending voice_times["start"] were no longer equal. It would be very useful to know what the notes_features last start and hold values were by voice in the list of voices used in csound. Don't get me wrong. With repeat_each_note at 2 it sounds very funky. But any higher numbers are just clunky. The reason is I now hear all those other notes which are preserved as the tuple of (note, octv) makes the notes distinct that previously just compressed        
                  chop_at = largest_evenly_divisible(brass_array.size,brass_oct_patte.shape[0])
      down to one note. Now they are separate notes. 
      I need to get rid of dividing the tpq by repeat_each_note, since the higher values are way too fast.
      But now it lasts way too long! Hold on, now it's too short! 25 seconds for repeat_each_note regardless of the other values. How does the number of notes go from 67,840 down to 763? Amazing. It was a bug in the _octave_shift function and its caller. Fixed it.

      Some examples:
            repeat_verse_array = 3 # how many tetrad chords before the scale
            repeat_each_note = 3 # repeat each note
            tile_time_steps = 1 # dictates how long the piece will be, how many repetitions of the tetrad plus the scale
            voice_multiplier = 2 # how many times to multiply times shape of instruments list
            rva   ren   tts   vm    duration
            3     3     1     2     18.8
      About two hours ago I was worried that it was over 5 minutes. Something must have changed. 
      piano_roll_to_notes_features gets an input of 783,360 and comes out with 392 notes. Not possible.
      I found the problem. The octave array was only shape = (75,) compared to voice.shape = (32,640,). I must have created octave array too soon. I send verse_array of shape (24, 32640) to build_octave_array, but what comes back is (16,75). build_octave_array was passing a local variable verse_array to _octave_shift, and should have passed note_array, the parameter. 
      There were a number of other failures that somehow didn't stop it from creating notes. Using global variable names inside functions is a bad idea, part #6,432.

      So what I've learned is that you make it longer by increasing either repeat_verse_array or voice_multiplier. Both have identical effects. Increasing tile_time_steps means that you get more scales and fewer verses. To change the tempo, use repeat_each_note. Can gofrom 2/4 to 3/4 to 4/4 to 5/4 etc. up to 16/4, which is pretty much the max. I'd stay away from the high primes like 11, 13, 15. 10 is pretty challenging. 

✅    You still have that nagging problem of the gliss_array having a different shape from the verse_array.
      This may come back to bite you.             
      
------------------------------------------
10/31/22 To do today:

✅    Think of ways to shorten up the verse part:
      a. Reduce the number of voice_multiplier and tile_time_steps. Same effect on both. Set them to 1, and you will still get the density of 16 voices. 
      a. Don't repeat the verse so many times using concatenate.
      b. Truncate the scales at random points, not always 8 notes now, may be have some only 5 or so?
      c. I wish I could vary the scale on repetitions, could I replace them in the verse_array
      d. Generate them on the fly instead of repeating them instead of tile, concatenate different ones each time. 
      e. I like the idea of ending the verse with the scale, since it will lead to the bridge.

✅    Figure out why doubling voices doubles duration. 
            instruments.shape[0] = 8
            voice_multiplier = 4
            voices = instruments.shape[0] * voice_multiplier = 32    
            After concat tetrad and scale. verse_array.shape = (4, 26)
            after repeating. verse_array.shape = (4, 52)
            after densify verse. verse_array.shape = (64, 52)
            Total notes to process: note_array.shape[0] * note_array.shape[1] = 3328, num_notes = 3328
            After piano_roll_to_notes_features. notes_features.shape = (2104, 15)
            tempo = 100, 62.4 seconds elapsed

            What does densify do:
            note_array = np.tile(note_array, tile_time_steps) # repeat the chords
            note_array = np.tile(note_array, (voices // note_array.shape[0],1)) # make more voices 
            note_array.shape was (4,52) prior to densify.
            
      The reason is that doubling voices gets transformed into doubling the duration, because piano_roll_to_notes_features doesn't care what how many voices you have, it just considers them another tranch of notes. The number of active voices is determined by the instruments array:
            instruments = np.array(["fpn", "fp2", "fp3", "fp4", "bnp", "bdl", "bdm", "bdh"]) has 8 voices
            instruments = np.array(["fp1", "fp2", "fp3", "fp4", "fp5", "fp6", "bn1", "bn2", "bd1", "bd2", "bd3", "bm1", "bm2", "bh1", "bh2", "bh3"]) # this has 16, so can be denser than 8 voices.
      If you make the instruments array larger, you will get more density. 
      tile_time_steps has the exact same effect as voice_multiplier. 
      Don't use voice_multiplier to increase density. If you want density control, use more instruments (think 16 or so) and then control density with the 
            density_input = np.array([.1, .3, .5, .8])

------------------
11/1/22 To do Today:

✅    Should I go back and create another way to mask at a different point in the process?
      I have changed piano_roll_to_notes_features to include a tuple of (note, octv) as the changing point for a note. 
      Identical pairs of (note, octv) are combined, with the duration and hold increased.
      
      Give it a try, but preserve what you have at this point, because it could quite easily go very wrong. I found a copy of the octave_array mask logic from 10/26/22 on Dropbox. I noticed that it flattens the array before building the mask array, then reshapes it back to the original shape before actually using the zero octaves to eliminate notes in piano_roll_to_notes_features. That has the nasty side effect of loosing visibility into the section of the piece where the notes are masked. I can't control where the masking takes place because they are hidden all throughout the section masked. The only reason I did that is that build_density_function can only handle one dimensional arrays. What if I built a function that could do what I wanted. What do you want? I don't think this is worth doing, so I won't. 

      piano_roll_to_notes_features converts the (voices, notes) to (notes, features) including the time_steps.
      It assigns voices by converting one of the (28) unique 3-letter voice names into a "time_tracker_number", which is a unique number used for keeping track of the current time in each of the unique 3-letter voice names. The voice names can be reused:
            voice_name = instruments[input_voice_inx % num_inst] # list of 3-letter voice names
      But you need to make sure that the number of instruments is a multiple of 4. In this case 32 voices come in, and they are assigned one of the 8 voices, with reuse of the name. This increases the length of time by 4 times.

      I wonder if I can use build_octave_array to keep some octaves 0, which would cause them to vanish. If I allow the zeros to persist:
            octave_array = build_octave_array(verse_array, spread = 6, add = 0) # some will be zero
            rng.shuffle(octave_array, axis = 0) # axis = 1 means the clumps are destroyed, but the zeros are scattered randomly (as are all the others.
      Then change send_to_csound_fileto select only notes with non-zero octave values, as we have already done with hold values. This makes two separate masking techniques that cost relatively little. 
            notes_features = np.array([row for row in notes_features if row[2] > 0]) # only non-zero hold values
            notes_features = np.array([row for row in notes_features if row[5] > 0]) # only non-zero octave values
      See how the numbers decrease due to these three factors:      
            Total notes to process: note_array.shape[0] * note_array.shape[1] = 10752, num_notes = 10752
      Piano roll compresses consecutive identical octave/note pairs into one note with more duration
            After piano_roll_to_notes_features. notes_features.shape = (4555, 15)
      Then the two filters removes a lot of notes due to 0 hold or 0 octave:
            In send_to_csound_file after selecting for non-zero hold values. notes_features.shape = (2898, 15)
            After send_to_csound_file. notes_features.shape = (2736, 15)
            In ticks: 167.95 in seconds: 125.96

      the function masked_notes_features masks notes by setting the hold values to zero, while the build_octave_array does the same for octaves. One function sets a trigger value and another filters based on that trigger. Do they differ in effect? Who knows.

✅    I change the verse_array collection to include two scales:
            verse_array = np.concatenate((np.repeat(verse_array, 3, axis = 1), new_scale(mode, root, rng.choice(ranks, p = p), verse_array.shape[0]), np.repeat(verse_array, 3, axis = 1), new_scale(mode, root, rng.choice(ranks, p = p), verse_array.shape[0])), axis = 1) 
      We have three of the tetrads, then a scale, then three more tetrads, and a different scale. This is then repeated through either tile_time_steps or voice_multiplier, and to a lesser degree repeat_verse_array.            

✅    I'm still confused why gliss_array is so small:
            gliss_array.shape = (4, 6)
            after densify gliss. gliss_array.shape = (32, 12)
      How does it not cause a downstream problem? It's because I don't increment input_note_inx at the right spot.
      At the start of the (note_array, octave_array) loop I set it to zero.
      at the end of the {voice, octave} loop I increment it. 
      The problem is that only assign a value to prev_gliss on the first time through the (note_array, octave_array) loop. I should have assitned it right after I assigned prev_note. Now it will fail as it should.
            index 12 is out of bounds for axis 1 with size 12 <-- success!
      gliss_array is not the right size. It should be the same size as verse_array and octave array. Fixed it:
            gliss_array = np.full(verse_array.shape, 799, dtype = int)
-------------------------
11/2/22 To do today:

✅    Fix the shape of gliss array. 

✅    It sure sounds like the z_factor grows as the piece reaches the ending. 
      It starts out non-existent, then gets too big. I saw no evidence in the data, but changed it to always 1% of the time_per_note. Sounds O.K. now.

✅    Work on the bass flute part. 
      The first decision is whether to use the same structures or create new ones. For example, I'll need the equivalent of note_dict, verse_array, gliss_array, octave_array, env_array, and the others. The goal is to build notes_features with the right timing so they will synchronize with the vamp. The current function create_vamp is passed some timing values. Prove that those are sufficient to synchronize with vamp.

      Here's the note_dict structure that is sent to piano_roll_to_notes_features:
            note_dict = {"note_array": verse_array,
                 "octave_array": octave_array,
                 "instrument_array": instruments, 
                 "upsample_array": upsample_array,
                 "envelope_array": env_array,
                 "velocity_array": velocity_array,
                 "volume_array": volume_array,
                 "gliss": gliss_array,
                 "tpq": tpq} 

      What should the woodwind note_dict look like? Can I use piano_roll_to_notes_features. I think so, perhaps with some minor changes to it.
            note_dict = {"note_array": wind_array,
                 "octave_array": wind_octave_array,
                 "instrument_array": wind_instruments, 
                 "upsample_array": wind_upsample_array,
                 "envelope_array": wind_env_array,
                 "velocity_array": wind_velocity_array,
                 "volume_array": wind_volume_array,
                 "gliss": wind_gliss_array,
                 "tpq": tpq} 

      So I've made bass_flute_creator, based largely on vamp_creator. 
      I turned repeat_each_note into repeating the notes in the trills. Selecting the trill based on repeat_each_note values. Trying to figure out how the various variables in common across the two note generating functions relate.
      
      repeat_each_note: 4 wind_array = np.repeat(wind_array, repeat_each_note, axis = 1). convert (4,1) to (4,4)
      tile_time_steps: 2 note_array = np.tile(note_array, tile_time_steps). convert (4,4) to (4,8)
      voice_multiplier: 2 note_array = np.tile(note_array, (voices // note_array.shape[0],1)). convert (4,8) to (8,8)
      What I need to do now is something with repeat_verse_array to make it as nearly 87.27 seconds long, just like the same inputs made vamp_creator. I'm only up to 16 seconds now. 
      Plus I need tempo to be honored. and tpq. 
      How is repeat_verse_array used in vamp_creator? This is the only place where it is done:
            verse_array = np.array([dmu.build_chords(mode, root, rng.choice(ranks, p = p), (inversion % 4) + 1) \
                    for inversion in np.arange(0,repeat_verse_array,1)]).T 
      Wouldn't it be nice if this worked:
            wind_array, wind_gliss_array = np.array([root_chord_slide(mode, root, this_combo, trill_type) for this_combo in choose_best_rank_inversion_combos(how_many = repeat_verse_array)]
      There are so many things wrong with this that I don't have a hope of fixing it. Fixed it.
            note_gliss_array = np.array([root_chord_slide(mode, root, choose_best_rank_inversion_combos(), trill_type) for _ in np.arange(repeat_verse_array)])
            print(f'{note_gliss_array.shape = }') # (8, 2, 4) (collection_of_arrays, note_array & gliss_array, each by 4)
            wind_array = note_gliss_array[:,0,:]
            wind_gliss_array = note_gliss_array[:,1,:] 
            print(f'{wind_array.shape = }, {wind_gliss_array.shape = }')

----------------------------------------------------------
11/3/22 To do today:

✅    Find out if the notes and the glisses are properly aligned. They don't sound right. Each note needs the right trill.
      Compare. Once I transposed the note and gliss arrays, it seems to be working ok. Except for the middle of two.

✅    It seems to be picking the right combination of notes and gliss values. 
      But for some reason the last note is half as long as the other notes.     
      i 1.0 20.0 10.0 60.252391614085106 36.0 3.0 6.0 5.0 1.0 801.0 1.0 1.0 799.0 799.0 25.62 ; 10 seconds
      i 1.0 30.0 5.0 59.0 44.0 3.0 6.0 7.0 0.0 803.0 1.0 0.0 799.0 799.0 25.0                   ; 5 seconds why?
      
      For some reason the first few notes on wind_array have 10 dumplicates, but the last has only 5 duplicates.
      I think there is something wrong with repeat_verse_array. Set it to 1 and you get 4 notes, 4 gliss. As expected.
      Set it to 2 and you only get 8 notes, but 8 gliss, as expected. But only 4 notes play, I think it's because the first two (note. gliss) pairs have the same starting rank, inversion. 
            best_rank_inversion_combos = np.array([["A", "A", 1, 2],["A", "A", 1, 4],["A", "A", 2, 1],["A", "A", 2, 3]
      Sure enough, the first two have the same note collection, rank "A" inversion 1. So I could shuffle them, or I could pick the combos better, or I could zip gliss with note, octave. That's what I should do. Fixed it.
      
✅    Instead of random inversion combos, select the same every time so I can track note and trills together.
            combo_set = np.array([0, 1, 2])
            note_gliss_array = np.array([root_chord_slide(mode, root, best_rank_inversion_combos[combo], trill_type) for combo in combo_set])
----------------------------------------
11/4/22 To do today:

✅    Find the bug with this issue:
      np.arange[repeat_verse_array = 3]
      ['A' 'A' '1' '2']
      ['A' 'A' '1' '4'] # this combo produces a weird set of note, gliss.
      ['A' 'A' '2' '1']
      (1.0, '16/9', 805.0)(805.0, '4/5')
      (1.0, '10/9', 806.0)(806.0, '5/6')
      (1.0, '4/3', 807.0)(807.0, '6/7')
      (1.0, '14/9', 804.0)(804.0, '7/8')
      
      These yield this set of ratios:
      64/45
      25/27
      8/7
      49/36
      When I just pick the A, A, 1, 4 by itself [1] it works perfectly. But when I pick [0, 1, 2] the ratios on [1] are flipped from where they should be.
      4/5 should be 5/4, 5/6 should be 6/5, 6/7 should be 7/6, and 7/8 should be 8/7. What do the chords A, A, 1, 4 look like?
      If I pick three combos, all [1,1,1] it does the right thing. But if I pick [0,1,2] is screws up [1]. 
      Perhaps there is something wrong with the function that checks if a gliss has already been stored. It's like it doesn't store the gliss for combo[1]. It only stores 8 gliss arrays, and the second 4 are correct for combo[2], but not for combo [1]. The one required for combo[1] is missing from the gliss_array. 

      There are 3 places where this screw up could happen.
      1.    dmu.build_slides - no errors found there
      2.    In the root_chord_slide - No errors found there
      3.    In the piano_roll_to_notes_features - might not keep proper track of the zip notes, octaves, glass

      I need to confirm that the linkage between the gliss_array number, like 800, 801, 802 corresponds correctly with the note number, like 32, 36, 40, 44. The first four are correct, but the next four are wrong, and the final 4 are correct. The wrong ones would be correct if they were inverted. But if I ask for three of the same, they all come out correctly.

      Asked for [2,1,0] and 2 is wrong. It's supposed to be 
            tones_1 = array([36, 40, 44, 32]), tones_2 = array([32, 36, 40, 44]), gliss = array([800., 801., 802., 803.])
      Looking just at the output of root_chord_slide:
      36 down to 32 10/9 down to 16/9. It chooses gliss 800 for this trill. 800 is 4/5, it goes down to 8/9 with is 16/9, correct
      40 down to 36 4/3 down to 10/9. it chooses 801, which is 5/6, gets him to 10/9 which is correct
      44 down to 40 14/9 down to 4/3. It chooses 802, which is 6/7, gets him to 4/3 which is correct
      32 down to 44 16/9 down to 14/9. It chooses 803, which is 7/8, gets him to 14/9 which is correct. 
      
      Here is what root_chord_slide provides:
            tones_1 = array([32, 36, 40, 44]), tones_2 = array([44, 32, 36, 40]), gliss = array([803., 800., 801., 802.])
      32 down to 44 16/9 down to 14/9. It chooses 803, which is 7/8, gets him to 14/9 which is correct.
      36 down to 32 10/9 down to 16/9. It chooses gliss 800 for this trill. 800 is 4/5, it goes down to 8/9 with is 16/9, correct
      40 down to 36 4/3 down to 10/9. it chooses 801, which is 5/6, gets him to 10/9 which is correct
      44 down to 40 14/9 down to 4/3. It chooses 802, which is 6/7, gets him to 4/3 which is correct
            tones_1 = array([32, 36, 40, 44]), tones_2 = array([36, 40, 44, 32]), gliss = array([804., 805., 806., 807.])
      32 to 36 16/9 to 10/9 chooses 804 for this 5/4
      36 to 40 10/9 to 4/3 chooses 805 6/5
      40 to 44 4/3 to 14/9 chooses 806 7/6 
      44 to 32 14/9 to 16/9 chooses 807 8/7 All correct.

      And yet, when we reach csound the first note 36 is assigned 803, which is wrong. 
      So the mistake doesn't happen in root_chord_slide, it happens after that, before getting to csound.
      Here is wind array after generating the gliss values:
      wind_array = array([[36., 32., 32.], tracker 20
                        [40., 36., 36.], tracker 21
                        [44., 40., 40.], tracker 22
                        [32., 44., 44.]]) tracker 23
      wind_gliss_array = array([[800., 803., 804.], 
                              [801., 800., 805.],
                              [802., 801., 806.],
                              [803., 802., 807.]])
      For each of the three chords, it has the correct note and gliss values. 

      Now I am wondering if I need to transpose the array at some point. I confirmed that I have to transpose it once after it comes out of root_chord_slide, but do I need to do it again?
      Here is the structure in piano_roll_to_notes_features each of four voices. These are the soprano, alto, tenor, bass parts, each with three notes. Here is what we see inside piano_roll_to_notes_features:
            voice = array([36., 32., 32.])  gliss = array([800., 803., 804.]) soprano voice assigned to tracker number 20
            voice = array([40., 36., 36.])  gliss = array([801., 800., 805.]) alto voice_array tracker 21
            voice = array([44., 40., 40.])  gliss = array([802., 801., 806.]) tenor voice tracker 22 
            voice = array([32., 44., 44.])  gliss = array([803., 802., 807.]) bass voice tracker 23 

      If piano_roll_to_notes_features does what I expect, it will read all the notes from the first voice, then all the notes from the second voice, and so on until all the vocies are processed. I'm hearing three notes, but the middle one has the wrong trill value.

      after piano_roll_to_notes_features, here are the notes and the gliss #s
      The notes are right but the glisses are all wrong:
            [ 36. 803.] tracker 20 gliss shoujld be 800, 803, 804
            [ 32. 804.] "
            [ 32. 804.] "
            [ 40. 800.] tracker 21
            [ 36. 805.] "
            [ 36. 805.] "
            [ 44. 801.] tracker 22
            [ 40. 806.] "
            [ 40. 806.] "
            [ 32. 802.] tracker 23
            [ 44. 807.]
            [ 44. 807.]

      I think I found the problem:
             notes_features[output_inx] = \
                  np.array((1, duration + z, hold, velocity[-1], prev_note[0], prev_note[1], voice_num, stereo, \
                        envelopes[input_voice_inx, -1], glx, upsample[input_voice_inx, -1], \
                        envelopes[input_voice_inx, -1], 799, 799, volume[-1]))
      That should have been not glx, but prev_note[2], like the note is prev_note[0] and octave is prev_note[1].
      But when I made that change I got: tuple index out of range on the line with the prev_note[2]:
            ---> 57                               envelopes[input_voice_inx, input_note_inx], prev_note[2], upsample[input_voice_inx, input_note_inx], \

      I had assigned to prev_note without including glx:
            prev_note = (note, octv, glx) #<-- was missing the glx, so when prev_note reached the critical spot, prev_note only had two values, and I was asking gfor the third. Fixed it. That was a bear. Several bears, all in piano_roll_to_notes_features.

--------------------------------
11/5/22 To do today: Grampy day with Bea 

--------------------------------
11/6/22 To do today:

✅    Update the anaconda stack on my T480. 
            mamba update --all
      Takes a long, long time.
            jupyter --version
                  jupyter core     : 4.7.1
                  jupyter-notebook : 6.4.11
                  qtconsole        : not installed
                  ipython          : 7.26.0
                  ipykernel        : 6.2.0
                  jupyter client   : 6.1.12
                  jupyter lab      : 3.4.2
                  nbconvert        : 6.5.0
                  ipywidgets       : not installed <-- this might be useful for interfacing with ctcsound. I can't find any reference to this, except this: 
                  https://notebook.community/scotgl/sonify/ver_0.7/v0.7_Panned_Pulse_Test
                  nbformat         : 5.4.0
                  traitlets        : 5.0.5

✅    I'm wondering if I should make an array of (features, voices, notes), where each number is a feature, like note, octave, volume, gliss, etc.
      I could stack them together (axis = 0) and pass that to piano_roll_to_notes_features:
            note_array = np.stack((verse_array, octave_array, gliss_array, upsample_array, env_array, velocity_array), axis = 0)
      But then how do I unstack them? Well, there is no special (voices, notes) relationship is there? 
      One way is just to reshape them, but that destroys the (voices, notes) relationship if there is one. 
            note_array = note_array.reshape(note_array.shape[0], -1) # from (6, 16, 456) to (6, 7296) where the 6 are the 6 different features.
      Another way is to use the list(zip(*note_array)) operator to split the arrays back into separate ones.

✅    There are lots of ways to initialize a two dimensional (voices, notes) type array to use as octave, volume, envelope, etc.      
      Here are a few:
            octave_array = build_octave_array(verse_array, spread = 6, add = 0) # some will be zero - this takes advantage of some customer coding for octaves, which allows me to clump together notes in the same octave. I don't see how this could apply to other features
            env_array = rng.choice([8,1,2,0,16], size = verse_array.shape) # we randomly assign the set of envelopes across the (notes, features) of a given shape.
            upsample_array = rng.choice([254, 255, 0, 1, 2, 3], size = verse_array.shape) # assigned like th env_array.
            wind_velocity_array = np.full(wind_array.shape, 54) # one value for all the velocity. I don't like that, because I want each instrument to have a different velocity
            volume_array = build_density_function(np.array([25, 27, 28, 30, 28, 26, 25]), verse_array.shape[1]) # This is not (voices, notes), it's just notes. Designed to control volume from start to finish with one set of values.
            gliss_array = np.full(verse_array.shape, 799, dtype = int) # assigned early, then repeated and densified along with the notes.

✅    Some tasks to complete:
      a.    Make velocity and volume the same dimension as notes, octaves, gliss. I will need to get a different array to provide the gradual change on volume over time. I used to have an "a" operator in samples.pas, that would handle the gradual increase over the course of the piece, separate from the notes volume. Another option is to have volume provide that gradual volume control function, while velocity would be used to choose which sample to use (for the bosensorfer) or the control over the instruments having different velocity levels. I completed that.

      b.    Combine all the same dimensional variables into the zip process. Completed that.

      c.    Compare some options:
            x.    Should you combine existing (voices, notes) into one larger structure before sending them to piano_roll_to_notes_features
                  I don't like that idea because you have not yet assigned a start time.
            x.    Should you combine existing (notes, features) into one larger structure before sending them to fix_start_times.
            yes:  Should you combine the (notes, features) after fix_start_times, before send_to_csound_file <-- this is what I plan to try first.
-------------------------------
11/7/22 To do today:

✅    Make sure the timing between the winds and the percussion is the same duration.
      So I've started that. Both of the note generating functions have a parameter called init, which if true sets the following:
            if init:
                  init_voice_start_times() # start from the begining
                  stored_gliss = dmu.init_stored_gliss() # resets the global glissando array and the global current_gliss_table variable to 800
      If I set it to init=True, all works as expected starting at time zero. But if I follow that by running the same note generating function with init=False, csound starts playing after a minute. The csound input file new_output.csd:
                  Inst Start          Hold          Vel                Ton   Oct   Voice Stere Envlp Gliss Upsamp R-Env 2nd-gl 3rd Volume
                  i 1.0 114.0 1.5 54.68912583950285 44.0 1.0 1.0 16.0 0.0 799.0 3.0 0.0 799.0 799.0 25.30130583505545 
                  i 1.0 114.0 1
      Starts at 114 seconds, which is the value at the end of the previous run. The reason is that when you call the function send_to_csound_file, that writes a new csound file as if the previous one is still there. So the key is to create all the structures you need, then call send_to_csound_file. I'm thinking I need to preserve what I have and create a new notebook to start refactoring the route through the process.
      Saved the current status as: Diamond_music_percussion_winds_separate.ipynb
      Created a new version as: Diamond_music_merge_percussion_winds.ipynb
      
      Decision time:
      This is what I think the new structure should be:
            What has to be done in the process:
                  generate notes in a structure of (voices,notes)
                  make them have more notes using these values:
                        repeat_verse_array, repeat_each_note, tile_time_steps, voice_multiplier, instruments (not sure about that one)
                  Build the other required values in the right structures: octave, upsample, envelope, volume, velocity, and gliss
                  Each of these need to be the same dimensions as the notes (that is not the case for volume and velocity)
                        This will require some work to be done. This will allow balance to be made between the instruments, which is not possible now
                  piano_roll_to_notes_features takes those and creates a new array of (notes, features) using the values in the note_dict structure. 
                        This will require modification to take additional notes after the first time through. 
                  At present, the critical values and their status:
                        duration: assigned based on tpq values, combined notes have longer durations
                        hold: same as duration plus a little bit 
                        velocity: switched to have shape (voices, notes)
                        notes: shape (voices, notes) assigned to the value of the prev_note[0]
                        octave: shape (voices, notes) assigned to the value of the prev_note[1]
                        voice_num: assigned the time_tracker_number in the voice_time[inst] structure. This will be changed in fix_start_times, which calls show_voice_time_short_name to determine the csound_voice number
                        stereo: random number invented in piano_roll_to_notes_features
                        envelopes: shape (voices, notes)should be made part of the zip method and assigned as prev_note[x]
                        gliss: shape (voices, notes)assigned to the value of the prev_note[2]
                        upsample: shape (voices, notes)should be made part of the zip method and assigned as prev_note[x]
                        r_envelope: shape (voices, notes)should also be made part of the zip method - same as left envelope for now
                        2nd gliss: hard coded for now as 799
                        3rd gliss: hard coded for now as 799
                        volume: same as velocity
                  
                  This is where we could have a new function that combines output from piano_roll_to_notes_features from multiple sources.
                  Create a sink that can hold notes_features items prior to fixing their start times. 

                  assign start times based on the sum of previous notes durations:
                        fixed_start_time = fix_start_times(voice_features)
                  send the finalized (notes, features) array to csound:
                        voice_features = send_to_csound_file(fixed_start_time, tempos = 't0 ' + str(tempo))
                  call csound with the final output

            note generating functions:
                  responsible for generating notes, but not yet up

      I'm leaning towards combining arrays of (notes, features) after piano_roll_to_notes_features but before sending them to fix_start_times. That's the next project. Time to go to the grocery store.

      Where should it go? Current flow:
            call the note generator, with some timing variables, to return (notes, features)
                  vamp_creator
                  bass_flute_creator 
                  hot_brass_creator (not yet made, will be woodwinds)
            merge the (notes_features) across the note generators all with the same timing variables
            call fix_start_times
                   notes_features = fix_start_times(notes_features)    
            call the last masking
                  density_function = build_density_function(density_input, notes_features.shape[0])
                  notes_features = masked_notes_features(notes_features, density_function) # 
            call the send_to_csound_file with the final notes_featuers
                  notes_features = send_to_csound_file(notes_features, tempos = 't0 ' + str(tempo), tempo = tempo)
        
----------------------
11/8/22 To do today:

✅    Build the skeleton for the hot_brass_creator function. Just for timing purposes for now.

✅    Test some other vamp_creator_combos[choice]

✅    Spread out the bass flute glides

✅    Tighten up the synch between the note generators. Toward the end of the piece they are out of synch.

      So I've completed yesterday's work, and it's clear that the durations are not the same, but are very close.
            
      Not such a big problem because I haven't worked on the timing of the bass flute. It's way too quiet.
      But in any case, I'll need a way to match the timing between the instruments. 
            bass flute part:
                  repeat_verse_array = 10, repeat_each_note = 2, tile_time_steps = 3, voice_multiplier = 1, tempo = 100
            percussion part:
                  repeat_verse_array = 10, repeat_each_note = 2, tile_time_steps = 3, voice_multiplier = 1, tempo = 100
            So the inputs are the same. 
            What are additional variables I can use. What about tpq?
                  percussion: In ticks: 114.01 in seconds: 68.4
                  wind_instruments: In ticks: 119.94 in seconds: 71.96
            Another try:
                  In ticks: 114.01 in seconds: 68.4
                  In ticks: 120.06 in seconds: 72.04
            Four seconds difference in only 72 seconds is unacceptable.
            Much closer by setting tpq = 2 in call to piano_roll_to_notes_features. This may be good enough.
      I remember many weeks ago I spent a few days on the extend function, making sure that the extending was spread equally across all the voices. extend() processes a (notes, features) structure. I think it needs to work before fix_start_times. It changes the durations in (notes, features) and uses the voice_number to spread across all the notes. 
            def extend(note_array, min_dur, max_dur, budget = 0.10, likelihood = 0.20):
            extend_max = 8
            min_dur = 0.25
            winds = extend(winds, min_dur, extend_max, budget = 20.0, likelihood = 0.9) # these knobs don't have a reliable control
            The results were dismal. 

------------------------
11/10/22 To do today

✅    Eliminate the diversion of timing between persussion and wind_instruments.
      Reduce the size of each section to improve synchronization. 
      Once I set the envelope to 2 and increased the velocity from 54 to 70, I could hear that they are perfectly synchronized. The bass flute does extend for 4 seconds after the percussion, but all the downbeats appear on time.

✅    There are two masking supported at this time:
      masked_voices_notes - this creates zeros in the octave array based on a random density_function of the same dimension as the note_array, (voices, notes).
      masked_notes_features - this creates zeros in the hold values. Input must be (notes, features).

      Both execute the note elimination in the send_to_csound_file function:
            fixed_winds = np.array([row for row in fixed_winds if row[2] > 0]) # preserve non-zero hold value
            fixed_winds = np.array([row for row in fixed_winds if row[5] > 0]) # preserve non-zero octave value
      
      I think I have a bug in masked_voices_notes. It should use a density_function that is the same size as the second dimension of the octave_array. It was checking against the first dimension. Fixed it, but haven't determined the effects this has downstream. I haven't been using this function much lately. (at all.)
      
✅    Finish the hot_brass_creator function:
      It needs to be able to mask the unwanted notes, not in a random fashion, but deliberately in patterns.
      I could mask in masked_voices_notes, but it expects an octave array and a density function.
      I need one that will use pattern masking of the octave_array.

      brass_array.shape = (4, 20)

                                            1                           
              0  1  2  3  4  5  6  7  8  9  0  1  2  3  4  5  6  7  8  9
            [40 38 32 46 46 32 38 36 34 32 42 40 34 36 42 44 32 34 44 46]
            [44 42 36 34 34 36 42 40 38 36 46 44 38 40 46 32 36 38 32 34]
            [32 46 40 38 38 40 46 44 42 40 34 32 42 44 34 36 40 42 36 38]
            [36 34 44 42 42 44 34 32 46 44 38 36 46 32 38 40 44 46 40 42]

      I'd like a mask like this to go against the octave_array.
            [ 1  1  1  0  0  0  1  0  0  1  0  0  0  1  1  1  0]
            [ 1  1  1  0  0  0  1  0  0  1  0  0  0  1  1  1  0]
            [ 1  1  1  0  0  0  1  0  0  1  0  0  0  1  1  1  0]
            [ 1  1  1  0  0  0  1  0  0  1  0  0  0  1  1  1  0]
      
      What I want is to create an octave_array that has zero where I want silence, and 1 where I want it to sound, then multiply the mask times the octave_array.
            octave_array = octave_array * mix_mask # multiply octave values by zeros to erase a percent of the notes
      That means I first need the octave_array, which consists of (voices, notes) with octave values from 1 to 8 or so. This is created by build_octave_array:
            octave_array = build_octave_array(verse_array, spread = 3, add = 1) # min 1, max 5, avg 2
            rng.shuffle(octave_array, axis = 0) # axis = 0, preserve clumps axis = 1 means the clumps are destroyed
      Next step is to create a function that will accomplish this change to the octave array on behalf of hot_brass_creator. 

--------------------------
11/13/22 To do today:      

✅    Work on the mask described yesterday.
      a. start before the note duplication processes so you have the dur=0.25 speed, or set repeat_each_note = 1, tile_time_steps = 1, voice_multiplier = 1, repeat_verse_array, to 10:
            repeat_verse_array = 10, repeat_each_note = 1, tile_time_steps = 1, voice_multiplier = 1, tempo = 100, choice = 0, density_input = array([0.4, 0.7, 0.8, 0.6, 0.4])

      b. Build a validation mask to test against, then a function that will build it automatically. 
            Test driven development

      c. What if the mask is not exactly equal in shape to the object being masked? Numpy has broadcasting rules.
            example: octave_array shape = (4,100)
                  pattern shape = (4,20)
            These are not broadcastable. They must be equal or one of them must be one.
            Can't broadcast arrays of shape (100,) and (20,) either. But this is not really what I want to do.
            
      d.    What I really want is to have a set of very interesting riffs that include chords, envelopes, velocities, which can be chosen easily, and blend with the overall mood of the piece. I think I have the first cut of this. But I'm having challenges matching the ticks that the bass flute and the percussion are able to achieve. I'll have to look at the def extend function for the method used to chop off extra notes.

----------------------------
11/14/22 To do today:

✅    Finish up the hot_brass_creator function.
      Try using the extend function. Notice that it clumps 72 notes all starting at time zero. 
      That doesn't seem right. I think it's because it's expecting integers, not 0.25 as the minimum 
            potential_factor = rng.integers(low = min_dur, high = max_dur, size = None, endpoint = True, dtype = int) # what might you extend them by
      There's your trouble. I'm looking for a float value between min_dur and max_dur
            potential_factor = rng.random() * (max_dur - min_dur) + min_dur
      It really destroys the rhythm. It tries to use up the budget early, then sounds good from there on out.

✅    Work on the bass flute part by incorporating the hot_brass_creator use of the three arrays to contol dropouts, envelopes, and velocity 
            #                            0           4           8          1
            brass_oct_patte = np.array([ 1, 1, 1, 0, 1, 0, 0, 1, 1, 0 ... ])
            brass_env_array = np.array([ 8, 8, 8, 0, 8, 0, 0, 8, 8, 0 ... ]) 
            brass_vel_array = np.array([65,65,65, 0,65, 0, 0,55,65, 0 ... ]) 
            
      Actually, I think I need something different for this section. What do I need?
      a.    Completely drop a trill, all notes simultaneously
      b.    Support just a straight chord without a trill.
      c.    What about slides? Use these. Each divides up the 256 data points differently, going from a fast slide to a very slow slide
            'cubic16_16_224'
            'cubic32_32_192'
            'cubic64_64_128'
            'cubic96_96_64'
            'cubic112_112_32'
      d.    Make it possible to select a variety of envelopes. Could be random.
      e.    I completely ignored that the repeat_each_note value is the same for all the trills. It's only called once and used for the entire section. Not what I expected.
            I made the change to choose a trill once for each chord pair. Sometimes those are only one pair. It all depends on the size of combo_set, which in turn is set by repeat_verse_array.  
      f.    I could chop the notes_features array at the point where the last note starts in the minimum voice.
      g.    Now I noticed that if the the csound doesn't seem to contain all the notes.
                  Brass. In ticks: 120.01 in seconds: 80.01
                  Percussion. In ticks: 114.01 in seconds: 76.01
                  Winds. In ticks: 179.95 in seconds: 119.97
                  Ticks across all voices. 180.14
                  start_times:
                  minimum_perc_start_time = 113.96
                  minimum_wind_start_time = 179.75
                  minimum_bras_start_time = 119.97
                  desired cut_off = 113.96510204081635
            yet the last start time was 119.97, which is the last note. I fixed this by creating a prune function that chopped at the last note of the shortest voice.
                  notes_features = np.array([features for features in notes_features if features[1] < cut_off])

-----------------------------
11/15/22 To do today:

✅    Make some music for a change. But first fix the problems identified yesterday.
      a.    Problem with reshape in hot_brass_creator:
                  choice = 7
                  repeat_verse_array = 8, repeat_each_note = 4, tile_time_steps = 2, voice_multiplier = 1, tempo = 110, choice = 7
                  combo_set = array([14, 12, 15,  9,  8, 11, 10, 13])
                  brass_octave_array.shape = (16, 128)
                  brass_array.shape = (16, 128) # this might as well be reshaped to 16 * 128 = 2048
                  The divisor of 2048 less than 44 is 32, not 42. What went wrong?
                                    128          // (128 // 44) = 2.+ 1 = 3 = 42
                  chop_at = brass_array.shape[1] // (brass_array.shape[1] // brass_oct_patte.shape[0] + 1)
                  This should be
                        chop_at = largest_evenly_divisible(brass_array.size,brass_oct_patte.shape[0])
                  reducing the length of brass_oct_patte to chop_at = 32
                  
      b.    The trills are not in rhythm with the percussion. For example, when choice = 7, repeat_each_note = 4, trill_type = trill_4_step.
            Is it due to modifying the repeat_each_note variable?
                  tpq = 3
            There's your trouble. Make it a multiple of 2.

      c.    Another problem with array sizes.
            choice = 11
            repeat_verse_array = 3, repeat_each_note = 5, tile_time_steps = 2, voice_multiplier = 2, tempo = 100, choice = 11
            combo_set = array([ 8, 10,  9])
            brass_octave_array.shape = (32, 60)
            brass_oct_patte.shape = (44,)
            brass_array.shape = (32, 60) <-- 32*60 = 1920
            reducing the length of brass_oct_patte to chop_at = 40
            brass_oct_patte.shape = (40,) <-- 1920/40 = 48
            multi = 32 <-- why 32, should be 40, right?

             ---> 52     brass_oct_patte = np.tile(brass_oct_patte, multi).reshape(brass_array.shape)
                  53     brass_env_array = np.tile(brass_env_array, multi).reshape(brass_array.shape)
                  54     brass_vel_array = np.tile(brass_vel_array, multi).reshape(brass_array.shape)

            ValueError: cannot reshape array of size 1280 into shape (32,60)
            I think this fixed it:    
                  multi = brass_array.size // chop_at
            Another failure at choice = 22
            repeat_verse_array = 1, repeat_each_note = 12, tile_time_steps = 1, voice_multiplier = 2, tempo = 110, choice = 22
            chop_at = 32
            brass_oct_patte.shape = (24,) <-- if the pattern is longer than the brass_array, it chops the pattern to the length of the brass_array
            but that causes downstream patters when it tries to reshapt the pattern
            brass_array.size = 768
            multi = 24
            768 / 32 = 24
                multi = brass_array.size // chop_at

                  ---> 54     brass_oct_patte = np.tile(brass_oct_patte, multi).reshape(brass_array.shape)
                        55     brass_env_array = np.tile(brass_env_array, multi).reshape(brass_array.shape)
                        56     brass_vel_array = np.tile(brass_vel_array, multi).reshape(brass_array.shape)

                  ValueError: cannot reshape array of size 576 into shape (32,24) <-- 32*24=768

      d.    New problem. I think I should prune as late as possible, but I think I already am:     
                  notes_features = prune(notes_features)
                  notes_features = send_to_csound_file(notes_features, tempos = 't0 ' + str(tempo), tempo = tempo)
            But I could prune inside send_to_csound_file.
            Here are the symptoms that need to be addressed:
                  before chopping the extra notes. notes_features.shape = (13200, 15)
                  after chopping the extra notes. notes_features.shape = (9722, 15)
                  last note ends: round(60*limit/tempo,1) = 72.0 seconds
                  In send_to_csound_file after selecting for non-zero hold values. notes_features.shape = (2974, 15)
                  after selecting for non-zero octave values. notes_features.shape = (2696, 15)
                  After send_to_csound_file. notes_features.shape = (2696, 15)
      
      e.    Bass flute is too loud, too few low notes. Fixed that. 

-------------------
11/19/22 To do today:

✅    Consider some alternatives to making the piece more musical:
      a.    Take a short 10-20 second snapshot of one part of the existing (notes, features) prior to send_to_csound_file and tile the heck out of it.
      b.    Find a way to accurately calculate the duration of each note generating function, given the input variables, plus the various multiplications,
            If I can do this, I can make them all the same earlier in the process. 

      Here is how the percussion shapes should be calculated.
      Example:
            choice = 0, repeat_verse_array = 10, repeat_each_note = 2, tile_time_steps = 3, voice_multiplier = 1, tempo = 100, choice = 0
            1.    generate a tetrad shape is (4, repeat_verse_array) (4,10)
            2.    concatenate 6 of those with 2 scales creating shape is (4, 6 * repeat_verse_array + 2 * 8) (4, 76)
            3.    take step2 and repeat each note by repeat_each_note (4, 4 * step2) (4, 152)
            4.    densify does two things: np.tile by tile_time_steps (4, tile_time_steps * step3) (4, 3 * 152) (4, 456)
            5.    increase the voice dimension by number of voices (32) divided by input note_array shape[0] (4) (4 * 8, 456) (32, 456)
            5.    Send the result to piano_roll_to_notes_features
      Here is how to bass flute shape should be calculated.
      Same example:
            choice = 0, repeat_verse_array = 10, repeat_each_note = 2, tile_time_steps = 3, voice_multiplier = 1, tempo = 100, choice = 0
            1.    generate some chord pairs based on the maximum of repeat_verse_array, repeat_each_note, tile_time_steps, voice_multiplier (4, 10)
            2.    repeat by repeat_each_note 2 (4,20)
            3.    tile by tile_time_steps 3 (4, 60)
            4.    multiply by voice_multiplier 1 (4,60) <-- should only affect total_shape_0, not total_shape_1
            5.    Only use repeat_verse_array if it's the maximum of all input variables.
            Another example:
            repeat_verse_array = 1, repeat_each_note = 12, tile_time_steps = 1, voice_multiplier = 2, tempo = 110, choice = 22, combo_set = array([8])
            1.    max is 12
            2.    repeat each note 12 (4, 144)
            3.    tile 1 (4, 144)
            4.    voice_multiplier 2 (8, 144)
      Here is how the hot_brass_creator should be calculated.
      New example:
      choice = 2, repeat_verse_array = 15, repeat_each_note = 2, tile_time_steps = 2, voice_multiplier = 1, tempo = 80, choice = 2, combo_set = array([16, 20, 17,  9, 15, 18, 10, 13,  8, 21, 14, 19, 11, 22, 12])     (15)
            1.    Create chord pairs based on the size of combo_set parameter passed to hot_brass_creator 15 chord pairs (15, 2, 4) reshaped to (4,30)
                  combo_set size is equal to repeat_verse_array.
            2.    densify does two things. np.tile by time_steps * repeat_each_note 2*2 = 4 4 * 30 = 120 (4, 120)
            3.    increase the voice dimension by instruments.shape * voice_multiplier * 16. 4 * 4 * 4 = 64
            4,    end up at (64, 120)

✅    Is it worth looking at a different architecture at this point? I'm not happy with the results so far. 
      I'm thinking I should try an approach where I build all three voices at the same time, instead of theorizing what will sound good at the end based on intermediary steps. Don't move forward until all voices sound good together. You can still use some of the material, but not all of it.
      For example:
            note_generating_functions that do very little.

--------------------------------
11/20/22 To do today

✅    Make just one measure of a good intro collection. 
      A solid bass line, a nice choppy rhythm-guitar-like background using finger piano and balloon drums, a counter rhythm on woodwinds imitating a horn section, and a easy bass flute trill with an interesting envelope. Imagine you are building an into do a very sexy Sade track. Something she would use to set the mood before she starts singning.

      Think of it as a form of test driven development. Your job is to create a set of (notes, features) with durations coming out of piano_roll_to_notes_features. Which means you need note_array consisting of a stack of notes, octaves, gliss, upsample, envelopes, velocities. Have a target be this as the end of a collector function:
            note_array = np.stack((wind_array, wind_octave_array, wind_gliss_array, wind_upsample_array, wind_env_array, wind_velocity_array), axis = 0)
            print(f'{note_array.shape = }')
            notes_features = piano_roll_to_notes_features(note_array, wind_volume_array, instruments, tpq)   
            print(f'After piano_roll_to_notes_features. {notes_features.shape = }')
            return notes_features

      Use this order:
            note generating functions for chords, slides, scales, bass line, melody.
            collector function that calls these note generating functions for all instruments using the current root, mode, rank collection, tempo, time signature
            stacking function for all the features: notes, octaves, durations, envelopes, volume, velocity, gliss, tracking voice.
            piano_roll_to_notes_features to convert matching arrays (voices, features) into (notes, features)
            fix_start_times to transform durations into start times and assign csound voice from tracking voice
            density adjustment function to mask and hide notes arbitrarily
            send_to_csound_file to convert (notes, features) into csound input file 
            call to csound to process generated file.

      Things to change compared to the current structure:
            a.    assign the voice in the collector function, so you know who is going to play the notes you are assembling
            b.    stacking function should also stack the voice for the (voices, features) arrays
            c.    change piano_roll_to_notes_features to take the assigned voice instead of doing the assignment itself 
            d.    create the collector function. At first just to make one measure, but make it possible to expand on some way.
            e.    make a note generating function that can make a bass line
            f.    make a note generating function to make a melody 
            g.    Decide if you are going to keep the piano_roll (voices, notes) structure, or move to a more explicit (notes, features) set of arrays.
                  1.    for (voices, notes): 
                        you can delay the creation of durations until later, and just count notes to make sure you are synchronized 
                        you can easily keep chords together as their appearance at a point in the piano_roll shows they play at the same time

                  2.    for calculating dur and hold, putting them in an array stacked into a note_array = np.stack(arr1, arr2, arr3)
                        You could have another array with duration and hold and just stack that with all the others. 
                        Which one would be easier when creating the measure? Try both.

✅    Note generating functions so far:
            chop_creator(repeat_verse_array) - builds as many 4 note chords as you want. pass the number of chords. returns (voices, notes) with note numbers 
            scale_creator(repeat_voices) - build as many unison scales. specify number of voices. returns (voices, notes) with note numbers
            slide_creator(slide_chord_pairs) - builds as many chord_pairs as you'd like across four voices. returns a tuple, notes (voices, notes) and glisses (voices, gliss#)
            horns_creator(slide_chord_pairs) - builds as many chord pairs from combo_set as you need. uses best_rank_inversion_combos. returns (voices, notes) number of notes returned is 2 times slide_chord_pairs. Use in pairs.
            bass_line_creator(note_count) - builds an interesting bass line. 
                  Returns (notes, octaves, envelopes) as many as it wants
                  It could also return (notes, octaves, envelopes), where if the note doesn't change, it means it is held, and octave = 0 means silence. I'm going with the latter first. returns 1 dimensional arrays: notes, octaves, envelopes)
                  
---------------------
11/21/22 To do today:

✅    Convert the note numbers in the bass_flute_creator into relative scale positions.
      Here are the scale positions:
      Bb    C     D     Eb    F     G-    Ab    A 
      0     1     2     3     4     5     6     7
      16/9  1/1   10/9  11/9  4/3   13/9  14/9  5/3
      32    34    36    38    40    42    44    46

      Here is the bass line - notice #43 G 3/2 is not in the rank A or B scale. It's in C and D though. 
      1     1     1     2     1     1     1     1     1     1     1     1     1     1     1     1
      Ab                C     F                Bb    G     Eb          D           C           C 
      14/9              1/1   4/3              16/9  3/2   11/9        10/9        1/1         4/3  
      44    44    44    34    40   40    40    32    43    38    38    36    36    34    34    40

✅    What is the chop at the end of every note? It's like the envelope is whack. What envelopes were used:
      8 f296
      2 f290 <-- I made some changes to this but I don't know if it solved the problem.

-----------------------------------------
11/22/22 To do today:

✅    Add a baritone guitar to the bass line. 
      That means you need another set of samples, so you will need to rebuild ball3.csd.
      Dangerous. Oh how very dangerous. The addition of one more instrument included sample files as #799, that I was saving for the flat glissando. Commented them out. Still segmentation faults. It doesn't like a bunch of my f tables, even though I didn't change any of them.

            error in score.  illegal opcode t (ASCII 116)
            ftable 3: illegal gen number
            f  3     0.00     0.00   256.00  256.00 ...
            ftable 4: illegal gen number
            f  4     0.00     0.00  1025.00 1025.00 ...
            ftable 298: illegal gen number
            f298     0.00     0.00  1025.00 1025.00 ..
            Lists a bunch more then segmentation faults at this one:
            ftable 601: illegal gen number
            f601     0.00     0.00   128.00  128.00 ...
            ftable 602:
      I don't see anything illegal about my gen numbers. I removed the baritone guitar samples and that made no difference. 
      Now the live csound works fine, including the baritone guitar, but the new_outout.csd fails with segmentation fault. I can't find anything that would cause the illegal opcode errors
      It looks like to source of the problem wasn't the extra CsoundSynthesizer tag, it was the t0 400 command. There was a blank before the t in t0, which appears to have made all the difference causing the segmentation fault. Yet that extra CsoundSynthesizer is new. Where did it come from? When I delete the line it continues to output no sound to the wave file. 
      The live csound stopped working now. And so does the csound to a wave file. 
      I just noticed this error to the console in Jupyter: 
            WARNING: Internal error in print_input_backtrace()
      Meanwhile, I have it creating csound to file successfully, the internal error went away.            
      The extra CsoundSynthesizer tag doesn't seem to cause problems. Where is it coming from? It's not being ignored with it is read in. There were some misplaced parentheses.
      There is still that click on the envelope 2 f290. I can live with it for now.
      How can I double the length of the section?
            note_array = np.tile(note_array, (2,1)) # turn a (6, 4, 32) array into a (6, 8, 32) doubles the length.
            (feature, voices, notes)
      A hard part is figuring out what should be included in a function or in the main line. Each voice will need it's own separate function. There is little I can reuse between them.

✅    Add a horn part. 
      I'd like to mask it with a smaller mask than the size of the note array, so the repeats are audible.
      I'll need to figure out the proper size of the mask such that I can make the mask of a size that has dimensions equally divisible into the octave array. For example, if the octave array is created to be the same size as the horn_array, (4,6) 3 pairs of 4-note chords, then mask could be (2,3) or (2,2). If the horn_array has 16 pairs, then it will be (4,32), and the mask could be any of (2,2), (2,4), (4,2), (4,4), etc up to (4,32). 2, 4, 8, 16, 32. What should it be? Later. I made a highest equal divisible function, 
            largest_evenly_divisible(array_size, max_number)

✅    So now I have a horn part and a bass line.
      I just need to combine them and send them to piano_roll_to_notes_features. 
      But first I must concatenate them, and they have to be the same shape for that to work.
      And how to I specify the instruments, each one is different. 

----------------------------------------
11/24/22 To do today:

✅    Change the horn part into a finger piano balloon flute part. 
      Or get rid of the masking. That's better used for percussion.
      Make a separate percussion chop part. But first get the synchronization right. 
      This is starting to sound good. Now add the horn part you were working on before.

✅    Figure out how to make sure each section is exactly the same length. Predictability is key.

      build_bass_line(repeat_section, notes, octv, env)
      repeat_section = 3
      input notes length = 32 
      tile by repeat_section 32 * 3 = 96
      bass_predicted = notes.shape[0] * repeat_section # 96 - three 32 sixteenth note measures

      build_arpeggio_part(repeat_section, repeat_notes... 3, 4
            voices = 8
            voice_multiplier = 2
            repeat_section = 3
            repeat_notes = 4
            repeat_all = 4
            np.repeat by repeat_notes  (4, 24)
            np.tile by voices // 4 = 2 (8, 24)
            tile by repeat_all 4 * 8 = 32 (32,24) 
            32 * 24 / 8 voices = 96
            arpeggio_predicted = repeat_section * repeat_notes * voices // 4 * repeat_section # 72

      build_horn_part(repeat_section, repeat_notes, octaves, env, voices)
            repeat_section = 2
            repeat_notes = 10
            repeat_all = 3
                  2                 10            2 
            mult = repeat_section * repeat_notes * 2 = 40
            voices = 4 
            then tile at the end of the build_horn_part by repeat_all 
            40     4//4          3   = 120
            mult * voices // 4 * repeat_all = 120
            horn_predicted = repeat_section * repeat_notes * 2 * voices // 4 * repeat_all # 120

      3 * 32 = 96
      3 * 4 * 2 * 4 = 96
      2 * 10 * 2 * 3 = 120

✅    What's next. I have the bass line, the horn chop, the finger piano and balloon drum percussion arpeggio. 
      Here's what I suggested earlier in the week:
      A solid bass line, a nice choppy rhythm-guitar-like background using finger piano and balloon drums, a counter rhythm on woodwinds imitating a horn section, and a easy bass flute trill with an interesting envelope. Imagine you are building an into do a very sexy Sade track. Something she would use to set the mood before she starts singning.
      So bass flute is next

            build_bass_flute_part(repeat_section, repeat_notes, repeat_all, octaves, env, voices)
      That was easy. But now it's way too dense.

      I need to be able to let each instrument rest for an extended period of time. Like play for a period of time, then rest for the same period as you just played.

-----------------------------------
11/25/22 To do today:

✅    Wrap Susie's birthday presents, make a card, figure out how to handle the Tuesday fridge delivery.

✅    Find a way to silence a phrase in the build_bass_flute_part function. 
      Just need to set the octaves for the right slices to zero.
      first must make it repeatable. Changed the combo_set to return np.array([8, 9, 10,11]).
      set the key_metric to 2.
      silenced the bass, arpeggio, horn with booleans. 
            bass_flute_predicted = 192
            repeat_section = 4, repeat_notes = 16, repeat_all = 3, mult = 64
            octaves.shape = (4, 64) 
      When it comes out of the initial note_generating function, after the gliss is separated from the notes, the notes look like this:
            note_array.shape = (4, 4)
      We will be working on the (4,64) array of octaves. This results from repeat_section * repeat_notes 4 * 16 and before the repeat_all has it happen three times. repeat_section is controlled by key_metric. 
      I'd also like to allow octave changes other than setting it to 0. I should be able to set it to +1 or +2.
      I can't preset the octaves array randomly, because every time it changes I get a new note to sound, some very short, which is uncontrollable. But I could set the values in the mainline of the program. Now it looks like this:
            octaves = np.full((voices, mult), 4, dtype = int)
      What if I made it into 4 sections of 16 slots each, I could set each slot independently.
            #                           octaves to choose from; initial_shape; odds of each choice; how long; how many voices
            octaves = np.tile(np.repeat(rng.choice([0,3,4,5], size = (4,1), p = [.4, .1, .3, .2]), repeat_notes), (4,1))
            print(f'{octaves.shape = }')
                  octaves.shape = (4, 64)
      Trying to do the same thing with the horn, and the result is nothing like with the bass flute. I need to go through the same process I did for bass flute. Need to understand the arrangement of the horn note generating function. 
            repeat_section = 4, repeat_notes = 8, repeat_all = 3, mult = 64, voices = 4
            key_metric = 2 
                  repeat_section = 2 * key_metric
            created original with repeat_section = 4. note_array.shape = (4, 8) # <-- initial output of note_generating_function
            So I start out with 4 voices of length 8. That is a unit.
                  octaves = rng.choice([0,3,4,5], size = (4,1), p = [.4, .1, .3, .2]) # (4,1)
                  octaves = np.repeat(octaves, repeat_notes) # (4,4)
                  octaves = np.tile(octaves, (4,1)) # (4,64)
            I think it might work if I use the initial size to be 98,1) instead of (4,1) - has to be same size as the initial output of the note_generating_function. 
                  octaves = np.tile(np.repeat(rng.choice([0,3,4,5], size = (8,1), p = [.4, .1, .3, .2]), repeat_notes), (4,1))
      I stopped testing with different key_metric, and now it only works with key_metric = 2
      key_metric = 3, fails in horn section octaves.shape is not equal to (4, mult). It looks like when I set the combo_set to a hard coded value, it screwed up the prediction for section length. Fixed it. Now I can set the key_metric to any of 2,3,4,5 for tempo = 100 and get the following durations. Of course, if I change the tempo, then other times will result.
            7: 1:40.5
            6: 1:26.4
            5: 1:11.7
            4: 0:57.6
            3: 0:43.2
            2: 0:28.8
            1: 0:14.4

--------------------
11/26/22 To do today:

✅    See if there is something you can do to make the horns more like what you originally intended.
      Lots of up down up, and chop chop. Maybe I'll have to hand taylor the octaves.

✅    Keep working on creating a function that can be repeatedly called. 
      Set the mode, root, and rank in each of the calls to the note_generating_functions. You will need to fix some of the note_generating_functions so they won't automatically pick the mode = "oton", root = "16/9", rank = "A"

✅    Add a few more note, octave, envelope pairs for the bass_line_creator. 
      Make them a structure with a throuple, many options deep that can be called.
      One in particular takes a chord in 1st inversion on rank A followed by a rank B with 3 beats on each for 24 out of 32 beats then hold 8 beats on F, or 4 beats on F, down an octave to the lower F. Or 4 F oct 3, 2 F oct 2, 2 F oct 1.

✅    What if I made a function that took in a text string to convert to note, octv, env.
      It would consist of a set of note numbers in a scale, octave, and envelope for each note and created the required throuple described in #3 above. Those are tedious to create, and so even when they are appropriate, I tend not to create them. Make them easier to build. Make your own tools, no one else will. Example:
            # Bb     D  F  Ab  C   f- G-  A   F.    F.  F. 
            n0o1e8d3 n2 n4 n6 n1o2 n3 n5 n7 n4o4d4 o3d2 o2 

------------------------------
11/27/22 To do today:

✅    Break the problem up. 
      _parse to parse a word, and arrays_from_text that calls _parse for each space separated word.
      To fill in the blanks, if a word is missing some features, automatically assume a prior value. This means you need to store prior values in the function that calls the decode word.
      Once it comes out of the parsing function, you need to convert any dur value greater than 1 into multiple note values. 
      What I want coming out of this is the equivalent to what I used as input to bass_line_creator:
            notes = np.array([6, 6, 6, 1, 4, 4, 4, 0, 5, 5, 3, 3, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4])
            octv = np.array([2,2,2,3,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2])
            env = np.array([8,8,8,2,8,8,8,2,8,8,8,1,8,8,2,2,16,16,16,16,16,16,16,16,16,16,16,16,16,16,8,8])
      Amazing. I wish I had done this earlier. about four hours to finish. Two functions: arrays_from_text(input_text), which returns notes, octaves, envelopes as an array ready to use in a note_generating_function, and _parse(word), which returns individual notes values for note, oct, env, dur, & hold. The latter two are consumed internally, with dur dictating how many notes are returned, and hold is ignored. 
----------
Time out to catch up on YourLearning.com assignments. More to do, but at least I'm current.      

--------
12/2/22 To do today:

✅    The horn part is perfectly awful. 
      I'm sure it meets the specifications I gave it, but it's useless in it's present form.
      Next step: 
      a.    Duplicate the new note generation used for the bass part:
                  input = "n6o2e8d3h0 n1o3e2d1 n4o2e8d3 n0d1e2 n5d2e8 n3d2 n2e8 n1e2 n0o1d12e16 n2d2e8 o2n4"
                  notes, octv, env = arrays_from_text(input)
            You will have to do it four times to assign all four of the instruments.
            Key measurements: 
                  building the horn line
                  horn_predicted = 672, repeat_section = 14, repeat_notes = 8, repeat_all = 3, mult = 224, voices = 4
                  in build_horn_part. mode = 'oton', root = '16/9', rank = 'A'
                  horn_note_array.shape = (6, 12, 224)
                  in piano_roll_to_notes_voices. Total notes to process: num_notes = 16128
                  horn_notes_features.shape = (1029, 15)
            So the build_horn_part produces an array of (6, 12, 224) from the given inputs. 
            mult = repeat_section * repeat_notes * 2 # <-- 14 * 8 * 2 = 224
            horn_predicted = 672, which is mult(224) * repeat_all(3)
      def build_horn_part() input: repeat_section = 14, repeat_notes = 8, repeat_all = 3, voices = 4
            output: array of (6, 12, 224) from the given inputs. 6 is the number of features that have been stacked
                  how does it go from 4 voices to 12? Number of voices is false. It's transformed into a repeated section by later functions.
                        note_array = np.tile(note_array, (repeat_all ,1)) # here it is. 
      def build_horn_from_text() input: repeat_section = 14, repeat_all = 3, note_array, octave_array, envelope_array, voices = 4
            output: array of (6, 12, 224) just like the other horn part.
            What shape should the note_array, and in turn the octave_array, and envelope_array be? (3, 28)
                  Can't be 224 / 3 #  that's 74.66667
                  224 / 14 = 16 # it's short, but it has to include the key_metric or it won't scale with the other instruments.
                  224 / 8 = 28 # just right but it's missing the scaling factor key_metric
      def build_horn_from_text(repeat_section, repeat_all, note_array, octave_array, envelope_array, voices, mode = "oton", root = "16/9", rank = "A"):

-------------------------      
12/4/22 To do today:

✅    I need to find a way to create more variations and reduce the repetitions. 
      When repeat_section is 14, that's never going to work. Here is what I am doing now, which results in repeat_section (14) exact copies of the note_array:
                  note_array = np.tile(note_array, (repeat_section, 1)) # (6, 56, 16) # 6 features, 56 voices, 16 notes
      I need to find a way to roll the (note, octv, env) arrays for each repetition. The following does that:
            note_array = np.array([np.roll(note_array, rng.integers(low = -4, high = 4, size = None), axis = 2) for inx in np.arange(repeat_section)])

            print(f'after rolls. {note_array.shape}') # (14, 6, 4, 16)

            What I need: (6, 56, 16) # 6 features, 56 voices, 16 notes. the 56 voices transform into 4 voices and 14 repetitions of the 16 notes. I could also use (6, 4, 224). That's no better. 

      I need to transform this shape into that shape.
            output of the roll list comprehension shape: (14, 6, 4, 16) <-- 14 rolled copies of the 6 features, 4 voices, and 16 notes 
            goal is this shape: (6, 56, 16)
            note_array = note_array.reshape(note_array.shape[1], note_array.shape[0] * note_array.shape[2], -1)
      This transforms the structure into the right shape, but with the wrong result.
            note_array = note_array.transpose(note_array.shape[1], note_array.shape[0] * note_array.shape[2], 16)
      This doesn't work either. Beyond the scope of the transpose operation. 
      What about concatenation:
      first create repeat_section copies in a new array with each copy having a different roll
            note_array = np.array([np.roll(note_array, rng.integers(low = -2, high = 2, size = None), axis = 2) for inx in np.arange(repeat_section)])
            print(f'after rolls. {note_array.shape}')
            concat_array = np.empty((6, voices, 0), dtype = int)
      Then step through those rolled copies and concatenate them together one at a time.
            for inx in np.arange(repeat_section): concat_array = np.concatenate((concat_array, note_array[inx]), axis = 2)
            note_array = concat_array
      That works. Makes it (6, 4, 224) (features, voices, notes)
      While I'm at it, set some random number of repeat_section copies octaves to zero.
      I tried doing the same thing with rolls for the bass part, and it just sounds whack. I need another way to vary the bass line. Maybe have multiple bass lines from which each 32 beat section can choose from. I decided to roll by sensible numbers:
            note_array = np.array([np.roll(note_array, rng.choice([-16, -8, 0, 8, 16], size = None), axis = 2) for inx in np.arange(repeat_section)])
      What about a mask against the bass line?
            octave_array = mask_array(octave_array, mask)

✅    Mistake in build_horn_from_text were indicies into the scale, not actual note numbers. 
            notes: [6 6 6 5 5 5 4 3 2 2 2 4 4 4 5 6] These are not supposed to be note numbers. They are valid note numbers, but not the ones I wanted. 
                  scale = dmu.build_scales(mode, root, rank)
                  notes = np.array([scale[notes] for (notes, octv, env) in answer])
            That fixed it. 

✅    Make some alternative bass lines. Here are the two additional 32 note arrays:
            input = ("n0o2e8d4 n4e2d3 d1 n0d4e8 n4o1d3e2 d1 n6o2d3e8 n3d1e2 n4e8d3 n2d1 n3e8d3 n1e2d1 o3n4e8d3 o2d1e2",
                  "n0o2e8d2 n2 n4 n6 n1o3d3 n6o2d1 n3d3 n4d1 n2d3 n0o2d1 n4n3 o1d1 o2n0d3 n2d1 n6d2 o1d4",
                  "n4o1e8d3 n1o2d1 n6d3o1 n4o2d1 n1d3 n0d1 o3n1d2 n4o2 o1n0d4 o2n4d3 n5d1 n6d3 n1o3d1 n0o2d4")
            notes, octv, env = arrays_from_text(input[rng.integers(low = 0, high = len(input))])
      I made a new one, but it sounded very repititive, so I applied a mask to the octave_array. That seems to have repaired the repetitiveness.
      In the vamp_creator:
            divisor = largest_evenly_divisible(notes.shape[0], key_metric)
            likelihood = .7
            mask = rng.choice([0, 1], size = (voices, divisor), p = [1 - likelihood, likelihood])
      Then pass mask to build_bass_line
            octave_array = mask_array(octave_array, mask)  # set some octaves to zero to make them silent

✅    Made a version that sounded pretty good, and posted it to ripnread.com. 

5.    What's next. Modulate. Go to the bridge. What are the bridge chords. It's been so long I've forgotten the structure. 
      From the notes from a blog post on 8/14/22.
      vamp:
            otonality on 16:9 - B♭

            bridge:
            otonality on 8:7 - D+
            utonality on 3:2 - G♮ - now called D 9:8
            otonality on 16:15 - D♭
            utonality on 4:3 - F♮ - now called C 1:1
            otonality on 1:1 - C♮
            utonality on 7:6 - E♭ - now called A 7:4
            otonality on 16:9 - B♭
            utonality on 5:4 - E♮ - now called B 15:8
            
      With key_metric = 2, each chord lasts 4.8 seconds
      def bridge_creator(mode, root, rank)
      Just the bass line with no repeats produces 32 116th notes tempo 100 tpq = 0.25 which lasts 4.8 seconds. Perfect. What about the other instruments?
      Something is wrong. When I set bass & horn to true and flu & arp to false, I hear horn and bass. But when I add arp, the horn goes silent. Must have been an auditory allusion, because I hear them now.

      Problem. Those labels are the note at the location in the cassandra for the 8th degree, while my new method labels based on the 0th degree.
      for example, utonality on 4:3 is now called the utonality on 1:1. Make adjustments accordingly
-------------------------------------------------
12/5/22 To do today:

1.   Simplify the bridge. It's way to complicated. Less time on each chord. The charm is hearing the changes. 
     I need a break from this. I'm going to do some more education. 
-------------------
12/7/22 To do today:

1.    I was dreaming about this. 
      I wanted a horn part with an envelope that started hard, backed off fast, then grew to the end. Play a chord for 8, 12, or 16 beats, then two quick rank B chords. Maybe use that for the bridge. Or use the long slide between the chords in 4 continuous glissandi. 
      I'm too tired to do this now. I can't get ctcsound to work.

----------------------------------
12/8/22 To do today

✅    I can't toolbox enter csound from the vscode terminal on the T480. 
      I switched to a different code-server and it works now. See 
            Error: failed to initialize container csound
      Both work correctly on the T480 and ThinkCentre See the details in /var/home/prent/Dropbox/Tutorials/vscode/Setting Up VScode server.txt
----------------------------------------------------------------------------
12/13/22 To do today:

1.    I'm back after spending the last 8 days getting my ThinkCentre set up and stable. All my systems work. But I'm too tired to make any music right now.

-----------------------
12/14/22 To do today:

1.	Create the Anita Baker slide support function.
	Make a multiple slide function that takes as arguments a set of notes and durations, and returns a starting note and glissando, such that each glissando stays at the target note the duration passed in. Think Anita Baker, who carried glissandi across a whole melody. 

2.	Make a minimal conda environment just for the jupyter notebook used in Diamond Music. 
      I'm doing this on the HP800 box now. See /home/prent/Dropbox/Tutorials/Fedora-CoreOS/Fedora Silverblue Kinoite on HP800.txt Creating an environment called diamond on a toolbox called diamond.
	Keep the old one, because it has tensorflow, stable baselines, pytorch, and the other steps along the way. The goal today is not to overconfigure, but just enough to run the notebook in 
            code-server serve-local
      Somehow I was able to get the whole jupyter environment working with the current Diamond Music notebook. Start to finish on Diamond_music_combined_voices.ipynb made a wav file. The problem with ctcsound went away. It's running with a kernel in the gym environment. Which is available on the host as well as in the csound toolbox. Which is amazing, since I only have the copy of csound installed in the csound toolbox. I installed another copy in the tunnel toolbox and forgot about it. 

✅    Fix the T480 ctcsound.py proliferation:
      /home/prent/miniconda3/lib/python3.9/site-packages/ctcsound.py # <-- this is on the base environment
      /home/prent/miniconda3/envs/gym/lib/python3.9/site-packages/ctcsound.py # <-- this is the gym environment
      Get rid of the wrong one. I hope that doesn't screw everything up. I should have checked the dates.

----------------------------------------------
12/15/22 To do today

✅    Use new envelopes
      e18 f280 start with a bash, diminish, then grow to the end.
      e33 f265 less loud at the start, but builds to the end 
      e35 f263 with very sharp start and builds to the end. 

-------------------------------------------------
12/16/22 To do today

✅    Get jupyter lab running with the diamond conda environment. It works on the ThinkCentre. 
✅    Get out of the Audacity requirement to play the sound. 
            os.system(f'play ~/Music/sflib/ball3.wav')
      That works great. Much faster OODA loop.
✅    Keep working on the horn section. I could not get a good roll amount. Try one at a time.

------------------
12/17/22 To do today:

✅    Change the strategy for the horn part.
      Use the prearranged path through the bridge that takes the inversions into account. But keep the same rhythmic pattern, with some alterations to keep it interesting. Here is the array that stores the optimum paths through the bridge chords:
            print(f'{all_bridge_chord_arrays.shape = }')
            array_num = rng.integers(low=0, high = 19)
            print(array_num, dmu.show_scale_ratios(all_bridge_chord_arrays[0][array_num]))
                  all_bridge_chord_arrays.shape = (4, 19, 4, 9)
                  13 [['16/9' '12/7' '9/5' '28/15' '8/5' '7/4' '7/4' '3/2' '14/9']
                  ['10/9' '1/1' '9/8' '16/15' '1/1' '1/1' '1/1' '15/8' '16/9']
                  ['4/3' '8/7' '9/7' '4/3' '8/7' '5/4' '7/6' '15/14' '10/9']
                  ['14/9' '10/7' '3/2' '8/5' '4/3' '3/2' '7/5' '5/4' '4/3']]
      One problem: bridge_creator is called once for every chord in the bridge, and what I'm trying to create is on call to do the horn part across all chords. Some ways to resolve this:
            I could test to see if this is the first time called, and if not, don't create it.
            I could do the horn part separate from the bridge_creator function.
            I could set horn=False when I make subsequent calls to bridge_creator
      I will need to simplify multiple_chord_slide to just do what I need.   
            def new_multiple_chord_slide(rank, chosen_array): # let the function choose the inversions to use
            return notes, gliss 
      Got it working for now. I arbitrarily multiplied by 9 - not sure if this was right. 
            tpq = .25 * horn_predicted * repeat_notes # <-- switched to repeat_notes and it worked great.
            Until it stopped working. I had made the bass notes only 16 beats long by mistake.
      What I need to do next is allow multiple simultaneous runs with octaves. Lots of choices here:
      a.    I could just create another four wind instruments and send through a second batch
      b.    I could make use of the hold/duration difference to make the first on have duration of zero and the second have a duration of some value. That implies that I have control over the hold/duration prior to piano_roll_to_notes_features, which I don't.
      c.    Content yourself with four voices. It will get dense enough later on.
      
✅    Make sure your uton chords are what you expect. 
      C uton should have an F minor chord. C uton 0 2 4 has 4/3 8/5 1/1. That's F minor. All good.

✅    I'm concerned that the horn chords don't match the bass chords. Sounds wierd.
      The former are derived from all_bridge_chord_arrays[0][array_num]) are not the same as the ones used by the bass, derived from bridge_keys. I double checked and made some significant repairs. Fixed it.

✅    Now I'm concerned that the inputs to the bass line are not being processed correctly.
      The bass notes change at the following times in the inputs: d16 d16 two notes to total 32 time_steps 
      The new_output.csd has them changing at 0, 2, 6, 8, 12, 16, 20, 24, 28, 32, 36
      or at 0, 4, 8 12, 16, 18, 22, 24, 26, 30, 32, 34, 38, 40, 42, 46, 48
      Sometimes a break of two seconds, sometimes 4. No pattern each time is different. It could be because some other factor is changing. It could be the masking setting some octaves to 0. That was it. Never mind.

✅    To convert an eps to pdf, execute this command in the terminal session in sflib:
            gs -dNOPAUSE -dBATCH -sDEVICE=pdfwrite -sOutputFile=ball3.pdf ball3.eps
      Where ball3.eps is the input file and ball3.pdf is the output. Very fast.

------------------
12/18/22 To do today:

1.    Build a melody for the bass flute based on the flow through the chords:
            print(f'                           0      1       2       3      4       5       6      7')
            print(*[(mode, ratio, dmu.show_scale_ratios(dmu.build_scales(mode, ratio, rank))) for mode, ratio, rank, inversion in bridge_keys],sep='\n')
            print(*[(mode, ratio, inversion, dmu.show_scale_ratios(dmu.build_chords(mode, ratio, rank, inversion))) for mode, ratio, rank, inversion in bridge_keys],sep='\n')
            print(*dmu.show_scale_ratios(all_bridge_chord_arrays[0,0].T),sep='\n')
                                             0      1       2       3      4       5       6      7
                  ('oton', '16/9', array(['16/9', '1/1', '10/9', '11/9', '4/3', '13/9', '14/9', '5/3'],
                       ))
                  ('oton', '8/7', array(['8/7', '9/7', '10/7', '11/7', '12/7', '13/7', '1/1', '15/14'],
                       ))
                  ('uton', '9/8', array(['3/2', '18/11', '9/5', '1/1', '9/8', '6/5', '9/7', '18/13'],
                       ))
                  ('oton', '16/15', array(['16/15', '6/5', '4/3', '22/15', '8/5', '26/15', '28/15', '1/1'],
                       ))
                  ('uton', '1/1', array(['4/3', '16/11', '8/5', '16/9', '1/1', '16/15', '8/7', '16/13'],
                       ))
                  ('oton', '1/1', array(['1/1', '9/8', '5/4', '11/8', '3/2', '13/8', '7/4', '15/8'],
                       ))
                  ('uton', '7/4', array(['7/6', '14/11', '7/5', '14/9', '7/4', '28/15', '1/1', '14/13'],
                       ))
                  ('uton', '15/8', array(['5/4', '15/11', '3/2', '5/3', '15/8', '1/1', '15/14', '15/13'],
                       ))
                  ('oton', '16/9', array(['16/9', '1/1', '10/9', '11/9', '4/3', '13/9', '14/9', '5/3'],
                       ))
                  ('oton', '16/9', '1', array(['16/9', '10/9', '4/3', '14/9']))
                  ('oton', '8/7', '3', array(['12/7', '1/1', '8/7', '10/7']))
                  ('uton', '9/8', '3', array(['9/5', '9/8', '9/7', '3/2']))
                  ('oton', '16/15', '4', array(['28/15', '16/15', '4/3', '8/5']))
                  ('uton', '1/1', '2', array(['1/1', '8/7', '4/3', '8/5']))
                  ('oton', '1/1', '1', array(['1/1', '5/4', '3/2', '7/4']))
                  ('uton', '7/4', '4', array(['7/6', '7/5', '7/4', '1/1']))
                  ('uton', '15/8', '4', array(['5/4', '3/2', '15/8', '15/14']))
                  ('oton', '16/9', '3', array(['4/3', '14/9', '16/9', '10/9']))
                  ['16/9' '10/9' '4/3' '14/9']
                  ['12/7' '1/1' '8/7' '10/7']
                  ['9/5' '9/8' '9/7' '3/2']
                  ['28/15' '16/15' '4/3' '8/5']
                  ['1/1' '8/7' '4/3' '8/5']
                  ['1/1' '5/4' '3/2' '7/4']
                  ['7/6' '7/5' '7/4' '1/1']
                  ['5/4' '3/2' '15/8' '15/14']
                  ['4/3' '14/9' '16/9' '10/9']
      Having real trouble with the bass flute part. The upsample is whack, the octaves are all over the place. Start there. Why are the octaves ranging from 3 to 6? Fixed it. 
      In build_horn_from_text there is this line:
            note_array[inx, 1] += rng.choice([-1, 0, 1], size = None, p = [0.4, 0.55, 0.05]) # set the octave up or down an octave 
      This made sense for the horn part, but not for the bass flute. 
      And I can't figure out how to make it the same length as the other instruments. Instead of 72 seconds it's 36 seconds.
      This is still true even when I made the inputs have dimension (4,64). Still just 36 seconds. 
      bass_flute_note_array = np.tile(bass_flute_note_array, repeat_all) 
      It was bass_flute_note_array.shape = (6, 4, 64)
      now is bass_flute_note_array.shape = (6, 4, 128)
      in piano_roll_to_notes_voices. Total notes to process: note_array.shape = (6, 4, 128), num_notes = 512
      128 notes, and it still is limited to 36 seconds. But even though the bass line shows a last time as 72 seconds, it actually ends at 36. It's stuck at 36. and the bass voice_time[inst]["start"] is stuck at 72, even though the last note is ending at 36 seconds. Now the horn goes all the way to 72 seconds, with one note, the bass line says it goes to 72 in voice_time, but it in reality goes only to 36, and the bass flute is too quiet and says it only goes to 36, and ends at 36. Time to go for a walk. It sounds like crap. The code smells. Top it off that the notes_features array shows voices 1, 11 going to 71, but the new_output.csd goes only to 36. 
      In summary, something is very very strange:
      1.    The printing of notes_features in send_to_csound_file shows notes happening through start time = 70.99
      2.    The voice_time value for the bass_voices ends at 71.993
      3.    The new_output.csd only goes to 35.999, This is because limit to writing to csound file is set at limit = 35.99989795918366 I chose the wrong value.
      4.    The voice_time value for the bass_flute ends at 36.0196 and nothing I can do will make it go any further. 
      Where is the truth?
      def fix_start_times(note_array) accepts as a parameter note_array of shape (notes, features), and updates the 

✅    Make jupyter servers available from other machines. 
      Info here: https://docs.anaconda.com/anaconda/user-guide/tasks/remote-jupyter-notebook/ and here:
      https://stackoverflow.com/questions/69244218/how-to-run-a-jupyter-notebook-through-a-remote-server-on-local-machine
      Essentially you just run the notebook on the remote in no browser mode.
      
      You need a token if you haven't set up a password. Set up a password on the remote (ThinkCentre, for example) in a terminal type. Do this just once on the server:
            jupyter notebook password
      Then every time you want a jupyter server on the ThinkCentre:
            jupyter notebook --no-browser --port=8888 #<-- this is the <PORT> in the next line.
      Then setup up an ssh tunnel on the T480
            ssh -L 8080:localhost:<PORT> <REMOTE_USER>@<REMOTE_HOST>
            ssh -L 8080:localhost:8888 prent@192.168.68.72
      And on the T480: http://localhost:8080
      Works on the ipad if you first open inx and issue the ssh -L command there, then open localhost:8080. Enter password and you're in. Neat.
      
3.    Refactor the long piece from TonicNet so that it has more variety. 
      Consider gradually morphing the envelopes from sharp to soft and back. 
      The bass line could be more forceful. Right now it's just random notes in the chord, when it could be carefully chosen. I generated 1,000 new midi files for our evaluation. Perhaps one will fill the bill.

---------------------------------
12/19/22 To do today:

1.    Look back on how you handled the verse portion of Balloon Drum Music earlier this Fall. 
      It had a nice bounce and just needed a shift to changing harmonies that the bridge could offer. 
      Today it's overwhelmed by the loud woodwinds. Start there, then fix the aimless bass flute part. 
      You need a special sort of openness for the bass flute to be a melody. 

✅    Fix the timing trouble with the bass flute not extending past time 36. 
      It was because the volume_array shape limits the number of notes that can be, processed in 
            piano_roll_to_notes_features
      I fixed that cluster-f*ck. Now I need to go back and make the flute part worth hearing.

✅    Do a search for 99_999 and fix the assignment to choose the maximum of voice_time
            if limit == 0: limit = np.max([voice_time[inst]["start"] for inst in voice_time])

----------------------
12/20/22 To do today:            

✅    Fix the bass flute part. This is the old one:
            inputs_array = np.array([
            #                                                          32                                                         64
            #                       8              8    8               8  8                       8               8               8
            #   3         3   1    1      2  2  2  2    8  3    3  1    1      12        2      1  1    3  3    1  1    2    2  2  2
            ["n0e8d3v58o4 n2 n4d1 n6 n0o5d2 n2 n1 n3 n0d8 d3n2 n4 d1n6 n7 n0o6d12e1 o5n4d2e8 n6d1 n7 n0d3 n2 n4d1 n6 o5d2n0 n2 n1 n3",
             "n0e8d3v58o4 n2 n4d1 n6 n0o5d2 n2 n1 n3 n0d8 d3n2 n4 d1n6 n7 n0o4d12e1 o5n4d2e8 n6d1 n7 n0d3 n2 n4d1 n6 o5d2n0 n2 n1 n3",
             "n0e8d3v58o4 n2 n4d1 n6 n0o5d2 n2 n1 n3 n0d8 d3n2 n4 d1n6 n7 n0o2d12e1 o5n4d2e8 n6d1 n7 n0d3 n2 n4d1 n6 o5d2n0 n2 n1 n3",
             "n0e8d3v58o4 n2 n4d1 n6 n0o5d2 n2 n1 n3 n0d8 d3n2 n4 d1n6 n7 n0o0d12e1 o5n4d2e8 n6d1 n7 n0d3 n2 n4d1 n6 o5d2n0 n2 n1 n3",], 
            #                                                 32                                        64
            #                             16                   16                  16                    16 
            #       12         2      1    1      12    2    1  1    8  3    3  1   1       12      2        1  1 
            ["n0e16d12v58o4 n2d2e8 n4d1 n6d1 n0o5d12 n2d2 n1d1 n3 n0d8 d3n2 n4 d1n6 n7 n0o6d12e1 n4d2o5e8 n6d1 n7",
             "n2e16d12v58o4 n2d2e8 n4d1 n6d1 n0o5d12 n2d2 n1d1 n3 n0d8 d3n2 n4 d1n6 n7 n2o6d12e1 n4d2o5e8 n6d1 n7",
             "n4e16d12v58o4 n2d2e8 n4d1 n6d1 n0o5d12 n2d2 n1d1 n3 n0d8 d3n2 n4 d1n6 n7 n4o6d12e1 n4d2o5e8 n6d1 n7",
             "n6e16d12v58o4 n2d2e8 n4d1 n6d1 n0o5d12 n2d2 n1d1 n3 n0d8 d3n2 n4 d1n6 n7 n6o6d12e1 n4d2o5e8 n6d1 n7"],
            #                                           36              52              64
            #                   12          12          12         
            #        3     3  3  3  3  3  3  3  3  3  3  3   2     2    12       4    4  4
            ["o5e8n0d3v58 n6 n7 n5 n6 n4 n5 n3 n4 n2 n3 n1 n2d2e8 n0 n7e16d12 n6d4e8 n4 n2",
             "o5e8n0d3v58 n6 n7 n5 n6 n4 n5 n3 n4 n2 n3 n1 n2d2e8 n0 n5e16d12 n6d4e8 n4 n2",
             "o5e8n0d3v58 n6 n7 n5 n6 n4 n5 n3 n4 n2 n3 n1 n2d2e8 n0 n3e16d12 n6d4e8 n4 n2",
             "o5e8n0d3v58 n6 n7 n5 n6 n4 n5 n3 n4 n2 n3 n1 n2d2e8 n0 n1e16d12 n6d4e8 n4 n2"]})
      What are the available notes:
            print(*[(mode, ratio, dmu.show_scale_ratios(dmu.build_scales(mode, ratio, rank))) for mode, ratio, rank, inversion in bridge_keys],sep='\n')                  
                  #                          0        1       2       3       4       5       6       7
                  ('oton', '16/9', array(['16/9',   '1/1', '10/9', '11/9',  '4/3', '13/9', '14/9',  '5/3']
                  ('oton', '8/7', array(['8/7',     '9/7', '10/7', '11/7', '12/7', '13/7',  '1/1', '15/14']
                  ('uton', '9/8', array(['3/2',    '18/11', '9/5',  '1/1',  '9/8',  '6/5',  '9/7', '18/13']
                  ('oton', '16/15', array(['16/15', '6/5',  '4/3', '22/15', '8/5', '26/15','28/15', '1/1']
                  ('uton', '1/1', array(['4/3',    '16/11', '8/5', '16/9',  '1/1', '16/15', '8/7', '16/13']
                  ('oton', '1/1', array(['1/1',     '9/8',  '5/4', '11/8',  '3/2', '13/8',  '7/4', '15/8']
                  ('uton', '7/4', array(['7/6',    '14/11', '7/5', '14/9',  '7/4', '28/15', '1/1', '14/13']
                  ('uton', '15/8', array(['5/4',   '15/11', '3/2',  '5/3', '15/8',  '1/1', '15/14','15/13']
                  ('oton', '16/9', array(['16/9',   '1/1', '10/9', '11/9',  '4/3', '13/9', '14/9',  '5/3']
      What I am thinking of is two different ones:
      a. One for the uton that descends from 4,3,2,1,0 <-- how can I ensure it's always going down?
            the build_scale_mask ensures it always goes up, increasing the octave of each not until it hits the stratosphere.
            Could I put them in backwards then flip it?
      b. One for the oton that ascends from 2,4,5,6,7     

-----------------
12/21/22 To do Today:

✅    Update some functionality of the text parser:
      ✅    Pass in default values explicitly. 
            def arrays_from_text(input, prev_note = 0, prev_oct = 3, prev_dur = 4, prev_env = 1, prev_vel = 45, prev_ups = 0):
      ✅    Get rid of the hold variable. It doesn't work and you keep thinking it might start working. Not gonna happen.
      ✅    What else can I include? Upsample! This will have a cascading affect on lots of functions: 
            1. build_bass_line(repeat_section, notes, octv, env, mask, voices, vel, ups, mode = mode, root = root, rank = rank)
            2. build_horn_from_text(repeat_section, repeat_all, notes, octv, env, voices, vel, ups, mode = mode, root = root, rank = rank, octave_shift = 1)
            Some additional problems that need sorting out:
      ✅    In build_bass_line
            note_array.shape = (4, 32), ups_array.shape = (32,) - why is the ups_array the wrong shape? Perhaps because you didn't include the u value in the text input. Why doesn't it use the default values? That wasn't the problem. I had forgot that in build_bass_line we had to spread the notes across all voices, and also other features using:
                  ups_array = np.tile(ups_array, (voices, 1)) # make more voices
      ✅    Now the upsample appears to be whack for the bass flute. 
            Random notes have very fast vibrato. All of the notes with voice = 6 have ups = 0. And for some octaves, that results in very fast vibrato:
                  ;Inst Sta Hold  Vel   Ton   Oct  Voi Ster Env  Gliss   Ups R-Env 2nd-gl 3rd Volume
                  i1.0  0.0  3.3  60.0  32.0  4.0  6.0  9.0  1.0  799.0  4 1.0  799.0  799.0  60.0
                  i1.0  0.0  3.3  60.0  32.0  4.0  6.0  4.0  1.0  799.0  4 1.0  799.0  799.0  60.0
            I had to set ups to 4 to get a reasonable vibrato speed. I think I see the problem and a potential solution. It's not moving up to higher samples when it should. The design is one sample for two semi-tones. But it's going almost an octave before it changes:
                 instr 1:  p5 = 32.000  iMIDInumber = 48.000  iFtable = 675.000 This one is the only wrong one in the batch.        
            The real problem is that the note numbers are not sequential 0 through 255. Some are, but most are not. For example there are many C naturals in the set, but they could be 0, 17, 34, 51, ... and 255. That range has nothing to do with pitch. I'll need a more sophisticated calculation to convert from my note numbers to midi note numbers. It's not simple. This fixed it:
                  iMIDInumber = int(12 * ipitch / .12) + 12 * ioct

------------------------
12/22/22 To do today:

✅    Make sure you get the right samples. 
      Yesterday I changed the way the csound orchestra specified the sample from the set of samples for the instrument. 
            ipitch table p5, 3 ; convert note number 0-213 (or whatever the root is) to oct.fract format - generated table of note cents f 3 
            ioct = p6 
            ; what midi number should be chosen for the sample file
            iMIDInumber = int(12 * ipitch / .12) + 12 * ioct
            iFtableTemp table iMIDInumber, iSampWaveTable 
      This is a much more accurate way to pick the sample, especially when there are 256 notes in the table f3      

✅    Allow the calling of arrays_from_text and _parse_word to choose the word randomly. 
      This is much more complicated that you think. 
      Key challenges:
      a.    If you attempt to parse them out of order, the default values will be wrong, since you expect to keep the previous values, but the previous values may be subsequent values. This will make it manditory to assign all values in all notes. Just looking at the first one won't tell you what the subsequent ones are expecting. I'm thinking the only way to do this is to not reorder the input, but rather the output. That fails because even if you have the output availble, you don't know which output was derived from which input.
      b.    In order to reorder the output, you will have to know the boundary in the output that corresponds to the input. This information is not availble.
      c.    the order of the output depends on the number of items in the list. This will need to be calculated.
      d.    In order to work, you will need to assign values to all features in all notes. Or you could go through it in the order it was created, then recreate the input text with all the values specified. This will require keeping track of how many have the same value in a row, and creating a duration value equal to that count.
      
      Bottom line, I can't be certain this is any better than just making one more input text list with a different order. But I went ahead and implemented it anyway just to be certain. Now we can scramble it to our hearts content. Or better yet, have arrays_from_text return input_reconstructed. Then create helper functions that make the calling easier. Done.
            notes, octv, env, vel, ups, input_reconstructed = arrays_from_text(input)
      Then if you want to scramble the notes, send input_reconstructed through the arrays_from_text and set shuffle = True.
            notes, octv, env, vel, ups, _ = arrays_from_text(input_reconstructed, shuffle = True)

✅    Fix the use of arrays_from_text. 
      Take advantage of the fact that it returns notes, octv, env, vel, ups. Don't collect them in answer, then spend five lines extracting those values. Just receive them from the call to arrays_from_text. If only it were that simple. Take the bass flute part for example. This works now, but it's clumsy and can't be modified to take advantage of the arrays_from_text(shuffle = True), 
            answer = np.array([arrays_from_text(input) for input in inputs_array])
            scale = dmu.build_scales(mode, root, rank)
            notes = np.array([scale[notes] for (notes, octv, env, vel, ups, input_reconstructed) in answer])
            scale_mask = dmu.build_scale_mask(notes[0])
            assert(notes.shape == (4,32)), f'{notes.shape} not equal to (4,32)'
            octv = np.array([octv for (notes, octv, env, vel, ups, input_reconstructed) in answer])
            octv = octv + scale_mask
            env = np.array([env for (notes, octv, env, vel, ups, input_reconstructed) in answer])
            vel = np.array([vel for (notes, octv, env, vel, ups, input_reconstructed) in answer])
            ups = np.array([ups for (notes, octv, env, vel, ups, input_reconstructed) in answer])
      /tmp/ipykernel_31751/609575510.py:129: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
      answer = np.array([arrays_from_text(input, shuffle = True) for input in inputs_array]) # python doesn't like this because the data elements are not all the same
      /tmp/ipykernel_31751/609575510.py:131: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
      notes = np.array([scale[notes] for (notes, octv, env, vel, ups, input_reconstructed) in answer])
      I also will have a heck of a time makeing all the flutes (there are four as you know) have the same notes.

✅    Had a heck of a time with the tabs vs spaces in the jupyter notebook inside code-server. 
      To fix it, highlight the entire file with ctlr-a, then ctrl-shift-P to bring up command window, then Convert Indentation to Spaces (or tabs). Has to be all one or the other.

--------------------------
12/23/22 To do today:

✅    Get the shuffle algorithm working, in a sensible way. I have it working, but makes combinations of activities harder:
            notes, _, _, _, _, input_reconstructed = arrays_from_text(inputs_array)
            notes, octv, env, vel, ups, _ = arrays_from_text(input_reconstructed, shuffle = True)	
      This works. But how to make it one line?
      If I do this, it returns too many values:           
            notes, octv, env, vel, ups, _ = arrays_from_text(arrays_from_text(inputs_array), shuffle = True)	            
      I need to make two separate functions:
      a.    convert an array of text words into the input_reconstructed, without the notes.
            def fill_out_text(input):
                  _, _, _, _, _, input_reconstructed = arrays_from_text(input)
                  return input_reconstructed
      b.    convert the text into features
            def text_to_features(input, shuffle = False):
                  notes, octv, env, vel, ups, _ = arrays_from_text(input, shuffle = shuffle)	
                  return notes, octv, env, vel, ups
      c.    Here it how it will be used:
            notes, octv, env, vel, ups = text_to_features(fill_out_text(inputs_array), shuffle = True)
      d.    Completed the set: _parse, arrays_from_text, fill_out_text, text_to_features
      
✅    Now use it in bridge_creator
      This is a challenge. Also, I already had a np.roll implemented in build_horn_from_text, why not stick with that instead of randomizing the notes?
      The key is going to be taking the features shaped (32,) into (4,32).
      Now: notes.shape = (32,). I do this elsewhere with np.tile.
            ups_array = np.tile(ups_array, (voices, 1))
      bass_flute_note_array = build_horn_from_text(repeat_section, repeat_all, notes, octv, env, vel, ups, voices, \
                              mode = mode, root = root, rank = rank, roll_low = 0, roll_high = 1, likelihood = .99)
      swap the parameters for ups & voices to keep the array values together. voices is a scalar.  Done. 
      
✅    Some of the bass flute lines are having challenges with the octaves again. 
      I'm starting to think that the mask will never work, since we don't know what the note numbers mean. Fortunately build_scale_mask actually goes to the trouble of finding the ratio of the note numbers (0-255). 
      Coming out of text_to_features, do we have note numbers or scale numbers? numbers in the scale (0-7). Need to convert them into note numbers (0-255). Then it should work. Forgot that conversion before.
            notes = scale[notes]
      That's all it takes. I keep forgetting that.
      The octaves are still a little crazy. Here's the generated csound code:
                                  +-- note number 32 = Bb 16/9 36 = D- 10/9
                                  |     +-- octave should only go up one octave, and this one jumps two octaves
                                  |     |
            [1.0, 0.0, 3.3, 60.0, 32.0, 3.0, 6.0, 16.0, 1.0, 799.0, 0.0, 1.0, 799.0, 799.0, 55.0] 
            [1.0, 3.0, 1.1, 60.0, 36.0, 5.0, 6.0, 10.0, 1.0, 799.0, 0.0, 1.0, 799.0, 799.0, 55.0]

      I was looking at oton 16/9 instead of uton 8/7. Never mind. I adjusted the input text and the problem went away. Input texts can safely all be the same octave. The build_scale_mask takes care of keeping them within an octave. But I should run the octave mask after I've chosen the notes, which should not have any octave values other than a default for the whole section.
      But with the shuffle on, I still have a few octave strangeness.
      Case # 1: octv = array([4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7])
      We can't let it get that high.
      input_reconstructed = 'n0o4e1v60u0d4 n1o4e1v60u0d4 n2o4e1v60u0d4 n3o4e1v60u0d4 n4o4e1v60u0d4 n5o4e1v60u0d12'
      They are all o4. What notes will they yield? 
                              G-               F                    Ab                  Bb                Db                             
                                            C
            scale_mask = array([0, 0, 0, 0,    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,                        2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2,                          3, 3, 3, 3])                              
            notes = array([ 96,  96,  96,  96, 128, 128, 128, 128,  64,  64,  64,  64,  32, 32,  32,  32, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224,   0,   0,   0,   0])
      I'm thinking I just need a limiter. What would it look like?
            octv = np.array([np.min((octv[inx],5)) for inx in np.arange(len(octv))])
      Another option is not to combine the shuffle with an octave mask. If you shuffle, turn off the octave masking. Then we no longer need the limiter. Except when we do. Put it back in anyway. Some of the input_arrays cause trouble in areas of the bridge chords
            if shuffle: scale_mask = np.full(notes.shape, 0) # if you are shuffling the order of notes, don't mask the octaves.
            else: scale_mask = dmu.build_scale_mask(notes)  # if you are not shuffling, then mask away.

✅    Write a finger piano part that makes sense with the current bridge_creator. Must be relatively simple. 
      what does build_arpeggio_part do today?
      def build_arpeggio_part(repeat_section, repeat_notes, repeat_all, octave_array, envelope_array, mask, voices, mode = "oton", root = "16/9", rank = "A"):
      a.    chooses two chords from the best_rank_inversion_combos and load them into note_array (just notes), reshaped, T (4,2) repeat_section times
      b.    repeat notes by repeat_notes times - turns 1/16th notes into 1/4 notes (repeat_notes = 4)
      c.    repeats the four chords to match the number of voices 
      d.    create the octave as a masking tool octave_array = mask_array(octave_array, mask) - a random mask
      e.    envelope, gliss, ups, and vel arrays
      f.    stack them as note_array
      g.    tile them repeat_all times
      h.    return note_array 
      For sake of argument, maybe just off beat chords. o0d2d8u0v40 o4 o0 o4

      Make a new function called build_chop_part called as 
      build_chop_part(repeat_section, repeat_notes, repeat_all, octaves, env, voices, mask, mode = mode, root = root, rank = rank)
      def build_chop_part(repeat_section, repeat_notes, repeat_all, octave_array, envelope_array, mask, voices, mode = "oton", root = "16/9", rank = "A"):
      a.    choose 2 chords reshaped to (4,2) (4 voices, two chords) repeat_section times
      b.    repeat notes by repeat_notes times - turns 1/16th notes into 1/4 notes
      c.    repeats the four chords to match the number of voices 
      d.    create the octave, mask such that you end up with silent 2 ticks, play 2 ticks forever 
            mask = np.array([0, 0, 1, 1])
      e.    envelope, gliss, ups, and vel arrays
      f.    stack them as note_array
      g.    tile them repeat_all times
      h.    return note_array 
      Trouble: octave_array is (64,8) going into np.stack, all the others are (8,8) that seems allfully short. 
      see if you can initialize octave_array the same way you do envelope_array.
            octaves = rng.choice([4, 5], size = (voices, mult), p = [.6, .4,])
            octaves = rng.choice([4, 5], size = (mult, 8, p = [.6, .4,]) # <-- same (64, 8) result
            octaves = rng.choice([4, 5], size = (mult, p = [.6, .4,]) # <-- that worked.
            env = np.full(mult, 8)

✅    Why is this line not making it less dense. The flute is playing throughout. 
      Perhaps because you have four of the exact same flutes playing. Try mixing up the upsample values.
            density_input = np.array([.4, .3, .4, .6, .9])
            print(f'{density_input = }')
            notes_features = masked_notes_features(notes_features, build_density_function(density_input, notes_features.shape[0])) 
      It's still too continuous. I need to deliberatly make it silent for a space.

----------------------------
12/24/22 To do today:

✅    Start the day with an error:
      Right after this line:
            octave_array.shape = (24,), mask.shape = (4,)
            mask_tile = 4 # not enough - it should be 4 * 8 not 4 * 4. 
      build_chop_part(repeat_section, repeat_notes, repeat_all, octave_array, envelope_array, mask, voices, mode, root, rank)
            18 print(f'{mask_tile = }') # should be 4
            19 mask = np.tile(mask, (voices, mask_tile))
            ---> 20 octave_array = octave_array * mask  
            22 print(f'{voices = }, {octave_array.shape = }')

            ValueError: operands could not be broadcast together with shapes (8,24) (8,16) 

✅    Fix the lack of space in the bass flute. 
      Include some zero octaves in the text input.

✅    Use the various fading envelopes across the held horns.
      f273 through f278 all have three humps are e20 = e25

✅    First I have to repair vamp_creator. Haven't used it in a while and it's experienced code fade.
      I have a feeling it's not going to go terribly smoothly.   
      case #1: notes, octv, env, vel, ups = arrays_from_text(input[rng.integers(low = 0, high = len(input))])
      this function was changed, and split up into two functions:
            def fill_out_text(input):
                  _, _, _, _, _, input_reconstructed = arrays_from_text(input)
                  return input_reconstructed
      
            def text_to_features(input, shuffle = False):
                  notes, octv, env, vel, ups, _ = arrays_from_text(input, shuffle = shuffle)	
                  return notes, octv, env, vel, ups
      How to combine them to enable shuffle:
            notes, octv, env, vel, ups = text_to_features(fill_out_text(inputs_array), shuffle = True)
      case #2: answer now has to deal with input_reconstructed.
                  answer = np.array([arrays_from_text(input) for input in inputs]) # python doesn't like this, since one of the returned elements is a string, the rest integers.
                  scale = dmu.build_scales(mode, root, rank)
                  notes = np.array([scale[notes] for (notes, octv, env, vel, ups) in answer])
                  octv = np.array([octv for (notes, octv, env, vel, ups) in answer])
                  env = np.array([env for (notes, octv, env, vel, ups) in answer])
                  vel = np.array([vel for (notes, octv, env, vel, ups) in answer])
                  ups = np.array([ups for (notes, octv, env, vel, ups) in answer])
            how did I solve this in bridge_creator?
                  notes, octv, env, vel, ups = text_to_features(fill_out_text(inputs_array), shuffle = shuffle)
      case #3: in build_horn_from_text
            note_array = np.stack((note_array, octave_array, gliss_array, ups_array, envelope_array, vel_array), axis = 0)
            Not all the same shape. 
            It was because I moved the voices and forgot to replicate the same move in vamp_creator.
      case #4: Horn line is too short compared to the others:
                  ('bass:', 'fp1', '0:23')
                  ('horn:', 'obo', '0:08') # <-- too short. 
                  ('arp:', 'fp4', '0:23')	
                  ('bflu', 'bf1', '0:23')	
            Take a look at what happens in build_horn_from_text.
            Needed to add this at the end of that function: 
                  concat_array = np.tile(concat_array, (repeat_all,1)) # this is only needed in the vamp_creator, not the bridge creator.
            I'll have to find another way in vamp_creator to increase the horn length.

✅    Now is the time to combine the verse with the bridge.   
      Except the fix I made to build_horn_from_text resulted in very long bass flute in bridge_creator. Fixed that. I added a tile:
            answer = np.tile(answer, repeat_all) in the vamp_creator during the horn part.

      New problem: The length of each segment is not the same across the instruments. I'll need to prune them. 
      After pruning I get an error in this line:
            notes_features = np.concatenate((notes_features, current_notes_features))
      ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)
      This is saying that notes_features has only 1 dimension.
            In prune. format_seconds_to_minutes(minimum_perc_start_time) = '0:00', format_seconds_to_minutes(minimum_wind_start_time) = '0:00', format_seconds_to_minutes(minimum_bras_start_time) = '0:00', format_seconds_to_minutes(cut_off) = '0:00'
            before chopping the extra notes. notes_features.shape = (4173, 15)
            after chopping the extra notes. notes_features.shape = (0,)
            after prune. notes_features.shape = (0,)
      Prune is not working:
            In prune. format_seconds_to_minutes(minimum_bass_flute_start_time) = '0:00', format_seconds_to_minutes(minimum_horn_start_time) = '0:00', format_seconds_to_minutes(minimum_arp_start_time) = '0:00', format_seconds_to_minutes(minimum_bass_start_time) = '0:00', format_seconds_to_minutes(cut_off) = '0:00'        
            Which in turn leads to notes_features.shape = (0,)    
            Perhaps the problem is that we haven't gone through the routine that keeps track of those things. Where voice_time updated? Not until fix_start_time, which is just before it's sent to csound.
      I'll need a new prune that works with note_features before all the start times have been determined. 
            it will have to build arrays keeping track of the durations of all the notes in each of the voices. 
-------------------------
12/26/22    To do today:

✅    Does each section of verse and bridge end up with different durations? 
      Not according to my calculation as far as vamp_creator is concerned.
      What about bridge_creator: same. Ran through them both and they ended up at 960.079286 on the nose.
      If so, can it be prevented, or corrected? I can't get them not to be all the same.
      But somehow the numbers when I go through verse, bridge, verse, I end up with durations of 44 minutes and 44 seconds. but they are all identical: max_dur = 420251.85280612245, min_dur = 420251.85280612245, while what actually gets produced:
      After send_to_csound_file. notes_features.shape = (5616, 15)
      ('bass:', 'fp1', '5:05')	('bass:', 'fp2', '5:05')	('bass:', 'fp3', '5:05')	('bass:', 'btg', '5:05')
      This was because I had an error in prune_notes_features, where I was using an abandoned variable current_notes_features, which was the numbers in a group (20, 21, 22, 23) and it was summing all four numbers. 
         
      Problem still there:
            back from bridge_creator. current_notes_features.shape = (176, 15), notes_features.shape = (9897, 15)
            group_of_instruments = array(['bf1', 'bf2', 'bf3', 'bf4'], dtype='<U3'), instrument_numbers = array([20, 21, 22, 23])
            inst = 20	format_seconds_to_minutes(dur) = '00:05:11.990'
            inst = 21	format_seconds_to_minutes(dur) = '00:05:12.021'
            inst = 22	format_seconds_to_minutes(dur) = '00:05:11.981'
            inst = 23	format_seconds_to_minutes(dur) = '00:05:12.024'
            group_of_instruments = array(['obo', 'cla', 'frn', 'bss'], dtype='<U3'), instrument_numbers = array([24, 25, 27, 26])
            inst = 24	format_seconds_to_minutes(dur) = '00:04:00.193'
            inst = 25	format_seconds_to_minutes(dur) = '00:03:59.619'
            inst = 27	format_seconds_to_minutes(dur) = '00:03:59.865'
            inst = 26	format_seconds_to_minutes(dur) = '00:03:59.641'
            00:05:12.068, 00:03:59.888, delta = 00:01:12.179 
      It's off by a miute and 12 seconds thanks to the second bridge segment. Why? If I run that segment by itself it never gets that far off. What is it doing in the bridge section? Just playing one note for a specific duration. If it gets that wrong, it will screw up the whole segment. Look at the way the horn duration is assigned, special attention to the affect of key_metric. The problem is that I forgot to reset horn = True. It's still False the second time around, so it simply never runs the horn part. 
      Fixed it. But it's still a second off after five minutes.
            00:02:24.024, 00:02:22.795, delta = 00:00:01.229
            00:04:00.097, 00:03:58.799, delta = 00:00:01.298
            00:05:12.070, 00:05:10.616, delta = 00:00:01.453      
      It's like the tiny perturbations are adding up over time.
            00:02:24.047, 00:02:23.030, delta = 00:00:01.017
            00:04:00.045, 00:03:59.022, delta = 00:00:01.023
            00:05:12.050, 00:05:10.714, delta = 00:00:01.336
            00:07:36.066, 00:07:34.732, delta = 00:00:01.335
            00:10:00.095, 00:09:57.821, delta = 00:00:02.275
      after ten minutes it's 2 1/4 seconds off. 
      All these variations are after the z factor is applied, in piano_roll_to_notes_features. When I set perturb = 0, all the variations in time go away. 
            00:02:24.000, 00:02:24.000, delta = 00:00:00.000
            00:04:00.000, 00:04:00.000, delta = 00:00:00.000
            00:05:12.000, 00:05:12.000, delta = 00:00:00.000
            00:07:36.000, 00:07:36.000, delta = 00:00:00.000
            00:10:00.000, 00:10:00.000, delta = 00:00:00.000      
      The question remains if I should add the perturb back in, at a lower level. My major fear is that they are additive in some way. I add a trivial amount to one note, subtract a trivial amount from another, all the subsequent values seem to be affected. I think it would be more predictable to do this modification in the send_to_csound_file function. Try it there. 
            perturb = time_per_note * 0.01 # set it to 1% of the time per note. 
            z_range = np.linspace(-perturb, perturb, 50)
            max_z = 0
            min_z = 0
            z = rng.choice(z_range) 
            max_z = np.max((z, max_z))
            min_z = np.min((z, min_z))
            duration += z
            if duration < 0: duration = abs(duration - z)

            print(f'{round(min_z,5) = }, {round(max_z,5) = }')  
      This is sounding like crap.  I'm not tracking the changes I'm making to the note start times. My log shows none until the end.

✅    Something is whack with the function that generates the glissandi f tables in the new_output.csd. after the f2 table, there is this:
            f f f f f f f f f f f f f f f f f f f f f f f f f f f f 827.0 0.0 2048.0 -7.0 1.0 121.0 1.0 120.0 0.9183673469387755 121.0 0.9183673469387755 120.0 0.826530612244898 
      I don't think that is correct. It was a result of trying to reset the indentations. I fixed it. 

✅    I would like to increase the octave range of the horns.
      In the long slow slide in bridge_creator. tile then modify the octaves. I tiled the note_array after the stacking:
            before tiling note_array.shape = (6, 4, 1)
            note_array = np.tile(note_array,2)
            after tiling note_array.shape = (6, 4, 2)
      it only created three voices, then four when I modified the density.
      This is how I spread the note_array out in the build_arpeggio_part:
            if voices > 4: 
                  note_array = np.tile(note_array, (voices // 4, 1))
      But that is before I stack them.
      I figured out a way to implement this.

✅    So after all those changes I thought I would do a quick run through for the blog, but the addition of four extra voices has screwed up the timing. 
      It now has horns long slide in the verse part. How did that happen? I think I need to look more closely at the horns_creator part. I fixed it. 

-------------------------------
12/27/22 To do today:

✅    Find a way to make the two sections more alike. 
      They need to be more similar, consistent, and like they were composed at the same time by the same person. At this point, they sound like they were composed by two different people and mailed into the editor to make the best of it. 
      a. Change the bass section
      b. change the arpeggio section

✅    The verse horn part is too repetitive. 
      Notice that it only picks one input string for each run through the verse section. It just repeats that for the whole verse. Not good. The key to variation is to take advantage of the roll_low=-3, roll_high=4, likelihood=0.65, octave_shift=2 (up or down this many octaves). At this time, roll_amount is also only done once for all the repetitions. Instead of using the same roll amount for all the repetitions, I created a different one for each. Much better now. I had to work on this for several days with manifold changes over that time. I like it now.

✅    Make the bass flute louder in the verse, and softer in the bridge. 
      Make sure volume is being used in the csound orchestra. At one point it wasn't.
            iamp = ampdb(iVel) * p15 / 5 ; velocity input is 60-80 - convert to amplitude 
      verse, if flu:
            volume_array = np.full(bass_flute_predicted, 60) # was 50
      bridge, if flu:
            volume_array = np.full(bass_flute_predicted, 19) # was 35

✅    Make the horn softer in the bridge, louder in the verse
      verse, if horn:
            volume_array = np.full(horn_predicted, 45) # was 56 must go down.
      bridge, if horn:
            volume = np.full(1, 20, dtype = int) # was 25

✅    Fix the density array.

✅    Understand the difference between key_metric and repeat_verse. 
      I think I need to set repeat_verse high, so I get several different horn vamps, while key_metric should stay low. repeat_verse only affects the verse, and has no impact on the bridge. 

✅    Fade out on the verse where key_metric = 1, repeat_verse = 1 makes 24 seconds.
      I have what I think should work, but it has no effect on the notes being written to new_output.csd. after I've set field #14 to fade out, it goes through a few other functions:
            notes_features = fix_start_times(notes_features)
            notes_features = send_to_csound_file(notes_features, tempos = 't0 ' + str(tempo), tempo = tempo, print_only = 1500) # , limit = 0.75
            
-------------------------
12/28/22 To do today:

✅    Did you know that even when you host code-server serve-local, it reaches out to Microsoft and fails if the internet is down (like it is today).
        code-server serve-local
            [2022-12-28 06:01:03] error error requesting https://update.code.visualstudio.com/api/latest/server-linux-x64-web/stable: error sending request for url (https://update.code.visualstudio.com/api/latest/server-linux-x64-web/stable): error trying to connect: dns error: failed to lookup address information: Try again
      I should make sure I keep a copy of the code-server that I can run locally.
           
✅    The latest Balloon Drum Music (ball3-t2.wav) is way too complicated at the start. Try with much lower density and see if that make the start less cacophonous.

✅    The features that can be set in text_to_features are: notes, octv, env, vel, ups. And the implied duration by repeating notes.

✅    Fix the fade at the end so it is gradual and across all the instruments. 
      Now it doesn't fade the bass as much as the other instruments. I tried a comparable fade_in at the start, and it starts just with the horn and balloon flute.
      The reason is that the array is not sorted by time. It works on this array:
      current_notes_features = vamp_creator(key_metric, "oton", "16/9", "A", bass = True, horn = horn, flu = True, arp = True)
      It is just in the order in which it was created. So when I cause the velocity and volumes to be multiplied by fade_in or fade_out, it doesn't affect all voices equally. It instead fade_in goes from just one or two instruments to all instruments of the other way around for the fade_out. 
      I will need to find another way to fade in and out. The fade out works, because it becomes more of a vamp as the horns and bass flute disappear, then the balloon drum/finger piano goes away, leaving only the bass. How can I accomplish the reverse?

-----------------------------------------
12/29/22 to do today:

✅    Install a python virtual environment with pip to allow me to develop without using anaconda on the T480:
      See details here: /home/prent/Dropbox/Tutorials/Set-Up-Linux-on-Lenovo-T480/Setting up Fedora on Lenovo T480 laptop.txt
      
✅    How to build a python virtual environment:
            +-- specify the version you want to run
            |          +-- run a library module - what follows will be executed as a script, not an otion to python 
            |          |  +-- run the specified environment
            |          |  |    +-- a directory to run the environment in
            python3.11 -m venv test_app_venv
            source test_app_venv/bin/activate
      
            If you have trouble installing specific packages using PIP, you should install the following packages:
                  sudo dnf install gcc openssl-devel bzip2-devel libffi-devel zlib-devel wget make -y
            I had no trouble with any packages, so I did not need to do that.

      build the environment:
            sudo dnf install python3.11 -y
            toolbox create virtual_python # <-- only need to do once.
            toolbox enter virtual_python
            python3.11 -m venv python_env
            source python_env/bin/activate # <-- run a program in the created directory to start the virtual environment. 
      install pip in the virtual environment             
            python3.11 -m pip install --upgrade pip
      install other packages in the following order, and don't put too many at once or pip can't handle it:
            pip3.11 install jupyterlab
            pip3.11 install numpy 
            pip3.11 install matplotlib
            pip3.11 install scipy
            pip3.11 install importlib fractions copy logging os 
            sudo dnf install sox csound-devel
      Now you are ready to run jupyter
            jupyter-lab
      Or run the notebook in an instance of code-server.

      To exit the virtual environment:
            deactivate 
      
      Another task. Set up the virtual python environment on the ThinkCentre. toolbox enter virtual_python Can't import ctcsound. 
            This is in the virtual python environment in a toolbox that includes csound-devel. It also can't import it into toolbox enter csound, conda activate diamond.
                  find / -name ctcsound.py 2>/dev/null
                        /usr/lib64/python3.11/site-packages/ctcsound.py
                        /var/home/prent/miniconda3/envs/gym/lib/python3.9/site-packages/ctcsound.py
                        /run/host/var/home/prent/miniconda3/envs/gym/lib/python3.9/site-packages/ctcsound.py
                  echo $PATH
                        /var/home/prent/Dropbox/Tutorials/Diamond_Music/python_env/bin:/home/prent/miniconda3/bin:/home/prent/miniconda3/condabin:/home/prent/.local/bin:/home/prent/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
            I wonder if I added the python3.11 path into the path?
                  export PATH=/usr/lib64/python3.11/site-packages/ctcsound.py:$PATH
                  echo $PATH  
                        /usr/lib64/python3.11/site-packages/ctcsound.py:/var/home/prent/Dropbox/Tutorials/Diamond_Music/python_env/bin:/home/prent/miniconda3/bin:/home/prent/miniconda3/condabin:/home/prent/.local/bin:/home/prent/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
            That didn't help. I tried some offers of advice from stack overflow to use conda develop pathname. Didn't work. 

---------------------            
12/30/22 To do today:

✅    Try slowing it way down. 

✅    Make it so the speed of the slide is variable. 
            notes, gliss = new_multiple_chord_slide(rank, array_num)
      add another parm:
            notes, gliss = new_multiple_chord_slide(rank, array_num, each_slide_step) 
      each_slide_step must be between 1 and 239

3.    Make the horn section include 12 instruments.

✅    Make sure the bridge bass line changes with the root, mode, rank values. It does.

✅    Allow the use of variables in the text input:
            Instead of this:
                  input = ("n0o2e8d4v50 n4d3v60 d1 n0d4e8v50 n4o1d3e2v60 d1 n6o2d3e8v50 n3d1e2v60 n4e8d3v50 n2d1e2v60 n3e8d3v50 n1e2d1v60 o3n4e8d3v50 o2d1e2v60",
                 
            Allow this:
                  long = "e8v50"
                  short = "e2v60"
                  input = ("n0o2d4" + str(long) + " n4d3 d1" + str(short) + " n0d4" + str(long) + " n4o1d3" + str(short) + " d1 n6o2d3" + str(long) + " n3d1" + str(short) + " n4d3" + str(long) + " n2d1" + str(short) + " n3d3" + str(long) + " n1v60" + str(short) + " o3n4d3" + str(long) + " o2d1" + str(short),
            Does this make it simpler to create? Don't know. 

✅    Make it so the bass flute in the bridge uses the same set of chord inversions as the horn. 
      I could not do that because the bass flute operates on a scale, and the chord inversions are a tetrad.
                  array_num = rng.integers(low = 0, high = 19)
                  notes, gliss = new_multiple_chord_slide(rank, array_num, each_slide_step)
            In new_multiple_chord_slide:      
                  rank_num = ord(rank) - 65 # convert "A","B","C","D" into 0,1,2,3 for index into all_bridge_chord_arrays
                  array_of_chords = all_bridge_chord_arrays[rank_num][chosen_array]
                  print(array_of_chords)
                        [[ 32 200  66 236   0   0 140 142  40]
                        [ 36 204   2 224 192   4  76  78  44]
                        [ 40 192 194 228 128   8  12  14  32]
                        [ 44 196 130 232  64  12 204 206  36]]
                  print(array_of_chords[:,0])
                        [32 36 40 44]
                  print(*[array_of_chords[:,inx] for inx in np.arange(array_of_chords.shape[1])])
                        [32 36 40 44] [200 204 192 196] [ 66   2 194 130] [236 224 228 232] [  0 192 128  64] [ 0  4  8 12] [140  76  12 204] [142  78  14 206] [40 44 32 36]
                  But I need a scale, and this only provides the best inversion for each chord, which is a totally different structure. And I already run the scales through a tool that ensures it always goes up. 

✅    There is still too much repetition in the bass flute part. I should make an effort to remove the need for this:
                  repeat_all = 2
                  bass_flute_note_array = np.tile(bass_flute_note_array, repeat_all)
            I could to do that if I picked a longer section earlier, or repeat then shuffle. 
            Be careful of density functions that eliminate the bass flute completely.
            I decided to make each text input twice as long to 64 beats. I could clean it up some more.
--------------------------
12/31/22 To do today

✅    Isolate the horn verse part. The octaves are wrong, it's too repetitive. 
      All true statements. I just went through this:
            Sounds like it was using only one text input. Look into this more closely.
                  repeat_verse = 2
                  key_metric = 3
                  horn = True
                  for inx in np.arange(repeat_verse):
                        current_notes_features = vamp_creator(key_metric, "oton", "16/9", "A", bass = False, horn = horn, flu = False, arp = False)
            It was in fact chosing texts 41 times. 
                  grep input_chosen ball3.log -c # <-- input_chosen is found twice in each line
                        82
            Spread out equally over the four options:
                  grep "input_chosen = 0" ball3.log  -c
                        18
                  grep "input_chosen = 1" ball3.log  -c
                        17
                  grep "input_chosen = 2" ball3.log  -c
                        22
                  grep "input_chosen = 3" ball3.log  -c
                        25
            So why does it sound like they are all the same?
            Where are the repeats taken? in the verse section.
                  repeat_all = 3
                  answer = np.tile(answer, repeat_all) # this is where you get your repetitiveness - does it always 3 times
            What can I do to moderate the repeats? I could shift the octaves, upsample, velocity (like it's an echo dying away)
            What's happening in build_horn_from_text? It repeats it again by repeat_section, but then rolls each one.
            And it adds or subtracts an octave from each one. 
            And it might set it to octave zero according to the 1 - likelihood. 
            Meanwhile all I'm logging is the shapes. Added some more logging. But I need a way to restart the log. It's very confusing when I still have the old log output in the mix.
                  dmu.start_logger(jupyter_log) # <-- starts over from the beginning of the file
            It sounds like I'm setting the octaves to zero, and yet they are still sounding.
            I think I found out why the octave shift is so screwy. I am chosing from 3 options, 
                  new_octave = rng.choice([-1 * octave_shift, 0, octave_shift],p = [0.1, 0.7, 0.2])
            What I want is an integer from -2 to +2. With probabilities assignable. Can't have both. Actually I can. choose between a range of values with probabilities for each one. But how many are there? 
                  new_octave = rng.choice(np.arange(-octave_shift, octave_shift, 1), p = [0.1,???] # <-- must sum to 1 

            Changed it to:
                  octave_shift > 0: new_octave = rng.integers((-1 * octave_shift + 1), high = octave_shift, endpoint = True) # returns -1, 0, 1, 2
            I can't assign probabilites now. But at least it doesn't shift 2 octaves lower on me all the time.

            What about an occassional shuffle to the input text? Here's how you shuffle the bass flute part in the bridge
                  shuffle = rng.choice([True, False], p = [0.3, 0.7])
                  notes, octv, env, vel, ups = text_to_features(fill_out_text(inputs_array), shuffle = shuffle)
                  # if you are masking the scale:
                  scale = dmu.build_scales(mode, root, rank)
                  notes = scale[notes]
                  if shuffle: scale_mask = np.full(notes.shape, 0) # if you are shuffling the order of notes, don't mask the octaves.
                  else: scale_mask = dmu.build_scale_mask(notes)  # if you are not shuffling, then mask away.
                  octv = octv + scale_mask
                  octv = np.array([np.min((octv[inx],5)) for inx in np.arange(len(octv))]) # limit it to no more than octave 5 or 6
            It needs to be very low likelihood. It's pretty chaotic.
                  answer = np.array([text_to_features(fill_out_text(input), shuffle = rng.choice([True, False], p = [0.1, 0.9])) for input in input[input_chosen]]) 
            I suggest earlier that I moderate the velocity (like it's an echo dying away) for each repeat, just a little bit. progressively diminishing velocity. I implemented it (I think). But I can't hear the effect. I see it in the notes, but it just doesn't sound in the audio.
            Maybe I need to do both the volume and the velocity. But that is dangerous because volume has one level for all voices, and velocity is unique to each note.

✅    Check to make sure the randomizer is being properly initialized. It is. It's pulled from the OS on instantiation of the notebook.

✅    Make it possible for a very short slide in the horn bridge. Update this line in bridge_creator:
            each_slide_step = rng.integers(low=2, high = 120) # how long the slide takes from 20 to 120 steps out of 256

-----------------------
1/1/23 To do today:            

✅    Poke some more holes in the bass flute melody in the bridge. Too many notes. 
      Concentrate on the uton descending 4 3 2 1 0 and otonal ascending 4 5 6 7 0. Don't get distracted. I can also decrease the likelihood value in the call to build_horn_from_text. Default is likelihood = .65
      in bridge_creator the call to build_horn_from_text is set to 
            likelihood = 0.7
      I could set it to a lower value, or just use the default. I think I'll do the latter.

✅    More of that baritone guitar. In build_bass_line:
            octave_array[2:4] += rng.choice([0, 1], size = None, p = [0.1, 0.9]) # <-- move from [0.1, 0.9] to [0.6, 0.4]

✅    Revise the input to the bass flute to include str(long) to replace e1v56 and str(short to replace 38v62)
      


----------------------
1/2/23 To do today

✅    Make sure the echo effect on the horn repetitions is affecting all the notes in all the voices. It was. 
      The problem was the limit on the p4 parameter in the csound that restricted it to the range 50 - 90. I was working on velocity changes below 45 which were discarded.
      I think I found something important. The way that the final volume is calculated, if p4 > 50, ivel = p4, but if it's less than 50, it never changes. So the final iamp value stays the same. This is due to the multi-sample, velocity-sensitive samples like the Bosendorfer set. That shouldn't be a problem. Just keep velocity between 50 and 90, and you should be fine. Reduce the volume variable instead. I should probably make sure this is implemented everywhere. I'm so used to keeping volume at 60 and velocity at 45, that it's probably everywhere.
      Strategy:
            1.    Make the default volume 5 and the velocity between 50 and 90, default at 80
                        long = "e8v74"
                        short = "e2v79"
                        vel_array = np.full(note_array.shape, 5, dtype = int) # <-- this used to default to 60, now look at it.
                        vel_echo_max = 6 # <-- I was setting this to 12 earlier today to no effect, due to the csound keeping it in range 50 - 90.
      I'm hearing some bass flute trills cutting off before they should. Like a bad envelope. 15 was the culprit. I meant 17. 
      Now there is some clipping that I need to get rid of. I think it's the arpeggios. Or could be the horns. Try the arp first. 
      In build_arpeggio_part:
            vel_array = np.full(note_array.shape, 75, dtype = int) # was 80
      I think I got that nailed. 
✅    New problem in new_multiple_chord_slide, where I was messing around with the gliss in the text input. 
            note_array = np.stack((notes, octv, gliss, ups, env, vel), axis = 0)
      Fails with ValueError: all input arrays must have the same shape
      Log says:       notes,   octv,   gliss,   ups,   env,   vel 
            shapes = [(8, 1), (8, 1), (8, 1), (8, 1), (8, 1), (2, 32)]
      So it's velocity that is wrong. I don't know where it got assigned, but it wasn't in the horn block in bridge_creator. Must have been left over from somewhere else.
      Another new problem. The velocity and volume are suddenly high precision floating point numbers. I don't remember ever using them in calculations that would require anything but integers. That's concerning. velocity: 25.647 volume 1.781 that's whack.
      The voices with such crazy velocities: 6, 5, 7, 3, 4, 11 - actually it's all of them.
      And I'm still clipping. Not nailed. It must be something in the bridge. See if the bass part in the bridge is the same amplitude as the vamp. Horns could still come down more in the bridge. 
      vamp: 
            long = "e8v80"
            short = "e2v85"
            volume_array = np.full(bass_predicted, 5) # <-- was 7 but that doesn't solve the clipping problem
      bridge: 
            long = "e8v80"
            short = "e2v85"
            volume_array = np.full(bass_predicted, 5)
      The intro is too sparce.
      Clipping seems attributable to the bridge arpeggio section. Or the bass section in both bridge and vamp. I think I nailed it this time...
      The entry verse section is just too unpredictable. I'm going to redo it with list comprehensions with tests if the voice is in a set of numbers. If it's not then you should save it somewhere and append it with zero volumes

------------
1/4/23 To do today

✅    Resolve the problem with the stack operation that caused a failure Monday afternoon.
            build_arpeggio_part(repeat_section, repeat_notes, repeat_all, octave_array, envelope_array, mask, voices, mode, root, rank)
                  20 shapes = [arr.shape for arr in [note_array, octave_array, envelope_array, gliss_array, ups_array, vel_array]]
      From the log file:
                  2023-01-02 16:05:16,874 - root - INFO - arpeggio_predicted = 64, repeat_section = 2, repeat_notes = 4, repeat_all = 4, mult = 16
                  2023-01-02 16:05:16,874 - root - INFO - in build_arpeggio_part. mode = 'oton', root = '16/9', rank = 'A'
                  2023-01-02 16:05:16,875 - root - INFO - shapes = [(8, 16), (8, 16), (8, 8), (8, 16), (8, 16), (8, 16)]
      What the shapes variable names are:             note_array, octave_array, envelope_array, gliss_array, ups_array, vel_array]
      The envelope array is only 8,8. vamp_creator has this:
            env = np.full(mult,8) # <-- give me quantity mult of 8's. I thought it was quantity 8 of mult's, but that would make no sense, and be wrong
      While bridge_creator has this:
            env = rng.choice([2, 8, 1, 16], size = 8, p = [0.1, 0.7, 0.1, 0.1])
            env = rng.choice([2, 8, 1, 16], size = mult, p = [0.1, 0.7, 0.1, 0.1])
      That fixed it. Easy-peasy.

✅    Make some final versions ball3-t11, 12, 13, 14. Complete. Go for a walk and decide which one to use.



---------------------
1/4/23 To do today:

✅    Make sure the github repo works. You will need to post some samples, which could be larger than github allows. At the moment that is 100 MB. "Individual files in a repository are strictly limited to a 100 MB maximum size limit." So I split it up into a few separate files:
      ls -lth *.zip
            -rw-r--r--. 1 prent prent 3.1M Jan  4 09:58 Oboe_Archive.zip
            -rw-r--r--. 1 prent prent 5.3M Jan  4 09:58 Frn_Hrn_B_Flut_Archive.zip
            -rw-r--r--. 1 prent prent 8.7M Jan  4 09:57 Clar_Bassoon_Archive.zip
            -rw-r--r--. 1 prent prent  69M Jan  4 09:54 F_Piano_Guit_Archive.zip

✅     Post #12 on ripnread and advertise on Facebook. Not so fast. A few corrections:
      a.    Lower the horn volume during the bridge. vel = np.full(notes.shape, 61) # was 63
      b.    Increase the bass flute volume during the bridge. long = "e1v70" # was v68
                                                            short = "e8v75" # was v73
      c.    Increase the minimum slide time for the horns during the bridge. Too fast is no good.
            each_slide_step = rng.integers(low=2, high = 120) # was low = 2 high = 120, now rng.integers(low=20, high = 140)
      d.    Remove some of the gaps in the bass flute melody during the bridge - Done
      e.    Increase the minimum echo diminishment during the verse. 3 to 5 to 4 to 7
      f.    Lower the bass flute volume during the verse. 72 to 70
      g.    print_only is too high
      h.    Make sure the bass octaves are not too low. I like low, but not all the time. They are almost all at o2, with some o1. 
      
--------------------
1/5/23 Completed posting to Ripnread and Facebook

--------------------------
1/7/23 To do today

✅    Clean up Diamond_Music_First_Steps. Keep only those files that are needed to move forward.
      a.    Copy it to an archive: /home/prent/Dropbox/Tutorials/Diamond_Music_Archive
      b.    Delete all the steps along the way no longer offer any value 
      c.    Move all the functions in Diamond_music_combined_voices.ipynb into diamond_music_utils_no_cts.py
            Make use of 
                  jupyter nbconvert --to python notebook.ipynb 
            This created Diamond_music_combined_voices.py - used it and deleted it.
            Copy all the functions over to diamond_music_utils_no_cts.py
            Renamed diamond_music_utils_no_cts.py as diamond_music_utils.py
            renamed the one with ctcsound support was renamed as diamond_music_utils_ctcsound.py
            Fixed all the references to functions in the library in the file: Diamond_music_combined_voices.ipynb
            Copied that one over to Diamond_Music_using_utils.ipynb - that's the one I want to start with to implement the g functions.

      This is a fairly large task. One of the issues I'm struggling with now is chosing what to put in the utility python module and what to keep in the notebook.
      a.    Should voice_time be notebook only? I could pass it to the utility when needed. <-- that's what I picked, and it was rather simple, as long as I was methodical. 
      b.    Should it be utility only? I could build a trivial API to get and put it as needed, like I did with function_tables - that would have been more complex.
      Got it done. It makes it all the way to the end of the notebook and generated #16, which is quite nice.

      I'll also need to test and validate all the calls from the new utility functions that currently refer to dmu.function_name, and have to switch to just the function_name.

2.    Before I forget aout it, the trills are expecting a very specific length of time. 
      When you add 10% to that length, then the trills are no longer synchronized with the tempo. I left it that way to add some variety, but it would probably be a good idea to fix it somehow. I could either assume the 10% always, and compensate in the trill length. Or do something else that will be just as devilishly complicated and full of smelly code.            

✅    Time out for a Facebook comment: from a post by Basile Huguenin-Virchaux
      I see a lot of interesting discussions here about harmony outside of 12-ED2, and I suddenly had an idea :
      Why not training a neural network that would be able to generate plausible chord progressions from any given pitch set ?
      The main difficulty for this would be to find a universal representation of tension - release relationships, but I have some intuition that using cents values plus a dissonance curve should do the trick (in which form is all the question). If this type of encoding is good enough, we should even only need to train the network in a 12-ED2 context and then it should be able to generalise the hidden "rules" it found to apply them in different context.
      I'm currently teaching myself about deep neural networks with tutorials and articles, but it seems to me that this specific project would really require a team because there are a lot of considerations to be aware of outside of the pure implementation side of things.
      Are there some folks here that would be interested in such a thing ? Also copying this to Xenharmonic Alliance.
      My response:
      I have been studying deep neural networks (in connection with some business uses like fashion prediction and credit checking). But I also have begun using the techniques to make music. One tried-and-true machine learning technique is the grid search. I applied that technique to searching for the optimal path through a series of tetrachords. The goal was minimizing the distance each of four voices would have to travel to reach their notes in nine four-note chords. I like the results so far. But I knew the chords I wanted to use, and it's a relatively simple task to find the best inversions to minimize movement in such a sequence. I've also used the Muspy library to evaluate the results of deep learning synthetic Bach chorale generation. https://muspy.readthedocs.io/en/latest/metrics.html. Hao-Wen Dong created this library of python functions that can do a variety of things. I evaluated chorales generated by TonicNet searching for those with the highest pitch entropy. I find them the most interesting. But I have not tried to use deep neural networks for chord progression generation in light of microtonality. As Plikity Plok mentioned, you usually need a corpus of wotks to learn from. Bach chorales provides that. But don't let that stop you. Muspy has a very limited set of metrics that can be applied to a set of chords. But it's a start. It can be the basis for scoring chords based on human perceptions. That suggests something along the lines of Reinforcement Learning from Human Feedback. ChatGPT uses that technique. And according to the Wall Street Journal, they are looking at an IPO in the $49 billion range. You could have the machine invent a progression, and have some human subjects score it. The machine would learn from the score and try to do better. If you are very patient, you could achieve some good results. There's more on the ChatGPT RLHF method here: https://www.assemblyai.com/blog/how-chatgpt-actually-works/

4.    Start work on the g function in Diamond_Music_using_utils.ipynb
      This one still has the cell designed for experimenting with future functions. 

---------------------------
1/8/23 To do today:

✅    Check out the work you did yesterday in moving functions into the library. 
      Start up a jupyter lab environment away from the one you ran to make the changes. Need to verify that all the calls to functions go to the python library and not to phantom cells that no longer exist.
            cd ~/virtual_python/virtual_python/ # <-- not sure this is required.
            jupyter lab --notebook-dir=~/Dropbox/Tutorials/Diamond_Music_First_Steps/ # tell jupyter what directory you want to run in 
      Found a bunch of calls that had what I was worried about.
      Once you are certain it is working, move the files to the library where the github repo is stored.    

✅    Fix the dictionaries directory. It's full of no longer valid contents.

✅    Sharps and flats: ♭♮♯

✅   Stop a running jupyter server:
      list the running servers:
            jupyter server list
                  [JupyterServerListApp] Currently running servers:
                  [JupyterServerListApp] http://localhost:8888/ :: /home/prent/Dropbox/Tutorials/Diamond_Music_First_Steps
            pkill -f -1 jupyter*
      It's gone now.      



-------------
1/11/23 To do today:

1.    Consider https://www.riffusion.com/about generates music from spectrographs. Code: https://github.com/riffusion/riffusion Or not.

✅    Double check the masking. 
      Make sure the masking in each of vamp_creator and bridge_creator are not influenced by the predominance of one or two instruments in the input that is masked:
            density_input = np.array([.9, .8, .6, .8, .9])
            logging.info(f'{density_input = }')
            notes_features = dmu.masked_notes_features(notes_features, dmu.build_density_function(density_input, notes_features.shape[0])) 
      This function, masked_notes_features operates on notes[:,2]. What is that field? Hold value. 
      Fields in notes_features: 
            0     1     2   3   4    5    6     7    8    9   10   11   12  13   14
            inst dur hold vel note octv voice stereo env gls1 ups renv 2nd 3rdl vol
      It uses the density function to affect the liklihood of setting the hold value to zero. The problem is that there is no relationship between the numbers and the timing. It more likly than not would simply favor one instrument over another, 
      At this early in the process, there is no solid relationship between the index into notes_features and the time scale.
      What is the relationship between the inx and the instrument? The file is a bunch of notes with features. The instruments all seem to be clumped together. I need to print them out to be certain. There is no relationship to speak of. It's a clump of notes in one voice, maybe 40, then another clump of 40 in a different voice. They all come together to get assigned start times, then they are sent to csound. In the latter, those with non-zero hold and non-zero octaves are preserved. 
      That's all well and good from the way it sounds: instruments go silent sometimes, then they are all over the place. Just like life. 
      If I really want to have total control of the density over time, I'll need to add something to send_to_csound_file to receive a density function and zero out some notes if we are seeking a less dense result. 

✅    Get the g function working. 
      I'm thinking I don't need to do anything else in the this function, other than just storing the gliss number, as in the number of notes that will need to be part of a slide.
            dmu.fill_out_text(input) # <-- ensure that each "word" has all the required features. noevugd.
      Just return those values to the caller and let them sort out what to do with them.    
      Be sure to set the default value for the gliss to 799.          

--------------------------
1/12/23 To do today:

✅    Masking is getting by on a wing and a prayer, and some serious denial. 
      Of course it sounds good, because I've been tweeking it like some kind of cargo cult until it sounds good. Should I stop there?
      I should really improve this function so it does a more sensible job and is faithful to the idea of timing.
            density_input = np.array([.9, .8, .6, .8, .9])
            dmu.masked_notes_features(notes_features, dmu.build_density_function(density_input, notes_features.shape[0])) 
      That one does very unpredictable masking, since the density function is not related to timing, but rather to where the clump of instruments is coming out of the vamp_creator or bridge_creator. 

      It might be easier if I just stop using it for now, and build a different masking function that does what I thought the old one did. That is:

            notes_features, voice_time = dmu.fix_start_times(notes_features, voice_time) # now you know the timing, but they are still not sorted by time.
            # Here is where you have the start times comitted. If you mask here, it will accurately reflect the timing.
            notes_features = dmu.send_to_csound_file(notes_features, voice_time, CSD_FILE, tempos = 't0 ' + str(tempo), tempo = tempo, print_only = 20) # , limit = 0.75

      I'm thinking I should have a different set of voice numbers each with unique density functions. What are the voice numbers at this point, after fix_start_times and before send_to_csound_file:
            They are 'csound_voice' after fix_start_times.
            voice_time:
                  {'fp1': {'full_name': 'finger piano 1',
                  'start': 0,
                  'csound_voice': 1,
                  'time_tracker_number': 0},

      So I am at the right spot, and I have a list of unique voice numbers in a collection, and I have some notes_features. The question is what would you like to do with them?
      I decided to just set the octaves to zero.

      Somehow there is a huge dump of notes at the very first second. from line 25 to 345 all in the 1/10th of a second.  Big bang there. Clipping on a massive scale. Why is the start time changed? Fixed it.

      So now I have a working function that reduces the density across the entire piece, based on a density function for each instrument group. But the result sounds flat. 
      I need more control over the timing of the different percentage chances of the note being zeroed out. Just randomly picking several points and hoping for the best doesn't work:
            density_input = np.array([[.89, .8, .6, .5, .8, .7, .6, .8, .9, .99], # bass line 
      I need to know how long to stay at one point and when to move to the next. How long are the sections?
      The problem is that I will need to determine the relationship between the number of notes and the number of voices, and the tpq in place for each voice. 
      For every time through the vamp_creator and bridge_creator, 
      I have the prune function, which reads notes_features, and uses the global instrument names, and logs the total time. I can repurpose that to return time_steps.
            def total_time_steps(notes_features):
                  return max_dur
      That will give me the duration of each section. I will need to preserve that until I need it to build the density_input string.
      So I now have that: 
           
            section_num = 17
            sums to 912 
            912 / 24 = 38. So I should create a density_input with 38 points for each of four instrument clusters.
            
            density_input = np.array([[.9,.8,.9,.7,.8,.9,.6,.7,.8,.9,.9,.7,.8,.9,.8,.7,.6,.8,.9,.8,.7,.6,.9,7,.8,.7,.6,.9,.8,.7,.8,.9,.6,.7,.8,.9,1.0,1.0], # bass line 
            
      A better idea is just to track transition points. The current method just creates too many to deal with, and is error prone. 

✅    Consider taking the whole notes_features array at some point and flipping it. Too late. It screws up the timing when you take something that already has durations in it and run it backwards. Or it appears to.

-------------------------
1/14/23 To do today 

✅    Finish the effort to sensibly control density over time. 
      a.    The best density reduction takes out a whole instrument group for a while. Especially for the horns and bass flute parts. Just getting rid of one or two of the eight instruments just makes it sound thin and weak. It's either there or it isn't. You can get away with occasional thin sounds, but not too many. Make them rare. This implies that the thin sections should be more common than a whole section, but rather chop up a section with dense and thin parts. 
      b.    What transition points do you have now:
             verse       bridge      verse       bridge      verse       bridge      verse       bridge      verse
             24          96          168        240          432         576         720         864         912
             24          72          72          72          192         144         144         144         48
      key    1           1           1           1           2           2           2           2           1
      repeat 1           1           3           1           4           1           3           1           2
      24 96 168 240 432 576 720 864 912
                                             V   BBB VVV  BBB VVVVVVVV BBBBB VVVVVV BBBBBB VV
                                             1   3   3    3   8        6     6      6      2
      section_length[:section_num] = array([ 24, 72, 72,  72, 192,     144,  144,   144,   48])
      So how do I convert that to density_input? It requires 38 data points. In reality it needs far more, since I want each section to have a variety. 
      density_input = 

----------------------------
1/15/23 Same as yesterday.
     
✅    Now that I've populated the density input by hand, I'm finding some unpredicted results:
      I had to change the first few values so that it would start the first bridge with a decent horn and flute probabilities.
      density_input = np.array([[.9,  .9, .9, .9, ...
                          [.01, .7, .9, .9, ...
                          [.9,  .8, .9, .6, ...
                          [.01, .5, .9, .9, ...

      I think as a general rule I should apply measures on the micro level to achieve micro level effects, and leave the macro trends to the macro effects.
      In other words, put the change in the small sections that belong there, and the ones in the large sections put them there. 

---------------------
1/16/23 To do today:

✅    Choose the right g feature and start it's implementation. The Anita Baker slide. Rapture 1986.

      Get back to work implementing the g text input capability for short glissandi in existing text input processing. 
      I'm thinking I should leave this one as is. There is plenty of slides here. I put all those slides in when I had so many horn riffs sounding alike. I also wanted to add slides to the bass part. But I think this is pretty good as it.

✅    Implement glissandi in text_to_features.
      What if I add another letter to the text_to_features function "g" which says how many of the next notes should be arrived at by glissando? That would be awesome. I'm always in search of that Anita Baker glissando. So many choice and controls.

      How would it work? 
            inputs_array = ["o4e1v56n0d4u0 n1 n2 n3 n4 d16n5 d4n6 o0n4 o4n5 o0n3 o4n4 n2 n3d2 n1",
                        "o4e1v56n0d4u0 n1 n2 n3 n4 d16n5 d2n6 n4 d4n5 n3 n4 n2 o0n3 o4n1 o0n2 o4n0",
                        "o4e1v56n0d4u0 n2 n1 n4 n3 d20n5o0 d2o4n5 n3 n4 n2 e8v62n3d1 n1 n2 n0",
                        "o4e1v56n0d2u0 n1 n2 n3 n4o4 d10o0n3 d16n5o4 n0d4 d6n1 n2 n3 n4",
                        "o4e8v62n0d1u0 n1 n2 n3 n4o4 d15e1v56n6 d20n0o0 d6n1o4 n2 n3 n4"]

      Where will it go?
            It needs to go after text_to_features was called. 
            Some will go in bridge_creator, verse_creator where text_to_features will now return a gls value.
            Some will go in build_horn_from_text
                  bass_flute_note_array = build_horn_from_text(repeat_section, repeat_all, notes, octv, env, vel, ups, gls, voices, \
                              mode = mode, root = root, rank = rank, roll_low = 0, roll_high = 1) #
            In build_horn_from_text:
                  # we could include some gliss values if we wanted to. 
                  gliss_array = np.full(note_array.shape, 799, dtype = int)
            How does the horn slide work in bridge_creator?
                  #                                       +-- what rank to use "A", "B", etc.
                  #                                       |     +-- there are 19 available
                  #                                       |     |          +-- 2 to 119
                  notes, gliss = new_multiple_chord_slide(rank, array_num, each_slide_step)
            It keeps the ftables needed for the glissando tracks through the chord changes.
            It returns the notes, gliss (table numbers) - it doesn't check for reuse
            It calls _build_voice_slide one voice at a time to track the changes through all the notes in the chord progression. This might be useful. 
                                         +-- current table number - the next f table available
                                         |      +-- all the notes that have to be passed through
                                         |      |                +-- how long is each glide
                  def _build_voice_slide(t_num, one_voice_array, each_slide_step = 120):
            It returns the ftable content for that multiple note glissando that csound requires. The caller is responsible for storing the table number, and saving the ftable for later passing to csound. 
            I will need a separate function but one that used new_multiple_chord_slide as a model.

            How does the bass flute slide work in vamp_creator?
                  bass_flute_note_array = build_bass_flute_part(repeat_section, repeat_notes, repeat_all, octaves, env, voices, mode = mode, root = root, rank = rank)
            It relies on a combo_set, a number from 8 to 16 or so as an index into best_rank_inversion_combos which is an array of (32,4) combos, rank1, rank2, inv1, inv2 
            It calls root_chord_slide(mode, root, best_rank_inversion_combos[combo], choose_trill_type(repeat_notes))
            It calls gliss = dmu.build_slides(tones_1, tones_2, gliss_type = gliss_type), but that only works for two notes. It does a great job with a move from one tetrad to another. It checks to make sure it needs to create a new ftable, or if it can reuse and earlier created one.

            So I'm building multiple_note_slide(note_array, each_slide_step):
                  return notes, gliss
            Based on new_multiple_chord_slide.
            How it's used:
                  you need to build a note_array consisting of the notes that you want to slide between. just those notes and no others.
                  notes, gliss = multiple_note_slide(note_array, each_slide_step)
                  notes = notes.reshape((4,1))
                  gliss = gliss.reshape(notes.shape)    
            What is the user interface:
                  g#number of notes to slide across. 
            Scale steps:
            0     1     2     3     4     5     6     7     8
            32    34    36    38    40    42    44    46    48

                                      +-- g8 glides n0 to n2 over 8 time steps
                                      |             +-- g12 glides n2 to n4 to n3 over 12 time steps
                                      |             |           +-- g0 ends glide
                               32       36   34 38    36 40 38   42 
                        o4e1v56n0d4u0g8 n2 g0n1 n3 g12n2 n4 n3 g0n5
                  normal processing:  np.array(32, 32, 32, 32, 36, 36, 36, 36, 34, 34, 34, 34, 38, 38, 38, 38, 36, 36, 36, 36, 40, 40, 40, 40, 38, 38, 38, 38, 42, 42, 42, 42) 
                  after processing g: np.array(32, 32, 32, 32, 32, 32, 32, 32, 34, 34, 34, 34, 38, 38, 38, 38, 36, 36, 36, 36, 40, 40, 40, 40, 38, 38, 38, 38, 42, 42, 42, 42)
                       gliss_array =  np.array(8,  8,  8,  8,  8,  8,  8,  8,  0,  0,  0,  0,  0,  0,  0,  0,  12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 0,  0,  0,  0)
            
            gliss_array = [801, 801, 801, 801, 801, 801, 801, 801] # I'm assuming all notes will get the same glis, as they get the same note, octave, env, vel, ups
      Some of the factors you will need to deal with. I never really considered how to handle overlapping glides. Make sure you test this out.
      a.    How long to stay at each note in the slide if it goes over more than two notes. Assume equal time for all? ___/   \____
      b.    How to deal with repeated slides, one after the other with no g0 pause.                                     3 1 3 1 4  = 12 steps
            They will look identical to a slide that continues
      ✅    When to build the slides. 
            1.    Should I build them in the same function as I discover the g values? No
            2.    Or wait until after the return from dmu.text_to_features() in bridge_creator or vamp_creator? Yes
      ✅    How to use or modify:
                  def _build_voice_slide(t_num, one_voice_array, each_slide_step = 120): 
            to meet these requirements.
            So I've been able to separate out several different elements:
                  keep this section discrete: notes_in_scale[end:start] = array([32, 32, 32, 32])
                  build a glide over this section: original_scale[start:end] = array([34, 34, 34, 34, 36, 36, 36, 36])
                  keep this section discrete: notes_in_scale[end:start] = array([38, 38, 38, 38])
                  build a glide over this section: original_scale[start:end] = array([40, 40, 40, 40, 42, 42, 42, 42, 44, 44, 44, 44])
                  keep this section discrete: notes_in_scale[end:] = array([46, 46, 46, 46])
            Now I need to pass them through different functions. 
            I have the slide part almost ready, but since I'm passing 8 notes, the slide takes place only during the change in note ratio. I'd like to compress the array before sending it though the function. Use np.unique(). But what if the array looks like this: np.array([32, 32, 32, 32, 34, 34, 34, 34, 32, 32, 32]), it gets compressed down to (32, 34])
            I wrote a util called thin that does what I want, compressed duplicate notes away. 
            
      ✅    I'll need to preserve the memory of the notes that the slide will go over, after I've changed the notes to be where I want them. 

      ✅    I've isolated the notes that have to be slid over, then I need to run them through the _build_voice_slide function. And concatenate them with the notes that don't need sliding.

      ✅    It would really simplify matters if I changed the gliss for no slide to 0, but that one is already used for a special purpose, namely how long to keep csound active waiting for work. "An f 0 statement (zero p1, positive p2) may be used to create an action time with no associated action."
      But it can also be used as a normal f table.
            f0 0 256 -7 1 256 1 ; no slide

      ✅    Where I left off: trying to concatenate the newly created f table to the stored f tables.
            stored_gliss_table = np.concatenate((stored_gliss_table, gliss_f_table), axis = 1) # this is a global variable.
            gliss_f_table.shape = (70,), stored_gliss_table.shape = (0, 70)
            gliss_f_table = np.reshape(gliss_f_table, (1, 70)) # <-- fixed it

---------------------
1/17/23 To do today

✅    Finish filling out the glide parts and the non-glide parts of the text processing steps.
      a.    populate the notes, octv, env, vel, ups, gls with the proper number of slots for each note.
      b.    notes - notes_in_scale has the right values, as does env, octv, vel
      c.    ups - needs to be able to increase or decrease the ups away from 0 if the slide goes up or down.
            0     1      2    3     4   5    6     7    8     9   10   11    12  13    14
            800.0 0.0 2048.0 -7.0 1.0 121.0 1.0 120.0 1.11 121.0 1.11 120.0 1.11 0.0
            element 4 & 6 is the start destination
            element 8 & 10 is the next destination 
            element 12 & 14 is the third destination
            element 16 & 18 is the 4th, theoretically
      
-----------------------------
1/19/23 To do today:

✅    Figure out where the parsing of the gliss values should go.
      in vamp_creator, in horn, we process several lines at once
            answer = np.array([dmu.text_to_features(dmu.fill_out_text(input), shuffle = rng.choice([True, False], p = [0.1, 0.9])) for input in input[input_chosen]]) 
      Then we parse the answer variable into arrays of notes, octv, env, vel, ups, gls, tile them by voices 
      Then send them through dmu.build_horn_from_text.
      in bridge_creator, in flu, we process only a single line
            notes, octv, env, vel, ups, gls = dmu.text_to_features(dmu.fill_out_text(inputs_array), shuffle = shuffle)
      tile by voices 
      send them through dmu.build_horn_from_text
      So if I put the processing of the gliss in build_horn_from_text, that means it only has to be in once place.

      There is a problem with dmu.build_horn_from_text. It is expecting all the voices in one batch, and I expect one voice at a time. 
      I will have to split them up into individual streams, then reassemble them at the end.

      So the question now is, why is the input to dmu.build_horn_from_text gliss shape (4,48) when all the others are (8,48)?
      Start here on Friday.z

✅    Remember to do something about the ups in the flu section where it assigns each instrument a different ups value. 
      I like that idea, but it should not just reassign them. It needs to shift the values that have already been assigned.

-----------------------------
1/21/23 To do today:

1.    See if you can get the whole environment working on the T15 laptop. 
      It didn't work, asked for an ipykernel install from pip.
            cd ~
            python -m venv virtual_python
            source virtual_python/bin/activate
            pip install ipykernel
      Still could not get code-server to execute the jupyter. Kept saying it was missing ipykernel.I got it working on several occasions, but never consistently.

✅    Fix the problem with the dimensions of the gliss array I found on the ThinkCentre.
      I think it's because I preloaded the gliss array before I sent it to further processing.
      vamp_creator called build_horn_from_text.
            2023-01-21 10:07:05,109 - root - INFO - vamp_creator horn before tile. answer.shape = (4, 6, 16)
            2023-01-21 10:07:05,113 - root - INFO - vamp_creator horn after tile.  answer.shape = (4, 6, 48)
      I think the problem is that I have two names for the gliss array and I get them mixed up. 
      gls = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0])
      At the very start of build_horn_from_text it has gliss_array as (4,48), while all the others are at (8,48)
      gliss_array.shape = (4, 48) # <-- right after it shows it as (48,0) here it is as (4,48)
      The reason is that I had neglected to tile the gls array, as I had all the other arrays.
      if voices > 4:
                  notes = np.tile(notes, (voices // 4, 1))
                  octv = np.tile(octv, (voices // 4, 1))
                  env = np.tile(env, (voices // 4, 1))
                  vel = np.tile(vel, (voices // 4, 1))
                  ups = np.tile(ups, (voices // 4, 1))
                  gls = np.tile(gls, (voices // 4, 1))
                  shapes = [arr.shape for arr in [notes, octv, env, vel, ups]]
✅    Create a jupyter session in code-server serve-local
      https://code.visualstudio.com/docs/python/environments
      I was able to do it once using code (the app), but not using code-server serve-local. But even the code version wasn't reliable.
      I got the code-server to work as well. I finally stumbled into a solution. For a while, but reboot and it vanished.

      First make sure the environment has been activated. I used this advice: https://stackoverflow.com/questions/64997553/python-requires-ipykernel-to-be-installed
      Open a new terminal window (ctl-shift-~)
      issue the environment commands:
            cd ~ 
            python -m venv virtual_python 
            source virtual_python/bin/activate
      Help from here: https://code.visualstudio.com/docs/python/environments
      search for "Work with Python interpreters"
            clt-shift-P
            Python: Select interpreter 
            select the one that says venv. 
      Now you have jupyter inside code-server. 
      But it can't find any of the python libraries, like numpy, that I installed in the environment, and it clearly won't find diamond_music_utils.py
      It's finally working, once I selected the right kernel:
            python 3 (ipykernel)

4.    I'd like to see if I could get the cuda library working on this machine for deep learning. Forget it Jack, it's a MX450 wimpy card.

--------------------------
1-22-23 To do today

✅    See if you can get a few slides working on the bass flute and the woodwinds.
      Trouble: thin(arr):
            993     target = np.zeros(arr.shape, dtype = int)
            --> 994     prev = arr[0]
            995     inx = 0
            996     for element in arr:

            IndexError: index 0 is out of bounds for axis 0 with size 0
      in build_horn_from_text. original_scale.shape = (4, 60), start = 12, end = 20
      There's your trouble: 
            in build_horn_from_text. original_scale.shape = (4, 64), start = 12, end = 28
            in thin. type(arr) = <class 'numpy.ndarray'>
            arr.shape = (0, 64)
      I'm expecting array of shape (some_number,)
      What goes into build_horn_from_text is four voices. It should be one voice at a time. I thought I fixed that.
      The problem was that I was assigning notes_in_scale[note_array] before spliting it into streams of one note per stream. I moved it into the loop:
            for notes, octv, env, vel, ups, gls in zip(note_array, octave_array, envelope_array, vel_array, ups_array, gliss_array):
                  notes_in_scale = scale[notes] # these will change for those notes that are gliding by f table
                  original_scale = scale[notes] # these will be saved to send to _build_voice_slide
                  logging.info(f'processing a stream: {[var.shape for var in [notes, original_scale, octv, env, vel, ups, gls]]}')
      Finally fixed that one. Then another cropped up:
      And another. Picking them off one by one. The reason is that the code path for the gliss wasn't tested until now.
            notes_in_scale is wrong:     [(64,),         (4, 64),        (4, 64), (4, 64), (4, 64), (4, 64)]
      The problem is that notes_in_scale and original_scale were being handled wrong.
-------------------------------------------
1/25/23 To do today:

✅    Several bugs that I thought I cleared yesterday are back again. 
      I must have neglected to synch after returning home last night. Bummer. I remembered most of the changes and was able to apply them quickly. 

-----------------------------------------
1/29/23 To do today

✅    Figure out why the slide bass flute parts have clicks. They end with DC signals. 
      a.    Why the short envelopes?

✅    Get rid of the silences until you are happy with the slides. Set likelihood = 0.99
      def build_horn_from_text(repeat_section, note_array, octave_array, envelope_array, vel_array,\
            ups_array, gliss_array, voices, mode = "oton", root = "16/9", rank = "A",\
            roll_low = -3, roll_high = 4, likelihood = .65, octave_shift = 0):

✅    Don't forget to ensure the ups values are right.

✅    Take a look at the eps output.
            gs -sDEVICE=pdfwrite -o ball3.pdf ball3.eps
      Notice that it is a GEN06: segments of cubic polynomials
      Here is the multinote horn slide after modifying the size of the steps and stays.
            I need 9 stays and 8 moves
            f 800.0 0.0 2048.0 -7.0 
            1.0 114.0 1.0 113.0 
            0.9642857142857143 114.0 0.9642857142857143 113.0 
            1.0125000000000002 114.0 1.0125000000000002 113.0 
            1.05 114.0 1.05 113.0 
            1.125 114.0 1.125 113.0 
            1.125 114.0 1.125 113.0 
            1.125 114.0 1.125 113.0 
            1.0546875 114.0 1.0546875 113.0 
            1.0 114.0 1.0 114.0 1.0  
      average_slide_step = 227.0, each_stay_step = 114.0, each_slide_step = 113
      2023-01-30 14:20:05,908 - root - INFO - total_f_steps = 1930.0
      How large is it? 1930. Too small.
      I'll have to take a look at _build_voice_slide()

✅    Fix the bugs in _build_voice_slide. 
      I think I got rid of all of them with the exception of the long slide, where that ends by going to zero, but after it has completely faded away. 

-------------------------
1/30/23 To do today:

✅    Set up an environment where the coding takes place on the T15 and the jupyter notebook is on the ThinkCentre.
      
      On the ThinkCentre:
            toolbox enter tunnel
            code-server serve
      It generates a URL to access from the T15:            
            https://insiders.vscode.dev/+ms-vscode.remote-server/think-center/var/home/prent
      code-server then allows you to open a folder you'd like to work in, and this switches the URL to:
            https://insiders.vscode.dev/tunnel/think-center/var/home/prent/Dropbox/Tutorials/Diamond_Music
      This is your window into the files on the ThinkCentre, not the T15. 
      
      Set up a separate tls tunnel to the ThinkCentre that mirrors 8888 port on the TC back to the T15.
            ssh -L 8888:localhost:8888 prent@192.168.68.73
      You may find that the port is already in use. If so:
                  lsof -i :8888 
                  kill -9 xxxx
            Kill the using pid xxxx thus listed or use this one-liner (didn't work the one time I tried):
                  lsof -wni tcp:8888 | xargs -I{} kill -9 {}
      The tunnel opens up a terminal window back on the ThinkCentre. Enter these commands on that window:
            cd ~
            toolbox enter tunnel
            python3.11 -m venv virtual_python
            source virtual_python/bin/activate
            jupyter lab --notebook-dir Dropbox/Tutorials/Diamond_Music
      Access this link on the T15 for the jupyter lab server on the TC:
            http://192.168.68.73:8888/lab        
      
      Note that you won't be able to play the audio file on the ThinkCentre in his Music/sflib folder using an audio player on the T15. You will be limited to audacity on the ThinkCentre. Deal with this by shipping the eps and wav files back to the T15 in the jupyter notebook, then running them on the T15. Easy-peasy.

✅    Finish the modification to the horns and the flute to include slides.

✅    Find out why the horn and bass flute sometimes get way too low octaves.
      I think it's because of the octave_shift variable. And why is the each bass flute playing different options. They should be in unison. On the other hand, it much more likely that it's caused by setting the octave to zero in the text, and subsequently having the octave shift send it up one octave to o1 or o2, which is way too low. That was it. Fixed it.

--------------------
1/31/23 To do today:

✅    Check this out. Summary of progress using AI for audio: https://github.com/archinetai/audio-ai-timeline
      They all sound like real music through a tunnel. In the distance. Like a lousy distortion pedal. Reminds me of the joke about the dog that can talk. He describes all the marvelous things he had done, in great detail. When the visitor asks why the owner wants to get rid of him, he answers that he's a terrible liar. 

✅    Fix the problems not solved in previous efforts. 
      Right now I'm stuck on dimensionalilty problems in build_horn_from_text.
            if note_array[inx, oct_col, inx2] > 0:
      I think I have an incorrect impression of note_array at this point in the code:
            note_array.shape = (6, 4, 64)
            beforerolls. rolls = array([0, 0, 0]), note_array[0,0,:8] = array([32, 32, 32, 32, 32, 32, 32, 32]), repeat_section = 3
            after rolls. rolls = array([0, 0, 0]), note_array[0,0,0,:8] = array([32, 32, 32, 32, 32, 32, 32, 32])
            repeat_section = 3
            note_array.shape = (3, 6, 4, 64)
            about to add new_octave = 0 to the current octave
            3 repetitions, 6 features, 4 voices, 64 note across the 4 voices.
      I'm cleaning up some of the cruft, and fixing things, but some problems still remai:
            1.    Some non-unison sections. 
                  These could be a result of taking each voice separately through some function and getting different results. These appear to have gone away.
            2.    Some very deep bass sections. I figured that one out, after about 2 1/2 day's work.

-----------------------
2/1/23 To do today:

✅    I'm starting to think that there are too many ways to make changes to the build_horn_from_text function. 
      a.    For the bass flute, here are the setting that:
            1.    Shuffle the order - only in 1% of cases
                  shuffle = rng.choice([True, False], p = [0.01, 0.99]) # shuffle will come later after I get the g values working
                  notes, octv, env, vel, ups, gls = dmu.text_to_features(dmu.fill_out_text(inputs_array), shuffle = shuffle)
            2.    np.flip the arrays if mode = 'uton'. After it converts the input from text to 6 features.
            3.    Mask octaves to zero to drop notes, only in 1% of cases
                  likelihood = 0.99 
            4.    How does the variable repeat_section affect the output: adds a dimension onto the start of the array.
                  (6, 4, 64) becomes (3, 6, 4, 64)
                  rolls = np.array([rng.integers(low = roll_low, high = roll_high, size = None) for inx in np.arange(repeat_section)])
                  note_array = np.array([np.roll(note_array, r, axis = 2) for r in rolls])
            5.    Do I make the repeats get quieter. I don't know. It's set in the call to build_horn_from_text vel_echo_max = 7 is default.
            6.    Alter the octave with octave_shift. No octave_shift defaults to 0
            7.    build_scale_mask for octaves only if not shuffle
                  if shuffle: scale_mask = np.full(notes.shape, 0) # if you are shuffling the order of notes, don't mask the octaves.
                  else: scale_mask = dmu.build_scale_mask(notes)  # if you are not shuffling, then mask away.
                  octv = octv + scale_mask
                  octv = np.array([np.min((octv[inx],5)) for inx in np.arange(len(octv))]) # limit it to no more than octave 5 or 6
            8.    When to you tile the voices? Before you send them through build_horn_from_text. What if you were to do that later?
            9.    Do you roll? No. Roll is only there to repeat_section repeats.
                  roll_low = 0, roll_high = 1
            10.   How long is each inputs_array element in terms of the d value sum.
                  Where is that checked? It's not. It should be. I put in a check to confirm the shape, and got a hit right away:
                  I fixed that one and this one popped up:
                              4            4  4  4| 4   12|8      8|4  2         2  2  2    1  1  1  1 
                        'o4e1v71n0d4u0g16 n2 n1 n4 n3g0 d20n5o0 n4d12 d2o4n5g12 n3 n4 n2 n3d1 n1 n2 n0'
                        Expected a duration of 64 and received notes.shape[0] = 66
                        fixed it.
            11.   Why are we still getting very low octaves:
                  Why would I have ones in the octaves? They were not in the text input.
                  It appeaers to be because of the scale_mask application.
                  Well that explains it. It takes a zero (meaning don't play now) and turns it into a one, very low note.
                  Should I just dump the octave mask? It's designed to keep a rising scale rising, not arbitratily dropping an octave in certain keys. But when it does it's job, is will frequently send the octave into the stratosphere. Here's an exampld:
                  scale_mask = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,
                        ...
                        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7]) #<-- 7 octaves up? Crazy.
                  after applying scale_mask:
                  octv = array([ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,
                        ...
                        9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11])
                  Fortunately, I have a filter that constrains the movement on the back end.                        
                        octv = np.array([np.min((octv[inx],5)) for inx in np.arange(len(octv))]) # limit it to no more than octave 5 
                  I changed the logic so I could include it if I wanted to. But for now it's gone.

            12.   New bug. null string in prev_oct. Why?
                  def text_to_features(input, shuffle = False)
                  --> 897       octv = np.append(octv, int(prev_oct))
                  ValueError: invalid literal for int() with base 10: ''
                  How did prev_oct get loaded with a null string?
                  It happened in building the bass line in vamp_creator.
                  It ran ok for a few, then this is what it barfed over:
                  input_chosen = 'n0o2d2g0e8v77 n2 n4 n6 n1o3d3 n6o2d1e2v82 n3d3e8v77 n4d1e2v82 n2d3e8v77 n0o2d1e2v82 n4n3e8v77 od1e2v82 o2n0d3e8v77 n2d1e2v82 n6d2e8v77 o1d4'
                  Crash.
            Prove it:
                  test_input = 'n0o2d2g0e8v77 n2 n4 n6 n1o3d3 n6o2d1e2v82 n3d3e8v77 n4d1e2v82 n2d3e8v77 n0o2d1e2v82 n4n3e8v77 od1e2v82 o2n0d3e8v77 n2d1e2v82 n6d2e8v77 o1d4'
                  notes, octv, env, vel, ups, gls, _ = dmu.text_to_features(test_input)
                  type(prev_oct)= <class 'str'>, prev_oct = '2'
                  type(prev_oct)= <class 'str'>, prev_oct = ''
                  Crash.
                  So the problem isn't that it's a string. You expect that. It's that it's empty.
                  od1e2v82 <-- There's your trouble. I suppose I could check for zero length strings. Done. Won't happen again, or if it does, I will be quickly able to fix it. 

-------------------
2/2/23 To do today:

✅    Fix all the changes I made to the bass flute to remove the dropouts. likelihood = 0.99 --> .7, shuffle 10%

✅    Do I make the repeats get quieter. I don't know. I can hear it in the horns, if faint. If you don't notice it, it's not strong enough.
      I had implemented it, but without comment.
            note_array[inx, vel_col, :, inx2] -= inx * rng.integers(4, high = vel_echo_max) # decrease the velocity with each repetition. 
      It works. Perhaps I need to increase vel_echo_max, the larger it is, the quieter the repeats. 

✅    The bass flute is really wiggy. The random choices are very strange. It could be that I need to mask fewer notes. 
      The quick d1 and d2 slides are ugly. 
      It sounds like the bass flute notes are being truncated if they are part of a slide. So I reduced the choices to just one for the oton and one for the uton, and the result is a mass of different outputs:
            'n0o4d12u0g0e1v71 n3d4g12 n4 n5 g0n6 n7 d6n0 g18n1 n3 n2 n4 e8v76d1n6g0 n7'
            'o4e1v71n0d4u0g16 n1 n2 n3 n4g0 d16n5 e8v76d2n6 n4 e1v71d4n5g24 n3 n4 n2 n3 n1'

----------------------------
2/3/23 To do today:

✅    Simplify the input to the bass flute and then gradually increase it until you find the errors. 
            after choosing the input array. inputs_array = 'o4e1v71n0d8u0 n7 n6 n5 n4 n3 n2 n1'
            after choosing the input array. inputs_array = 'o4e1v71n0d8u0 n1 n2 n3 n4 n5 n6 n7'
      The end result was lots of notes for every note. It's like somthing changed several times for every note. Instead of a half note, I got repeating 1/8th notes. This would be caused by something changing from one time step to the next, like the velocity, volume, upsample, or the like. 
      I found our trouble:
            n	o	e	v	u	g
            32	0	1	67	255	0
            32	4	1	67	255	0
            32	4	1	63	255	0
            32	4	1	64	255	0
            32	0	1	63	255	0
      The velocity for the note 34 is constant, but for the note 32, it changes with every time step. 67 to 62. Why?
      The vel value is 71 after it comes out of dmu.text_to_features(dmu.fill_out_text(inputs_array), shuffle = shuffle)
      Something happens after that, probably in dmu.build_horn_from_text(repeat_section, notes, octv, env, vel, ups, gls, voices, \
                              mode = mode, root = root, rank = rank, roll_low = 0, roll_high = 1, likelihood = 0.75, vel_echo_max = 10) 
      I'm pretty sure it has something to do with the echo processing. I must have the dimensions wrong. Start there tomorrow.
      The problem was caused by two issues:
      1.    Too high a likelihood of masking during a d8 note, turning it into several notes. 
            If I want to mask a note completely, likelihood is a bad place to do it. Much better on the back end.
      2.    Echo effect was located in the wrong place      
            note_array[inx, vel_col] -= inx * rng.integers(4, high = vel_echo_max) # decrease the velocity with each repetition. It needs to be only called once during the inx in np.arange(repeat_section) 
---------------------
2/4/23 To do today:

1.    Figure out why it sometimes splits into two different bass flute lines. This is going to be hard to find.
      I suspect is has something to do with a note split by a dropout.
      The first one I found in the current version is in a 154 second piece. 
      27-28 seconds, 42-46, 61-62, 76-80, 95-97, 127-131, 146-149. It's like the border between each of the 9 sections overlap.
      Ran it again and appear to have the overlap at the same times.
      27 42 61 76 95 128
      Same thing again.
      Next step is to try to synchronize the four voices and see if they are not identical.

      36 start of new voice in the whole piece. Each section is three starts. 9 picks of inputs_array. Each 17 seconds. So perhaps its 

✅    Why is the upsample set to 256 & 257. It's supposed to be 255 or lower. Fixed that one.
            if np.all(ups[start:end] > 255): ups[start:end] = 0 in two placed
            f np.all(ups[start:end] < 0): ups[start:end] = 255 in one spot.
            Fixed it.

✅    The change of note during a slide is too abrupt. 
      I need it to take longer to go from one place to another. How is that set?
            gliss_f_table = _build_voice_slide(current_gliss_table + loc, thin(org_notes[start:end]), each_slide_step = 180) # it was 113, changed it to 180, then 225
            def _build_voice_slide(t_num, one_voice_array, total_slide_size = 2048.0, each_slide_step = 113.0):
            Default is 113, but that is terribly fast, close to zero. Some bad math somewhere. It can get as big as 240 by assert statement.

4.    Long term I should really shift to the gliss_type == 'cubic16_16_224':

---------------------
2/5/23 To do today:

✅    Figure out why we have multiple different notes sounding at the end of each section. I think I have an idea.
      I'm logging notes before they go to dmu.piano_roll_to_notes_features. There are a bunch of errors that need to be fixed:
      a.    Each note has a different f table. There are 76 different ftables. I guess we don't check for duplicates. 812, 815, 818, & 821 are different ftables for the same note. I fixed that on 2/11/23.
      b.    Not only that, but there are multiple occurrences of those ftables, and they are each different from the others. Not any more.
      c.    They are not sequential, and numbers are used more than once. Fixed that.
      d.    Some of the very short notes have slides. Fixed that.
      e.    It could be an error in the logging logic. Check it. It was, plus an error in diamond_music_utils.py. After I retrieve a current_gliss_table value, I need to increment it. The number retrieved can be used if it's the first, but not if its the subsequent one.     
      I've made some improvements, but there are still times when two different notes are played.

-----------------
2/8/23 To do today:

1.    Pick some better melodies for the bass flute. Remember, you are trying to emulate Anita Baker in Rapture 1986.

✅    Figure out a working system to edit on the T15 and run on the ThinkCentre.
      a.    This works: 
            Open vscode on the T15
            click the double >< in the lower left corner, connect to ThinkCentre
            open folder Dropbox/Tutorials/Diamond_Music
            open terminal    
                  toolbox enter tunnel
                  hostname -I 
                        192.168.68.73  # <-- you are accessing the ThinkCentre filesystem directly
                  conda activate tensorflow.2.6
                  jupyter lab
            open a jupyter notebook file in vscode 
            Select the conda tensorflow.2.6 environment 
                  You may have to muck around for a while to get it to work.
                  
      b.    This works: but it keeps loosing the connection. This morning it actually worked on the iPad. That's good. How long?
            ssh -L 8889:localhost:8889 prent@192.168.68.73 # <-- on the T15. This may only be necessary if you need to access the Jupyter Lab notebook from a browser. Not if you are only using code-server serve.
            hostname -i 
                  192.168.68.73  # <-- you are logged into the ThinkCentre
            conda activate tensorflow.2.6
            jupyter lab --notebook-dir Dropbox/Tutorials/Diamond_Music
                  You may have to kill a running notebook
                        lsof -i :8889
                              COMMAND     PID  USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
                              jupyter-l 21417 prent    7u  IPv4 205929      0t0  TCP localhost:ddi-tcp-2 (LISTEN)
                              jupyter-l 21417 prent    8u  IPv6 205930      0t0  TCP localhost:ddi-tcp-2 (LISTEN)
                        kill -9 21417
            code-server serve
                  open: https://insiders.vscode.dev/+ms-vscode.remote-server/think-center/var/home/prent
                  Takes a while. When it gets stable, open a folder:
                  /var/home/prent/Dropbox/Tutorials/Diamond_Music
            open a jupyter notebook file in code-server     
            Select a python environment, then select conda tensorflow.2.6 python interpreter.
            If that doesn't work, access the jupyter notebook here:
                  http://localhost:8889/lab

      c.    Some combination of the two that relies on Dropbox to move files from one system to another. 

----------------
2/10/23 To do today:

✅    Put together the skinniest notebook cell you can that can be used to test text to music pipeline. 
      I need the equivalent of the python REPL.
      First problem: INIT ERROR in instr 1 (opcode table.i) line 56: table: could not find ftable 0
      Something wrong with the input, on every one of the 16 notes. I think it's because I missed one of the processes that turns the voice number from the tracking number to the actual csound number. Such as 20-23 into a much lower number.
      fix_start_times needs to be called.
            notes_features, voice_time = dmu.fix_start_times(notes_features, voice_time) 


✅    The echo horn parts don't repeat as echos. 
       aybe it's too quiet on the repeats? Need to validate that they are doing what I expect.

-----------------------------
2/11/23 To do today:

✅    Fix the things you thought you fixed previously:
      a.    ftable numbers are whack:
            f 800.0 0.0 2048.0 -7.0 1.0 382.0 1.0 300.0 1.0909 382.0 1.0909 300.0 1.1818 382.0 1.1818 382.0 1.1818 
            f 802.0 0.0 2048.0 -7.0 1.0 382.0 1.0 300.0 1.2222 382.0 1.2222 300.0 1.1111 382.0 1.1111 382.0 1.1111 
            f 802.0 0.0 2048.0 -7.0 1.0 382.0 1.0 300.0 1.0909 382.0 1.0909 300.0 1.1818 382.0 1.1818 382.0 1.1818 
            f 804.0 0.0 2048.0 -7.0 1.0 382.0 1.0 300.0 1.2222 382.0 1.2222 300.0 1.1111 382.0 1.1111 382.0 1.1111 
            f 804.0 0.0 2048.0 -7.0 1.0 382.0 1.0 300.0 1.0909 382.0 1.0909 300.0 1.1818 382.0 1.1818 382.0 1.1818 
            f 806.0 0.0 2048.0 -7.0 1.0 382.0 1.0 300.0 1.2222 382.0 1.2222 300.0 1.1111 382.0 1.1111 382.0 1.1111 
            f 806.0 0.0 2048.0 -7.0 1.0 382.0 1.0 300.0 1.0909 382.0 1.0909 300.0 1.1818 382.0 1.1818 382.0 1.1818 
            f 808.0 0.0 2048.0 -7.0 1.0 382.0 1.0 300.0 1.2222 382.0 1.2222 300.0 1.1111 382.0 1.1111 382.0 1.1111 
            Reusing numbers 802, 804, 806
            skipping numbers 801, 803, 805
            Not reusing duplicates that are 100% the same 
            Suspicious that of 8 ftables, there are only two different ones.
            Looking at the input: 
                  3, 4, 5 in scale degree, 38, 44, 46 are the first three note slide E♭, A♭, A♮ (sharp is ♯) 
                  1, 3, 2 in scale degree, 34, 40, 44 are the second three note slide C♮, F♮, A♭ 
            Therefore two is the correct number of distinct slides. We just need to not create the duplicates. Later.
            At least get the numbering right. 

      b.    Why don't I get all the notes in the csd file and audio output?
            32, 38 (802), 44, 46. That's only half the notes. I'm ignoring the second half of the notes. It's like instead of all 64 time-steps it's only using 32. That's interesting. What is causing the cutoff of notes? 
            piano_roll_to_notes_features only reads the first 32 time_steps. I suspect it's because the volume array is not large enough. That's it. Fixed it. I wonder how many others are limited by the predicted values?
            The rest are limited to 32 time_steps apparently. I was able to quickly extend the others in bridge_creator to 64 time_steps. 

✅    Check to see if you have already stored one. Look at build_slides for a template.
            Got it done. But the echo diminishment is too large. Where is that set? I found it: dmu.build_horn_from_text with vel_echo_max = 10, changed it to 5. I wonder how it sounds in the horns part of vamp_creator.

---------------------------
2/12/23 To do today:

✅    Now that I have the bridge_creator working with repeat_notes = 16, I wish I could make that optional, so the bridge could be faster.           

-----------------
2/13/23 To do today:

✅    Need to implement #2 from 2/12/23. Vary the length of the bridge_creator inputs.
      All four parts must be able to use 1/2 the duration, maybe 1/4 if it would work.
      Try:
            repeat_notes = 4 and see what breaks.

-------------------
2/14/23 To do today:

✅    The timing of the different parts is not correct. 
      a.    at 120 seconds , the horn switches to the bridge_creator, while the bass flute is still on the vamp_creator.
      b.    at 72 seconds, the horn has moved the vamp_creator, while the bass flute is still on bridge_creator, and what is the trill at 92 seconds?
      The problem is that I need to have all the bridge_creator sections have the same length, because the horn only gets one try, and all the other instruments must match that duration, otherwise the horn is out of synch. 
      Fixed it. Now try setting long_bridge to 1,2,or 4. Works great. But I still haven't made customer inputs_array_32 = It was just slicing another one and calling it good. And at 80 seconds in it's great. 

✅    I have 1 & 2 working, but 4 is sketchy. 
      It only plays the bass flute for half the duration, then it's just the horns changing so slowly as to not being apparent.

------------------------------
2/15/23 To do today:

✅    Post version 26. It's pretty good. Two long_bridge 1's and one 2. Nice arrangement. Once I heard the full thing I noticed that the bass part disappeared. Did not post.

✅    I think I've fixed the long_bridge choices, but the one with length of 4 is way too long. 
      I need to cut all of their lengths in half, then I can choose 1,2, or 4. That's going to lead to some real crap, I'm afraid.
      First, let me see if the 4 actually works.
      #2 leaves a long space at the end without the flute. Not cool. I can't figure out how to fix it.

-------------------------
2/16/23 To do today:

✅    Figure out why the second half of the long_bridge = 4 doesn't have any bass flute. 
      Does it have anything to do with the way I hacked the bass part by not including a longer bass part?

✅    Check the relationship between long_bridge = 4, key_metric = 1, and repeat_verse = 2. 
      Do they all do basically the exact same thing and are therefore superfluous? Clearly having large numbers for the latter two and 4 for the former results in a very long bridge_creator. Like 10 minutes or more. That is not what I wanted.

✅    Make sure the echo diminishment is sufficient for the horn in the vamp_creator. 7 should do it. Bumped it to 10

✅    Something is wiggy with the bass flute gliss selection. They look like velocities, not ftable numbers. Whack.
            bass_flute_note_array.shape = (6, 4, 32)
            2023-02-16 07:22:14,026 - root - INFO - inx	n	o	e	v	u	g	d
            2023-02-16 07:22:14,026 - root - INFO -  0	32	4	0	255	1	70	6
            2023-02-16 07:22:14,026 - root - INFO -  1	38	4	0	255	8	78	2
            ...
            2023-02-16 07:22:14,029 - root - INFO -  13	44	4	0	255	8	73	1

      Think hard. What did you change. You changed the value of val_echo_max. Why would that screw things up?
      I've been all through build_horn_from_text and the numbers are either 0 or 800+ all the way to the end. 
      I'm beginning to think that there is something wrong with the logging of values. I haven't been looking at them for a while, they may have started going wrong a long time ago. 
      The v values of 255 are actual values for upsamples, e values of 0 are more likely upsamples, and g are velocity, while u of 1,8 are envelopes. 
      build_horn_from_text outputs notes_in_scale, octave_array, gliss_array, ups_array, envelope_array, vel_array
      log_notes expects notes, octv, gls, ups, env, vel, and builds d
      There's your trouble. I reordered all the parameters as noguev and d. 
      Fixed it. That was nasty.

✅    Now when I set long_bridge to 1, the arpeggio and bass are silent. This is wierd.
      inst = 31	dmu.format_seconds_to_minutes(dur) = '00:02:36.000' <-- 2:36
      inst = 3	dmu.format_seconds_to_minutes(dur) = '00:02:00.000' <-- 2:00 why did it stop?
      Look at the size of the volume_array. It's correct. Where else?
      This is too hard. Time for a walk.

--------------------------------
2/17/23 To do today:

✅    Complete the bridge_creator support for long_bridge = 1,2,4. 
      It works correctly as the first call to bridge, will it fail as the second?
      Could it be I left off a critical axis statement:
            notes_features = np.concatenate((notes_features, current_notes_features), axis = 0) # <-- the axis was missing before
      Perhaps, but I'm still missing the arp part in the second bridge call. 2:00 vs. 2:36 for all the other instruments.
      It's not caused by long_bridge = 1. The second bridge with long_bridge = 2 is also missing the arp part.
      Now it's happening with just one bridge call long_bridge = 2 or 4 but not = 1. arp is short notes. Something is wrong with the note counts in arp section of bridge_creator for long_bridge 2 & 4, and for bflu in 4:
            long_bridge       bass  horn   arp  bflu
            1                 1:00  1:00  1:00  1:00
            2                 2:48  2:48  2:48  2:48
            4                 5:12  5:12  5:12  2:48 <-- I just need to fix bflu 
      Start with long_bridge = 2. Where to look:
      a.    _predicted: all 64
      b.    volume_array: all 64
      c.    We predict 64 but only 32 time_steps are created. This could be the trouble.
            multiplied repeat_all by long_bridge, then removed long_bridge from arpeggio_predicted.
      Now fix long_bridge = 4 for bass flute. without messing up the previous ones. Compare bass_flute_predicted with the dimension of the time_steps.
      building the bass flute line in bridge_creator
      bass_flute_predicted = 128, repeat_section = 1, key_metric = 1, repeat_notes = 8, repeat_all = 2, mult = 16, voices = 4
      expected_time_steps = 64, inputs_array = 'e1v70n0o5d12u0g0 d10o0 e8v78n2d2o5 n4 n3 n5 e1v70n7d8g12 n6d4 e8v78g0d2n1 n3 n0 e1v70g12d4n4 n2 n3 g0n1', repeat_notes = 8
      There it is. bass_flute_predicted = 128 expected_time_steps = 64
      volume_array.shape = (128,)
      How can I fix that without screwing up the others. Some key values
            repeat_section = key_metric
            repeat_notes = long_bridge * 2 # <-- not used.
            repeat_all = 2 
      How are they used? repeat_notes isn't used at all!
      Now the vamp_creator bass_flute_predicted is off: bfp = 192, arp = 96
      I think I fixed the problem with bass flute predicted in vamp_creator, but I'll have to confirm it with other values of long_bridge
      I also reverted to an old version to create bass_flute_predicted, and now they match.
      But the timing is close but not there yet. Still 5:12 vs 2:48 
      Those numbers are not in a simple relationship to each other: 5:12 = 312 seconds 2:48 = 168 312/168 = 1.857xxx
      I figured I could just double the 2:48 and get 5:12, but that's not the case. Very strange.
      Anyway, I definitely have 64 time_steps.
      repeat_section causes the rolls, which are the echos.
      Almost cleared them all up, except for bass flute with long_bridge = 4. I thought I had that, but not really.
      most are 10:00 and bass flute is 7:36.
      Bass flute starts out as 64, then 192 - 3 times is probably the roll function. Should be 4. That fixed it for now.

✅    What's going on with the bass. It stops at 257 seconds. Doesn't start up until 678 seconds. It disappears for seven minutes. 
      It's not because of the density function. I changed it for the simpler version without any major dropouts, and the gap persists.
      It's the bridge_creator bass line when long_bridge = 4. Check:
      a.    octaves: was it missing in the text input - no. search for Here are the bass notes in the ball3.log.
      b.    isolate just the bass line.

------------------------
2/18/23 To do today:

✅    Figure out what the problem is with long_bridge = 4 in the bass part. 
      It's there, just very quiet. And slow. The notes exist. It's just that all the velocity values are zero. I saw that the order of passing parameters was not noguev,d as it should be and fixed that. This has no effect on the problem I was supposed to be addressing.
      inside build_bass_line, np.max(vel_array) = 82 in the vamp_creator, and only 0 in the bridge_creator. That's strange.
      Found the trouble:
      in bridge_creator, the return values are in the wrong order. They were:
            notes, octv, env, vel, ups, gls = dmu.text_to_features(input_to_process)
      and they should be:
            notes, octv, gls, ups, env, vel
      That solved the problem. For now.
      I was able to create ball3-t29 & ball3-t30 that sound pretty good. I'm still concerned about the mistimed trills. Let's get systematic about cleaning these up. Posted #30 on the blog and twitter. Not on facebook yet.

2.    I'm still bugged by:
      ✅    Trills don't match the tempo always. It's like one of them is mistimed. I had to cut the hold to hold * 1.01. 
            Improvement but not a final correction.
      b.    Bass flute melody is nothing special. It could be much better. Later
      ✅    The density input was built before recent revisions. 
            It needs to be created again. Or replacedd. I like the idea of replacing it. It was hard to keep, provided limited musical improvement, and wasn't able to make changes inside a verse or bridge. I'd call it a failurew. 

✅    I could redo #30 with more accurate timing for the density function. 
      I did not set final, and so did not take advantage of any of the density variations.
      I didn't notice that, so maybe it's not so important.

✅    I messed around with piano_roll_to_notes_features and now zero notes are making it into new_output.csd. Zero.      
      In send_to_csound_file after selecting for non-zero hold values. notes_features.shape = (0,) That's not right. All zero?
      It was because I had set hold * 0.0 instead of hold * 1.01. Oops. That's better than 1.1 in terms of getting the trills to sync with the rhythm. But 1.01 is better. 

----------------
2/19/23 To do today:

✅    Choose a density_function method that provides more control at the micro level, as well as the macro. 
      Control inside a section, and between all sections

✅    The lowest arpeggios sound off. I fixed it with several changes. I now track the average octave, and it's staying around 3.8, which is good. 
      Added control of the likelihood of a mask as a probabilistic number.
            likelihood = rng.choice([.5, .6, .7, .8], p = [.1, .2, .4, .3]) # range of probabilities to be masked from 50% to 20%
            logging.info(f'setting the mask in bass vamp. {divisor = }, {likelihood = }, {np.max(octv) = }, {np.min(octv) = }')
            mask = rng.choice([0, 1], size = (voices, divisor), p = [1 - likelihood, likelihood])

--------------------------
2/21/23 To do today:

Long term changes:

1.    Shift to gliss_type == 'cubic16_16_224' for the build_horn_from_text function. This would really improve the quality of the slides in the bass flute. Perhaps.

2.    Implement hold control inside text_to_features _parse, _arrays_from_text. 
      It will need some pretty massive changes to piano_roll_to_notes_features. Let's see what it sounds like at 1.01 first.

3.    The Aretha Franklin "Say a Little Prayer" contains some incredible glissandi. As does Anita Baker "Giving You the Best that I Got". "Good Love". 
      Actually every song in the Apple Music Anita Baker Essentials collection should be a guide for your next bass flute melody.

Short term changes:

✅    Take the advice you heard on the zoom conference last week. 
      If all your music is made up of 16th notes then your suffer from monotonousness. Try some other rythms. That means getting away from the mask to turn quarter notes into random complex 16th notes patterns. Use the likelihood modification from yesterday to make things even more sparse. Let the rhythms other than 1/16th notes flourish.
      One idea that has the highest effort to benefit ratio: Keep that same mask for longer periods of time so the rhythm has time to soak in. 
      The masks are so small that they change very little from one time through the bridge_creator and the next. 
      I reduced the density significantly, and let's see if that makes it simpler to follow.

---------------------
2/23/23 To do today: 

✅    Make it more sparse. 
-------------------
2/24/23 To do today:

✅    Make another three candidate mp3 files and go for a walk.

2.    Choose one.

------------------
2/25/23 To do today:

1. Move on to another sound. Some musical ideas:
      a.    Remake of Cuernavaca with more variety of possible keys. A music box that seems very out of tune getting more and more towards just harmony as it slows down.
      b.    Look at other ranks, include C,D, or maybe the higher orders.
      c.    Cello martele, finger piano, woodwinds, brass
      d.    

2.    Update the github, blog, facebook, twitter.

3.    Go back and listen to the first experiments with Bosendorfer & coconet rhythms. 
      These avoided a preponderance of 4:4 measures, which led to many surprises.

4.    Some coding ideas to avoid tickly-tacky 1/16th note rhythms caused by masking. 
      a.    Perhaps I could create a mask that limited the number of continuous 1/16th notes. What would characterize such rhythms? 
      Assume you start with a tonicnet Bach chorale, with lots of quarter notes, and several half and other mixed notes. Try to hand craft some masks and see what avoids the heavy dominance of 1/16th notes. It might be some check to make sure there are always at least two ones in a row. Or more. But there must be no more than a certain number of either ones or zeros. 

      b.    Perhaps I could take advantage of the processing of _arrays_from_text to generate time_steps from notes and durations. Make a flow chart from text to time steps to piano rolls to notes, feaatures. Introduce filters along the way and see what happens.

      c.    Add more features to _arrays_from_text. Start with holds. Take a look at comands.txt file. It has all the csound command letters. I really wish I had some of these, like the add, subtract, multipy, and divide. Or perhaps the right envelope, left envelope distiction. Stereo if it could default to a random location, some number than didn't mean location, but rather to let the system choose a random location in the 0 - 15 field. Like maybe 16. 

      d.    Consider changing the upsample values from 253, 254, 255, 0, 2, 1, 2 ,3 to -3, -2, -1, 0, 1, 2, 3. 

      e.    Generate evelope ftables on the fly instead of using the ones in csound.

